{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "#basic package\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import math\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "#topics modeling\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim \n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "#modelling\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, acf, pacf\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we restrict the time series to one value per 60 seconds \n",
      "we compute the complexity variables each 30 minutes \n",
      "each variables includes the values of at least the last 120.00 minutes (i.e. are using 120.00 values)\n"
     ]
    }
   ],
   "source": [
    "from UTILS import perc_element_dico\n",
    "import config_mobility as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "title_ = '_LB' #'_LB', '_all','_LSL'\n",
    "path_save_ = os.path.join(path_extracted_data, 'visual', 'predict_KBF', title_)\n",
    "#create a director if not existinga\n",
    "if not os.path.exists(path_save_):\n",
    "    os.makedirs(path_save_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download LDA info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\camil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#add all topic modelling into one dataframe\n",
    "li_dflda = []\n",
    "title_ = '_LB'\n",
    "min_topic = 2\n",
    "max_topic = 14\n",
    "df_all_lda = pd.DataFrame(columns=['day','HenID'])\n",
    "for nbr_topics_ in tqdm.tqdm(range(min_topic,max_topic+1)):\n",
    "    print(df_all_lda.shape)\n",
    "    path_save = os.path.join(path_extracted_data,'visual','LDA', title_, str(nbr_topics_))\n",
    "    df_lda = pd.read_csv(os.path.join(path_save,'df_topics'+str(nbr_topics_)+'.csv'), sep=';',parse_dates=['day']) \n",
    "    #print(df_lda.shape)\n",
    "    #df_lda.head(3)\n",
    "    df_lda['topic'] = df_lda['topic'].map(lambda x: 'topic_'+str(x))\n",
    "    #lets take the topic distribution / main topic of the clustering with k=6-15 over all the days of the first session\n",
    "    li_sorted_days = df_lda.sort_values(['day'],ascending=True)['day'].unique()\n",
    "    li_topics = [x for x in df_lda.columns if (x.startswith('topic')) & (x!='topic_info')]\n",
    "    dico_topics_newtopics = {c:'k'+str(nbr_topics_)+'_'+ c for c in li_topics}\n",
    "    df_lda.rename(columns=dico_topics_newtopics, inplace=True)\n",
    "    df_all_lda = pd.merge(df_all_lda, df_lda[['HenID','day']+list(dico_topics_newtopics.values())], on=['HenID','day'], \n",
    "                          how='outer')      \n",
    "    lda = gensim.models.ldamodel.LdaModel.load(os.path.join(path_save,'model'+str(nbr_topics_)+'.gensim'))\n",
    "    sys.exit()\n",
    "print(df_all_lda.shape)\n",
    "df_all_lda.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word appartenance to topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0.031',\n",
       "  '\"[[\\'zone_2\\', \\'zone_3\\', \\'zone_2\\'], [\\'intermediate\\', \\'intermediate\\', \\'intermediate\\'], 0]\"'),\n",
       " ('0.030',\n",
       "  '\"[[\\'zone_3\\', \\'zone_2\\', \\'zone_3\\'], [\\'intermediate\\', \\'large\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.027',\n",
       "  '\"[[\\'zone_2\\', \\'zone_3\\', \\'zone_2\\'], [\\'large\\', \\'intermediate\\', \\'large\\'], 1]\"'),\n",
       " ('0.027',\n",
       "  '\"[[\\'zone_3\\', \\'zone_2\\', \\'zone_3\\'], [\\'large\\', \\'large\\', \\'large\\'], 1]\"'),\n",
       " ('0.027',\n",
       "  '\"[[\\'zone_2\\', \\'zone_3\\', \\'zone_2\\'], [\\'large\\', \\'large\\', \\'large\\'], 1]\"'),\n",
       " ('0.024',\n",
       "  '\"[[\\'zone_3\\', \\'zone_2\\', \\'zone_3\\'], [\\'large\\', \\'large\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.021',\n",
       "  '\"[[\\'zone_3\\', \\'zone_2\\', \\'zone_3\\'], [\\'intermediate\\', \\'intermediate\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.020',\n",
       "  '\"[[\\'zone_3\\', \\'zone_2\\', \\'zone_3\\'], [\\'intermediate\\', \\'intermediate\\', \\'intermediate\\'], 0]\"'),\n",
       " ('0.017',\n",
       "  '\"[[\\'zone_2\\', \\'zone_3\\', \\'zone_2\\'], [\\'large\\', \\'intermediate\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.017',\n",
       "  '\"[[\\'zone_2\\', \\'zone_3\\', \\'zone_2\\'], [\\'intermediate\\', \\'intermediate\\', \\'intermediate\\'], 1]\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0.035',\n",
       "  '\"[[\\'zone_4\\', \\'zone_3\\', \\'zone_4\\'], [\\'small\\', \\'small\\', \\'small\\'], 1]\"'),\n",
       " ('0.033',\n",
       "  '\"[[\\'zone_3\\', \\'zone_4\\', \\'zone_3\\'], [\\'small\\', \\'small\\', \\'small\\'], 1]\"'),\n",
       " ('0.025',\n",
       "  '\"[[\\'zone_4\\', \\'zone_3\\', \\'zone_4\\'], [\\'small\\', \\'small\\', \\'small\\'], 0]\"'),\n",
       " ('0.021',\n",
       "  '\"[[\\'zone_3\\', \\'zone_4\\', \\'zone_3\\'], [\\'small\\', \\'small\\', \\'small\\'], 0]\"'),\n",
       " ('0.011',\n",
       "  '\"[[\\'zone_3\\', \\'zone_4\\', \\'zone_3\\'], [\\'small\\', \\'small\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.011',\n",
       "  '\"[[\\'zone_4\\', \\'zone_5\\', \\'zone_4\\'], [\\'small\\', \\'large\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.010',\n",
       "  '\"[[\\'zone_3\\', \\'zone_4\\', \\'zone_3\\'], [\\'intermediate\\', \\'small\\', \\'small\\'], 1]\"'),\n",
       " ('0.010',\n",
       "  '\"[[\\'zone_4\\', \\'zone_5\\', \\'zone_4\\'], [\\'intermediate\\', \\'large\\', \\'intermediate\\'], 1]\"'),\n",
       " ('0.010',\n",
       "  '\"[[\\'zone_4\\', \\'zone_3\\', \\'zone_4\\'], [\\'intermediate\\', \\'small\\', \\'small\\'], 1]\"'),\n",
       " ('0.010',\n",
       "  '\"[[\\'zone_3\\', \\'zone_4\\', \\'zone_5\\'], [\\'intermediate\\', \\'small\\', \\'large\\'], 1]\"')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show the words in each topics: could be usefull if we would like to caracterize the clusters\n",
    "for topicsID_topicsWordDistribution in lda.print_topics():\n",
    "    print('\\n----', topicsID_topicsWordDistribution[0])\n",
    "    s = [x.strip() for x in re.split(r'(\\*)|(\\+)', topicsID_topicsWordDistribution[1]) if x not in [None,'*','+']]\n",
    "    t_weight_word = [(s[i], s[i+1]) for i in range(0,len(s),2)]\n",
    "    display(t_weight_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the html produced and human interpretation, lets select some topics manually (then also automatically if for e.g. we know\n",
    "#the nrb of cluster to aim for)\n",
    "li_path = ['']\n",
    "#TODO once needed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
