{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from numpy.linalg import eig #eigenvector decomposition\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from  matplotlib.colors import LinearSegmentedColormap  # to define our own palette for plots\n",
    "from matplotlib import pyplot #barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be consistent across all notebooks\n",
    "#ADD YOUR PATH TO SAVE OUTPUT (e.g.: 'G:\\\\VPHI\\\\Welfare\\\\2- Research Projects\\\\OFHE2.OriginsE2\\\\DataOutput\\\\')\n",
    "path_extracted_data = 'TO ADD'\n",
    "#ADD A NAME in case you want multiple run with all output saved each time\n",
    "saving_name = 'TO ADD'\n",
    "#choose better naming of behaviour (different names from the behavioural syndrome csv file than repeatbatility, so that 4 of the \n",
    "#behaviours have to be defined two times\n",
    "dico_mvt_name = {'scalefoodsameDurTimingr50final':'food reactivity index',\n",
    "                 'scaleverticaltraveldistancefulllightperinsideh':'vertical travelled distance',\n",
    "                 'midcumZ4hMorning':'mid-nestbox zone usage',\n",
    "                 'SleepingUppest':'has slept on top tier',\n",
    "                 'WentinWG':'has been outside',\n",
    "                'food_sameDurTiming_r50_final':'food reactivity index',\n",
    "                'Sleeping_Uppest':'has slept on top tier',\n",
    "                'vertical_travel_distance_fulllight_perinsideh':'vertical travelled distance',\n",
    "                'mid_cum_Z4_h_Morning':'mid-nestbox zone usage'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DELETE WHEN SENDING TO PUBLICATION\n",
    "path_extracted_data = config.path_extracted_data\n",
    "saving_name = 'ALLOBS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioural syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download mean and CI estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IC = pd.read_csv(os.path.join(path_extracted_data,saving_name+'_df_CI_BRMS_BS_pred_allvar_FINAL.csv'), sep=',')\n",
    "print(df_IC.shape) \n",
    "display(df_IC.head(3))\n",
    "\n",
    "df_mean = pd.read_csv(os.path.join(path_extracted_data,saving_name+'_df_mean_BRMS_BS_pred_allvar_FINAL.csv'), sep=',')\n",
    "print(df_mean.shape) \n",
    "display(df_mean.head(3))\n",
    "\n",
    "#merge both estimates and the CI\n",
    "df = pd.merge(df_mean, df_IC, on=['Unnamed: 0'], how='outer')\n",
    "df.rename(columns={'Unnamed: 0':'parameter','x':'value_mean'}, inplace=True)\n",
    "df['text'] = df.apply(lambda x: \"%.2f\" % round(x['value_mean'],2)+' ['+\"%.2f\" % round(x['lower'],2)+', '+\"%.2f\" % round(x['upper'],2)+']', \n",
    "                          axis=1)\n",
    "#separate parameters family (random effect, fexed effect, sigma, correlatiom)\n",
    "display(list(df['parameter'].unique()))\n",
    "df['type'] = df['parameter'].map(lambda x: x.split('_')[0])\n",
    "display(df['type'].value_counts())\n",
    "\n",
    "#henID intercept random intercept\n",
    "df['HenID'] = df['parameter'].map(lambda x: x.split(',')[0].split('[')[-1] if 'hen_' in x else None)\n",
    "#else None, otherwise will utput the entire name (i.e. x)\n",
    "print(df['HenID'].unique())\n",
    "\n",
    "#mvt variable for the hen intercepts to be visualised\n",
    "df['mvtvariable'] = df['parameter'].map(lambda x: x.split('r_HenID__')[-1].split('[')[0] if ('r_HenID__' in x) \\\n",
    "                                        & ('cor_HenID' not in x) else None)\n",
    "li_mvt = [i for i in df['mvtvariable'].unique() if i!=None]\n",
    "print(li_mvt)\n",
    "print('------------------all dataframe')\n",
    "print(df.shape) \n",
    "display(df.head(3))\n",
    "\n",
    "#correlations dataframe\n",
    "df_cor_summarized = df[df['type']=='cor'].copy()\n",
    "for mvt in li_mvt:\n",
    "    df_cor_summarized[mvt] = df_cor_summarized['parameter'].map(lambda x: mvt in x)\n",
    "print('------------------correlations dataframe')\n",
    "display(df_cor_summarized)\n",
    "\n",
    "#sd dataframe\n",
    "df_sd_summarized = df[df['type']=='sd'].copy()\n",
    "df_sd_summarized['parameter'] = df_sd_summarized['parameter'].map(lambda x: x.split('sd_HenID__')[-1])\n",
    "print('------------------sd dataframe')\n",
    "display(df_sd_summarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the correlation matrix\n",
    "CorrM = np.zeros(shape=(len(li_mvt), len(li_mvt)))\n",
    "labels_ = np.array([['                                '] * len(li_mvt)] * len(li_mvt))\n",
    "for i in range(0,len(li_mvt)):\n",
    "    CorrM[i][i] = np.nan\n",
    "    for j in range(i+1,len(li_mvt)):\n",
    "        mvt1 = li_mvt[i]\n",
    "        mvt2 = li_mvt[j]\n",
    "        v = df_cor_summarized[(df_cor_summarized[mvt1])&(df_cor_summarized[mvt2])]['value_mean'].values[0]     \n",
    "        CorrM[i][j] = v\n",
    "        CorrM[j][i] = np.nan\n",
    "        t = df_cor_summarized[(df_cor_summarized[mvt1])&(df_cor_summarized[mvt2])]['text'].values[0] \n",
    "        t = t.replace(' [','\\n [')\n",
    "        labels_[i][j] = t\n",
    "        labels_[j][i] = ''\n",
    "print(CorrM)\n",
    "#print(labels_)\n",
    "plt.figure(figsize=(14,3)) #9, 6.5\n",
    "sns.heatmap(CorrM, cmap='RdYlGn', annot=labels_, fmt = '', \n",
    "            xticklabels=[dico_mvt_name[i] for i in li_mvt], yticklabels=[dico_mvt_name[i] for i in li_mvt],\n",
    "           vmin=-0.55, vmax=0.55)\n",
    "plt.xticks(rotation=10)\n",
    "#fmt = ''is required for string labels\n",
    "plt.xlabel('');\n",
    "plt.ylabel('');\n",
    "plt.savefig(os.path.join(path_extracted_data,'BS_corr.png'),dpi=300,format='png',bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eigenvector decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html\n",
    "#chose behaviour we want in the pca and assocaite them to a name\n",
    "li_mvt_pc = ['scalefoodsameDurTimingr50final', 'scaleverticaltraveldistancefulllightperinsideh', 'SleepingUppest', 'WentinWG']\n",
    "#midcumZ4hMorning\n",
    "Corr = np.zeros(shape=(len(li_mvt_pc), len(li_mvt_pc)))\n",
    "for i in range(0,len(li_mvt_pc)):\n",
    "    Corr[i][i] = 1\n",
    "    for j in range(i+1,len(li_mvt_pc)):\n",
    "        mvt1 = li_mvt_pc[i]\n",
    "        mvt2 = li_mvt_pc[j]\n",
    "        v = df_cor_summarized[(df_cor_summarized[mvt1])&(df_cor_summarized[mvt2])]['value_mean'].values[0]     \n",
    "        Corr[i][j] = v\n",
    "        Corr[j][i] = v\n",
    "print(Corr)\n",
    "#eigen decomposition sorted by biggest eingenvalues\n",
    "eigenValues, eigenVectors = eig(Corr)\n",
    "idx = eigenValues.argsort()[::-1]   \n",
    "eigenValues = eigenValues[idx]\n",
    "eigenVectors = eigenVectors[:,idx]\n",
    "#in R would simply be: eigen(Corr). same result\n",
    "print(li_mvt_pc)\n",
    "print(eigenValues)\n",
    "comp1 = list(eigenVectors[:,0])\n",
    "comp2 = list(eigenVectors[:,1])\n",
    "#unit length vector\n",
    "print(np.sqrt(sum([i*i for i in comp1])))\n",
    "print(eigenVectors)#first columns: pc1 (multiple 0,0 by limvt0, 1,0 by VTD,... ;  second: pc2\n",
    "print('Explained var:')\n",
    "li_exvar = [i/sum(eigenValues) for i in eigenValues]\n",
    "print(sum(li_exvar))\n",
    "li_exvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard deviation of the loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#download all posterior samples to compute std dev of the PCs\n",
    "df_allit = pd.read_csv(os.path.join(path_extracted_data,'BRMS_BS_pred_allvar_FINAL.csv'), sep=',')\n",
    "print(df_allit.shape)  #(1250, 4044) ou (5000, 1011)\n",
    "li_col = set([x for x in list(df_allit.columns) if 'cor_HenID__' in x]) #X*, where * is the number of chain\n",
    "print(len(li_col))\n",
    "display(li_col)\n",
    "df_allit = df_allit[li_col].copy()\n",
    "df_allit['run'] = df_allit.index\n",
    "print(df_allit.shape)\n",
    "display(df_allit.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find std deviation of pcs\n",
    "li_comp1 = []\n",
    "li_comp2 = []\n",
    "li_chain = list(set([x.split('.')[0] for x in list(df_allit.columns) if 'X' in x]))\n",
    "print(li_chain)\n",
    "for run in tqdm.tqdm(df_allit['run'].unique()):\n",
    "    for chain in li_chain:\n",
    "        df_ = df_allit[df_allit['run']==run][[x for x in list(df_allit.columns) if 'X1' in x]].copy()\n",
    "        M = np.zeros(shape=(len(li_mvt_pc), len(li_mvt_pc)))\n",
    "        for i in range(0,len(li_mvt_pc)):\n",
    "            M[i][i] = 1\n",
    "            for j in range(i+1,len(li_mvt_pc)):\n",
    "                mvt1 = li_mvt_pc[i]\n",
    "                mvt2 = li_mvt_pc[j]\n",
    "                vc = [x for x in list(df_.columns) if (mvt1 in x)&(mvt2 in x)]\n",
    "                if len(vc)!=1:\n",
    "                    print('ERROR')\n",
    "                    print(vc)\n",
    "                    sys.exit()\n",
    "                v = df_[vc[0]].values[0]\n",
    "                M[i][j] = v\n",
    "                M[j][i] = v\n",
    "        #print(M)\n",
    "        #eigen decomposition sorted by biggest eingenvalues\n",
    "        eigenValues, eigenVectors = eig(M)\n",
    "        idx = eigenValues.argsort()[::-1]   \n",
    "        eigenValues = eigenValues[idx]\n",
    "        eigenVectors = eigenVectors[:,idx]\n",
    "        #extract first and second column\n",
    "        li_comp1.append(eigenVectors[:,0])\n",
    "        li_comp2.append(eigenVectors[:,1])\n",
    "df_pc1loading = pd.DataFrame(li_comp1, columns=li_mvt_pc)\n",
    "df_pc2loading = pd.DataFrame(li_comp2, columns=li_mvt_pc)\n",
    "print(df_pc1loading.shape)\n",
    "display(df_pc1loading.head(5))\n",
    "\n",
    "#because Eigenvectors are not unique & multiplying by any constant, including -1 (which simply changes the sign), gives \n",
    "#another valid eigenvector, we have to account for this and ensure for isntace that one of the behaviour is always positive\n",
    "#and if not,  multiplying all behaviours by -1\n",
    "df_pc1loading['scaleverticaltraveldistancefulllightperinsideh'] = np.where(df_pc1loading['scalefoodsameDurTimingr50final']>0, \n",
    "                                 df_pc1loading['scaleverticaltraveldistancefulllightperinsideh'], #where condition is True (>0:keep)\n",
    "                                 df_pc1loading['scaleverticaltraveldistancefulllightperinsideh']*-1)\n",
    "#df_pc1loading['midcumZ4hMorning'] = np.where(df_pc1loading['scalefoodsameDurTimingr50final']>0, \n",
    "#                                 df_pc1loading['midcumZ4hMorning'], #where condition is True\n",
    "#                                 df_pc1loading['midcumZ4hMorning']*-1)\n",
    "df_pc1loading['SleepingUppest'] = np.where(df_pc1loading['scalefoodsameDurTimingr50final']>0, \n",
    "                                 df_pc1loading['SleepingUppest'], #where condition is True\n",
    "                                 df_pc1loading['SleepingUppest']*-1)\n",
    "df_pc1loading['WentinWG'] = np.where(df_pc1loading['scalefoodsameDurTimingr50final']>0, \n",
    "                                 df_pc1loading['WentinWG'], #where condition is True\n",
    "                                 df_pc1loading['WentinWG']*-1)\n",
    "#Note: this behaviours have to be done after all others\n",
    "df_pc1loading['scalefoodsameDurTimingr50final'] = np.where(df_pc1loading['scalefoodsameDurTimingr50final']>0, \n",
    "                                 df_pc1loading['scalefoodsameDurTimingr50final'], #where condition is True\n",
    "                                 df_pc1loading['scalefoodsameDurTimingr50final']*-1)\n",
    "df_pc1loading.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,1.5))\n",
    "cmap_ = LinearSegmentedColormap.from_list('rg',[\"lightgrey\", \"black\"], N=256) \n",
    "labels_ = np.array([['                   '] * len(li_mvt_pc)] * 2)\n",
    "for i in range(0,len(li_mvt_pc)):\n",
    "    labels_[0][i] = '%.2f' %round(comp1[i],2)+'\\n  (±'+'%.2f' %round(np.std(abs(df_pc1loading[li_mvt_pc[i]])),2) +')'\n",
    "    labels_[1][i] = '%.2f' %round(comp2[i],2)+'\\n  (±'+'%.2f' %round(np.std(abs(df_pc2loading[li_mvt_pc[i]])),2) +')'\n",
    "sns.heatmap(np.array([[i for i in comp1], [i for i in comp2]]), annot=labels_, fmt = '', cmap='RdYlGn',vmin=-1, vmax=1,\n",
    "            yticklabels=['PC1 \\n('+str(round(li_exvar[0]*100))+'%)', 'PC2 \\n('+str(round(li_exvar[1]*100))+'%)'], \n",
    "            xticklabels=[dico_mvt_name[i] for i in li_mvt_pc]);\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.savefig(os.path.join(path_extracted_data,'BS_PrincComp_loadings.png'),dpi=300,format='png',bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualise among behaviours correlation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#slope of a fitted line = Cov(X,Y)/Var(X) = corr(X,Y) * SD(X) * SD(Y) /Var(X)\n",
    "#                                         = corr(X,Y) * sqrt(var(X)) * sqrt(var(Y)) /Var(X)\n",
    "#Reference: https://www.physicsforums.com/threads/slope-of-ls-line-cov-x-y-var-x-intuitive-explanation.880963/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_mvt = ['scalefoodsameDurTimingr50final','scaleverticaltraveldistancefulllightperinsideh', 'midcumZ4hMorning',\n",
    "          'SleepingUppest', 'WentinWG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#choose color: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "#df[df['HenID'].isnull()].shape\n",
    "df_plt = df[~df['HenID'].isnull()].pivot(index='HenID', columns='mvtvariable', values=['value_mean',\n",
    "                                                                                       'lower','upper']).reset_index()\n",
    "df_plt.columns = ['_'.join(col) for col in df_plt.columns.values] #joining name from different index\n",
    "display(df_plt.head(3))\n",
    "for i in range(0,len(li_mvt)-1):\n",
    "    for j in range(i+1,len(li_mvt)):\n",
    "        mvtx = li_mvt[i]\n",
    "        mvty = li_mvt[j]\n",
    "        print(mvtx)\n",
    "        print(mvty)\n",
    "        cor_mvtx_mvty = df_cor_summarized[(df_cor_summarized[mvtx])&(df_cor_summarized[mvty])]['value_mean'].iloc[0]\n",
    "        cor_mvtx_mvty_upper = df_cor_summarized[(df_cor_summarized[mvtx])&(df_cor_summarized[mvty])]['upper'].iloc[0]\n",
    "        cor_mvtx_mvty_lower = df_cor_summarized[(df_cor_summarized[mvtx])&(df_cor_summarized[mvty])]['lower'].iloc[0]\n",
    "        print(cor_mvtx_mvty)\n",
    "        sd_mvtx = df_sd_summarized[df_sd_summarized['parameter']==mvtx+'_Intercept']['value_mean'].iloc[0]\n",
    "        print(sd_mvtx)\n",
    "        sd_mvty = df_sd_summarized[df_sd_summarized['parameter']==mvty+'_Intercept']['value_mean'].iloc[0]\n",
    "        print(sd_mvty)        \n",
    "        slope = cor_mvtx_mvty*sd_mvtx*sd_mvty/(sd_mvtx*sd_mvtx)\n",
    "        print(slope)\n",
    "        #choose color:\n",
    "        li_ = [mvtx, mvty]\n",
    "        if ('scalefoodsameDurTimingr50final' in li_) & ('scaleverticaltraveldistancefulllightperinsideh' in li_):\n",
    "            color_ = 'green'\n",
    "        elif ('scalefoodsameDurTimingr50final' in li_) & ('WentinWG' in li_):\n",
    "            color_ = 'yellowgreen' #lightsalmon\n",
    "        elif ('scaleverticaltraveldistancefulllightperinsideh' in li_) & ('SleepingUppest' in li_):\n",
    "            color_ = 'sandybrown'\n",
    "        elif ('scaleverticaltraveldistancefulllightperinsideh' in li_) & ('WentinWG' in li_):\n",
    "            color_ = 'darkgreen'\n",
    "        else:\n",
    "            color_ = 'black'\n",
    "        plt.figure(figsize=(5,5))\n",
    "        #ax = sns.scatterplot(data=df_plt, x='value_mean_'+mvtx,  y='value_mean_'+mvty)#,  size=\"size\", sizes=(20, 200))\n",
    "        plt.scatter(df_plt['value_mean_'+mvtx].tolist(), df_plt['value_mean_'+mvty].tolist(), color=color_, s=5)\n",
    "        plt.errorbar(df_plt['value_mean_'+mvtx].tolist(), df_plt['value_mean_'+mvty].tolist(),\n",
    "                     xerr=[df_plt['lower_'+mvtx].tolist(),df_plt['upper_'+mvtx].tolist()], \n",
    "                     yerr=[df_plt['lower_'+mvty].tolist(),df_plt['upper_'+mvty].tolist()],\n",
    "                     fmt=\"o\", color=color_, alpha=0.2,ms=5)\n",
    "        plt.xlabel(mvtx)\n",
    "        plt.ylabel(mvty)\n",
    "        x_min = min(df_plt['value_mean_'+mvtx].tolist())\n",
    "        y_min = x_min*slope\n",
    "        x_max = max(df_plt['value_mean_'+mvtx].tolist())\n",
    "        y_max = x_max*slope\n",
    "        plt.plot([x_min, x_max], [y_min, y_max], color='black')\n",
    "        text_ = 'r = '+\"%.2f\" % round(cor_mvtx_mvty,2)+' ['+\"%.2f\" % round(cor_mvtx_mvty_lower,2)+', '+\"%.2f\" % round(cor_mvtx_mvty_upper,2)+']'\n",
    "        plt.text(max(df_plt['upper_'+mvtx].tolist())*0.1, max(df_plt['upper_'+mvty].tolist())*1.4, text_, fontsize=13)\n",
    "        #plt.set_xlim([x_min, x_max])   \n",
    "        plt.savefig(os.path.join(path_extracted_data,'BS_'+mvtx+'_'+mvty+'.png'),dpi=300,format='png',bbox_inches='tight')\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for the repeatability csv files, download each file and concatenate them\n",
    "li_df = []\n",
    "for path_ in glob.glob(os.path.join(path_extracted_data,'R_estimates_*.csv')):\n",
    "    print('--------------------- files %s'%path_.split('\\\\')[-1])\n",
    "    df_ = pd.read_csv(path_, sep=',', index_col=0)\n",
    "    print(df_.shape) \n",
    "    display(df_.head(3))\n",
    "    li_df.append(df_)\n",
    "print('------------------------- ALL TOGETHER:')\n",
    "df_R = pd.concat(li_df)  \n",
    "df_R['VI_LL'] = df_R['li_VI'].map(lambda x: float(x.split(', ')[0].split('[')[1]))\n",
    "df_R['VI_UL'] = df_R['li_VI'].map(lambda x: float(x.split(', ')[1].strip(']')))\n",
    "df_R['VE_LL'] = df_R['li_VE'].map(lambda x: float(x.split(', ')[0].split('[')[1]))\n",
    "df_R['VE_UL'] = df_R['li_VE'].map(lambda x: float(x.split(', ')[1].strip(']')))\n",
    "df_R['VI'] = df_R['li_VI'].map(lambda x:float(x.split(' ')[0]))\n",
    "df_R['VE'] = df_R['li_VE'].map(lambda x:float(x.split(' ')[0]))\n",
    "display(df_R[['li_VI','li_VE','VI','VE','VI_LL','VI_UL','VE_LL','VE_UL']].head(3))\n",
    "df_R['li_mvt_named'] = df_R['li_mvt'].map(lambda x: dico_mvt_name[x])\n",
    "print(df_R.shape) \n",
    "display(df_R.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add nice text to output in the paper (i.e. with specific number of values after the comma, adding useless 0)\n",
    "#add R and 95% interval as a text column\n",
    "df_R['text'] = df_R.apply(lambda x: (\"%.2f\" % x['li_R'])+' ['+(\"%.2f\" % x['li_CIL'])+', '+(\"%.2f\" % x['li_CIU'])+']', \n",
    "                          axis=1)\n",
    "df_R['li_VI'] = df_R.apply(lambda x: (\"%.4f\" % x['VI'])+' ['+(\"%.4f\" % x['VI_LL'])+', '+(\"%.4f\" % x['VI_UL'])+']', \n",
    "                          axis=1)\n",
    "df_R['li_VE'] = df_R.apply(lambda x: (\"%.4f\" % x['VE'])+' ['+(\"%.4f\" % x['VE_LL'])+', '+(\"%.4f\" % x['VE_UL'])+']', \n",
    "                          axis=1)\n",
    "df_R.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a matrix with each row corresponding to a movement behavior and each column a situation (over time, wihtin a context,\n",
    "#across context). sort matrix by specific order\n",
    "dico_bstype_order = {'AC':6, 'LP10':5, 'LP2':2, 'VD':4, 'cold':3, 'time':1}\n",
    "dico_bstype_name = {'AC':'AC', 'LP10':'LLS', 'LP2':'ELS', 'VD':'VD', 'cold':'CET', 'time':'OT'}\n",
    "df_R['order'] = df_R['li_BStype'].map(lambda x: dico_bstype_order[x])\n",
    "df_R['li_BStype'] = df_R['li_BStype'].map(lambda x: dico_bstype_name[x])\n",
    "df_R = df_R.sort_values(['order'])\n",
    "#all R with CI\n",
    "df_plt = df_R.pivot(index='li_mvt_named', columns='li_BStype', values='text').reset_index()\n",
    "df_plt = df_plt[['li_mvt_named','OT','ELS','CET','VD','LLS','AC']]\n",
    "df_plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_ = LinearSegmentedColormap.from_list('rg',[\"lightgrey\", \"black\"], N=256) \n",
    "df_plt = df_R.pivot(index='li_mvt_named', columns='li_BStype', values='li_R')#.reset_index()\n",
    "df_plt = df_plt[['OT','ELS','CET','VD','LLS','AC']]\n",
    "#df_plt\n",
    "li_col = list(df_R['li_BStype'].unique())\n",
    "\n",
    "########################## normalize by row ##########################\n",
    "plt.figure(figsize=(5,2))\n",
    "df_plt_nr = df_plt.copy()\n",
    "for mv in list(df_plt_nr.index): \n",
    "    df_plt_nr.loc[mv] = (df_plt_nr.loc[mv]-df_plt_nr.loc[mv].min())/(df_plt_nr.loc[mv].max()-df_plt_nr.loc[mv].min())\n",
    "display(df_plt_nr)\n",
    "sns.heatmap(df_plt_nr, cmap=cmap_, annot=False,\n",
    "        xticklabels=list(df_plt_nr.columns), yticklabels=list(df_plt_nr.index),linewidths=1.8)\n",
    "plt.xlabel('');\n",
    "plt.ylabel('');\n",
    "plt.title('Repeatability normalized by rows \\n (comparison between contexts)', size=10.5)\n",
    "plt.savefig(os.path.join(path_extracted_data,'R_normalizedrowwise.png'),dpi=300,format='png',bbox_inches='tight')\n",
    "plt.show();\n",
    "\n",
    "########################## normalize by columns ##########################\n",
    "plt.figure(figsize=(5,2))\n",
    "df_plt_nc = (df_plt[li_col]-df_plt[li_col].min())/(df_plt[li_col].max()-df_plt[li_col].min())\n",
    "display(df_plt_nc)\n",
    "sns.heatmap(df_plt_nc, cmap=cmap_, annot=False,\n",
    "            xticklabels=list(df_plt_nc.columns), yticklabels=list(df_plt_nc.index),linewidths=1.8)\n",
    "plt.xlabel('');\n",
    "plt.ylabel('');\n",
    "plt.title('Repeatability normalized by columns \\n (comparison between behaviours)', size=10.5)\n",
    "plt.savefig(os.path.join(path_extracted_data,'R_normalizedcolumnwise.png'),dpi=300,format='png',bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check #obs and #individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check metadata\n",
    "#small check: (the gamma  : nestbox zone behaviour) family should have NAN everywhere, but is base dont he exact same dataset\n",
    "display(df_R[['li_BStype','li_mvt','li_ngroup','li_nobs']].sort_values(['li_BStype','li_mvt'])) #CORRECT!\n",
    "df_R[df_R['li_mvt']=='vertical_travel_distance_fulllight_perinsideh'][['li_BStype','li_ngroup','li_nobs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#verification of R based on VI, VE\n",
    "#in the binary the VE is the residual variance, which is define a s w(math.pi**2/3) innakawaga paper\n",
    "#in the gamma the VE is define as trigamma(shape) innakawaga paper\n",
    "df_R['verification'] = df_R.apply(lambda x: x['VI']/(x['VI']+x['VE']), axis=1)\n",
    "df_R['isequal'] = df_R.apply(lambda x: x['li_R']-x['verification']<0.01, axis=1)\n",
    "if df_R[~df_R['isequal']].shape[0]!=0:\n",
    "    print('ERROR in your within / between individual variance!')\n",
    "    display(df_R[~df_R['isequal']][['li_BStype','li_R','li_mvt','verification','VI','VE']].head(15))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_bstype_name = {'AC':'across context',\n",
    "                    'OT':'over time',\n",
    "                    'LLS':'late life stage',\n",
    "                    'ELS':'early life stage',\n",
    "                    'VD':'vaccination disturbance',\n",
    "                    'CET':'cold external temperature'}\n",
    "df_VIVEM = df_R.sort_values(['li_mvt'])[['li_BStype','li_mvt','li_VI','li_VE','li_mvtmean']].copy()\n",
    "df_VIVEM['li_mvt'] = df_VIVEM['li_mvt'].apply(lambda x: dico_mvt_name[x])\n",
    "df_VIVEM['li_BStype'] = df_VIVEM['li_BStype'].apply(lambda x: dico_bstype_name[x])\n",
    "df_VIVEM.rename(columns={'li_mvt': 'movement behaviour', 'li_BStype':'situations',\n",
    "                        'li_VI':'between-individual variance',\n",
    "                        'li_VE':'within-individual variance',\n",
    "                        'li_mvtmean':'trait meant'}, inplace=True)\n",
    "df_VIVEM.to_csv(os.path.join(path_extracted_data,'BS_df_VI_VE_TraitMean.csv'), index=False, sep=',')\n",
    "df_VIVEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe for metadata significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_c_meannbr = {'OT':60, \n",
    "                  'ELS':9, \n",
    "                  'CET':9, \n",
    "                  'VD':85, \n",
    "                  'LLS':9, \n",
    "                  'AC':128}\n",
    "df_R['meannbrdays'] = df_R['li_BStype'].map(lambda x: dico_c_meannbr[x])\n",
    "#remove the outlier\n",
    "df_R[['li_R','li_mvt','li_BStype','meannbrdays','VI','VE']].to_csv(os.path.join(path_extracted_data,'BS_lm_metadata.csv'), index=False, sep=',')\n",
    "df_R.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_R['li_R']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_mvt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.melt(df_R, id_vars=['li_mvt','li_BStype','meannbrdays'], value_vars=['VI','VE'], value_name = 'value')\n",
    "dico_V_named = {'VI':'between-individual \\n variance', 'VE':'within-individual \\n variance'}\n",
    "df_['variable'] = df_['variable'].map(lambda x: dico_V_named[x])\n",
    "dico_mvt_name2 = {'WentinWG': 'has been outside',\n",
    "                 'food_sameDurTiming_r50_final': 'food reactivity index',\n",
    "                 'Sleeping_Uppest': 'has slept on top tier',\n",
    "                 'vertical_travel_distance_fulllight_perinsideh': 'vertical travelled \\ndistance',\n",
    "                 'mid_cum_Z4_h_Morning': 'mid-nestbox zone \\nusage'}\n",
    "df_['li_mvt_named'] = df_['li_mvt'].map(lambda x: dico_mvt_name2[x])\n",
    "pal_ = {'between-individual \\n variance':'black', 'within-individual \\n variance':'grey'}\n",
    "display(df_.head(3))\n",
    "plt.figure(figsize=(10,1.1))\n",
    "l=1\n",
    "c=5\n",
    "for i,(mvt, df_plt) in enumerate(df_.groupby(['li_mvt_named'])):\n",
    "    plt.subplot(l,c,i+1)\n",
    "    if i==0:\n",
    "        sns.lineplot(x='meannbrdays',y='value', data=df_plt, hue='variable', palette=pal_, legend=True);\n",
    "        plt.legend(bbox_to_anchor=(-0.04, 0), loc='lower right', borderaxespad=0)\n",
    "    else:\n",
    "        sns.lineplot(x='meannbrdays',y='value', data=df_plt, hue='variable', palette=pal_, legend=False);\n",
    "    plt.ylabel('')\n",
    "    if i==2:\n",
    "        plt.xlabel('mean number of days between any 2 observations')\n",
    "    else:\n",
    "        plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.yticks([])\n",
    "    plt.title(mvt, size=10)\n",
    "    #plt.show();\n",
    "plt.savefig(os.path.join(path_extracted_data,'Within_between_var.png'),dpi=300,format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
