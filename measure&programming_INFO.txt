


-----------Topic modelling with LDA
différente longeur: 
- Pas bien d'utiliser climate change, et climate et change! donc se sticker à une size c'est peut être mieux, aussi ca peut faire pus de sens pour l'interpretation.
+ peut identifier les birds qui font plus de chaotic transition? (i.e. of length=2) & ceux qui font des move interessant (i.e. length >2)

1. bag of words: each documents will be converted to a vector of length of the vocabulary from all documents, and will for each voc give the count of this word in the particular documents ([0,0,2,1,0,0]: document has twice the 3 element from the voc and once the fourth element from the document)
2.When training an LDA model, you start with a collection of documents and each of these is represented by a fixed-length vector (bag-of-words). LDA is a general Machine Learning (ML) technique, which means that it can also be used for other unsupervised ML problems where the input is a collection of fixed-length vectors and the goal is to explore the structure of this data.

TO READ ABOUT: topic modelling with small dictionary, ethogram to define words, 

TOTRY: should we keep the mouvement during the night as well?? and add night hours? but those are less frequent so if yes, then dont remove them as easily than the other movement when preprocessing
info on model parameters 
https://radimrehurek.com/gensim/models/ldamodel.html
https://stackoverflow.com/questions/50805556/understanding-parameters-in-gensim-lda-model
*passes (int, optional) – Number of passes through the corpus during training
*random_state - this serves as a seed (in case you wanted to repeat exactly the training process)
*chunksize - number of documents to consider at once (affects the memory consumption)
*update_every - update the model every update_every chunksize chunks (essentially, this is for memory consumption optimization)
*passes - how many times the algorithm is supposed to pass over the whole corpus
*alpha - can be set to an explicit array = prior of your choice. It also support special values of `‘asymmetric’ and ‘auto’: the former uses a fixed normalized asymmetric 1.0/topicno prior, the latter learns an asymmetric prior directly from your data.
*per_word_topics - setting this to True allows for extraction of the most likely topics given a word. The training process is set in such a way that every word will be assigned to a topic. Otherwise, words that are not indicative are going to be omitted. phi_value is another parameter that steers this process - it is a threshold for a word treated as indicative or not.


------------motif  discovery
mon idee:
il est plus important de trouver des motifs long similarie que des motifs courts très similaires
on prends une ts on la coupe avec un scertan stride et longeur. on compare une par une et on regarder si sim=0 on as, si sim>similarity minimal recherche on stop, si sim>0 et <simliratié minimale recherché on continu, on coupe etc


------------DTW

However, DTW has a quadratic (au carré)
time complexity. Nevertheless, by applying the LB_Keogh lower bounding technique, DTW can perform approximately linear
ALso to reduce time read this paper: https://www.cs.cmu.edu/~christos/PUBLICATIONS/ICDE07-spring.pdf

https://www.cs.unm.edu/~mueen/DTW.pdf:
* Efficiency: You can use DTW to search one billion
subsequences in under two minutes, using all the “tricks”
shown in this tutorial. However a naïve off-the-shelf recursionbased DTW implementation would take six years1.
* Effectiveness: While DTW is quite robust, there are some
“silly” things you could do to cripple its effectiveness; not znormalizing, set the wrong warping window, enforcing the
endpoint constraint in certain datasets…

no k-means for DTW clustering (https://stats.stackexchange.com/questions/131281/dynamic-time-warping-clustering)
Do not use k-means for timeseries.
DTW is not minimized by the mean; k-means may not converge and even if it converges it will not yield a very good result. The mean is an least-squares estimator on the coordinates. It minimizes variance, not arbitrary distances, and k-means is designed for minimizing variance, not arbitrary distances.
Assume you have two time series. Two sine waves, of the same frequency, and a rather long sampling period; but they are offset by π. Since DTW does time warping, it can align them so they perfectly match, except for the beginning and end. DTW will assign a rather small distance to these two series. However, if you compute the mean of the two series, it will be a flat 0 - they cancel out. The mean does not do dynamic time warping, and loses all the value that DTW got. On such data, k-means may fail to converge, and the results will be meaningless. K-means really should only be used with variance (= squared Euclidean), or some cases that are equivalent (like cosine, on L2 normalized data, where cosine similarity is the same as 2− squared Euclidean distance)
Instead, compute a distance matrix using DTW, then run hierarchical clustering such as single-link. In contrast to k-means, the series may even have different length.
ALSO: DTW is a Distance Measure, not a Metric
We can set the value of w using leave-one-out cross-validation on the
testing data. So long as we have enough labeled data, this generally
works very well. What do you do if you don’t have enough labeled data? (open problem)
One Idea: Find a dataset that is similar, that does have labeled data, and hope
the best setting generalizes from that dataset.  Not perfect, but close The value of w vs. 
For classification and query-by-content, the best setting of w also
depends on the size of the training dataset.
If we are given more training data, we should expect:
– The error rate to decrease (as with all ML problems and all data types)
– The best value for w to get smaller 
Critical Point: You can generalize DTW to 2,3,4,…1,000 dimensions. However, it is very unlikely that more than 2 to 4 is useful, after that,
you are almost certainly condemned to the curse of dimensionality. 





