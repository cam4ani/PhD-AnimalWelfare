{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist #for euclidean distance of consistency\n",
    "from numpy import inf\n",
    "import networkx as nx\n",
    "from dtaidistance import dtw\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "import uuid #to generate random id\n",
    "import pickle #to save/load list of selected hens\n",
    "\n",
    "#test equal variance\n",
    "from scipy.stats import levene\n",
    "\n",
    "#clustering\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#interpolate curves for clustering among birds with not exact same days tracked\n",
    "#from scipy.interpolate import interp1d\n",
    "\n",
    "#modelling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, cohen_kappa_score, r2_score,\\\n",
    "mean_squared_error, mean_absolute_error, explained_variance_score#catboost, for a better support of categorical data\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from scipy.stats import pearsonr, spearmanr \n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "#PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "#clustering\n",
    "from sklearn.cluster import KMeans #only numerical var\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import kmodes\n",
    "from kmodes.kmodes import KModes #with categorical var as well\n",
    "\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dexplot as dxp #for barplot\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import chi2_distance, ts_visual, time_series_henColumn_tsRow, correct_key\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n",
      "correctlightschedule_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "#id_run = 'chapter0_final_'\n",
    "#path_dataoutput = r'G:\\VPHI\\Welfare\\2- Research Projects\\OFHE2.OriginsE2\\DataOutput'\n",
    "#path_extracted_data = os.path.join(path_dataoutput,'TrackingSystem') \n",
    "#path_extracted_data = os.path.join(path_extracted_data, id_run)\n",
    "dico_night_hour = config.dico_night_hour\n",
    "dico_matching = config.dico_matching\n",
    "li_binmn = config.li_binmn\n",
    "penalty = config.penalty\n",
    "dico_window = config.dico_window\n",
    "pal_class_treat = config.pal_class_treat\n",
    "pal_treat = config.pal_treat\n",
    "pal_class = config.pal_class\n",
    "pal_interintre_treatment = config.pal_interintre_treatment\n",
    "max_date_adaptability = config.max_date_adaptability\n",
    "dico_pen_tr = config.dico_pen_tr\n",
    "path_extracted_data_visual = os.path.join(path_extracted_data,'visual')\n",
    "path_extracted_data_visual_corr = os.path.join(path_extracted_data,'visual','correlation')\n",
    "path_extracted_data_visual_adap = os.path.join(path_extracted_data,'visual','Treatment&Classs','adaptability')\n",
    "print(id_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "rv = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected hens\n",
    "li_selected_hens = pickle.load(open(os.path.join(path_extracted_data_visual_adap,'li_selected_hens.pkl'), 'rb'))\n",
    "len(li_selected_hens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27214, 199)\n",
      "(6772, 199)\n",
      "(6772, 199)\n",
      "(6772, 199)\n",
      "(6429, 199)\n",
      "(6429, 199)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>level</th>\n",
       "      <th>duration_1_Zone</th>\n",
       "      <th>duration_2_Zone</th>\n",
       "      <th>duration_3_Zone</th>\n",
       "      <th>duration_4_Zone</th>\n",
       "      <th>duration_5_Zone</th>\n",
       "      <th>verification_daily_total_duration</th>\n",
       "      <th>dur_values</th>\n",
       "      <th>dur_values_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>PC0</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>clustering_ALL</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18886.0</td>\n",
       "      <td>3488.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>5908.0</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>[0.0, 18886.0, 3488.0, 518.0, 5908.0]</td>\n",
       "      <td>[0.0, 0.6557638888888889, 0.12111111111111111,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9310.0</td>\n",
       "      <td>5636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17454.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 9310.0, 5636.0, 0.0, 17454.0]</td>\n",
       "      <td>[0.0, 0.2873456790123457, 0.17395061728395061,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31849.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 551.0, 0.0, 31849.0]</td>\n",
       "      <td>[0.0, 0.0, 0.017006172839506173, 0.0, 0.982993...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID      level  duration_1_Zone  duration_2_Zone  duration_3_Zone  \\\n",
       "0  hen_1 2020-09-30              0.0          18886.0           3488.0   \n",
       "1  hen_1 2020-10-01              0.0           9310.0           5636.0   \n",
       "2  hen_1 2020-10-02              0.0              0.0            551.0   \n",
       "\n",
       "   duration_4_Zone  duration_5_Zone  verification_daily_total_duration  \\\n",
       "0            518.0           5908.0                            28800.0   \n",
       "1              0.0          17454.0                            32400.0   \n",
       "2              0.0          31849.0                            32400.0   \n",
       "\n",
       "                              dur_values  \\\n",
       "0  [0.0, 18886.0, 3488.0, 518.0, 5908.0]   \n",
       "1    [0.0, 9310.0, 5636.0, 0.0, 17454.0]   \n",
       "2        [0.0, 0.0, 551.0, 0.0, 31849.0]   \n",
       "\n",
       "                               dur_values_normalized  ... PC0 PC1 PC2 PC3 PC4  \\\n",
       "0  [0.0, 0.6557638888888889, 0.12111111111111111,...  ... NaN NaN NaN NaN NaN   \n",
       "1  [0.0, 0.2873456790123457, 0.17395061728395061,...  ... NaN NaN NaN NaN NaN   \n",
       "2  [0.0, 0.0, 0.017006172839506173, 0.0, 0.982993...  ... NaN NaN NaN NaN NaN   \n",
       "\n",
       "   PC5 PC6 PC7 clustering_ALL weeks_in_laying_barn  \n",
       "0  NaN NaN NaN            NaN                    1  \n",
       "1  NaN NaN NaN            NaN                    1  \n",
       "2  NaN NaN NaN            NaN                    1  \n",
       "\n",
       "[3 rows x 199 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily variables (one row per (henID, date))\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, 'daily_ALL_Variable_Tranformed.csv'), sep=';',\n",
    "                     parse_dates=['level','FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                              'FirstTimestamp_4_Zone', 'FirstTimestamp_5_Zone', \n",
    "                              'Nestbox_time_of_first_staid_longer_than900sec',\n",
    "                              'duration_last-firsttransition_mn'], dayfirst=True) \n",
    "df_daily['DOA'] = df_daily['level'].map(lambda x: (x-dt.datetime(2020,6,3)).days) \n",
    "df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: math.ceil(x/7))\n",
    "#first two month seems good from the %of hens not moving plot! and sounds good too (twice longer thatn they need to start moving)\n",
    "print(df_daily.shape)\n",
    "\n",
    "#filter by dates\n",
    "df_daily = df_daily[df_daily['level']<=max_date_adaptability] \n",
    "df_daily = df_daily[df_daily['level']>dt.datetime(2020,9,29)]\n",
    "\n",
    "#filter the selected hens\n",
    "df_daily = df_daily[df_daily['HenID'].isin(li_selected_hens)] \n",
    "\n",
    "#remove days that are not fully recorded\n",
    "df_daily['nbr_sec_per_day'] = df_daily['level'].map(lambda x: dico_night_hour[correct_key(x,dico_night_hour)]['nbr_hour']*60*60)\n",
    "df_daily['is_correct_amount_time'] = df_daily.apply(lambda x: x['nbr_sec_per_day']==x['verification_daily_total_duration'], axis=1)\n",
    "df_daily[(~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull())][['level', 'HenID', 'Total_number_transition', 'dur_values', 'verification_daily_total_duration','nbr_sec_per_day']]\n",
    "print(df_daily.shape)\n",
    "display(df_daily = df_daily[~((~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull()))])\n",
    "print(df_daily.shape)\n",
    "\n",
    "#remove the days where the night had movement recorded but not the days\n",
    "print(df_daily.shape)\n",
    "#display(df_daily[df_daily.isna().any(axis=1)])\n",
    "df_daily = df_daily[~df_daily['verification_daily_total_duration'].isnull()]\n",
    "print(df_daily.shape)\n",
    "\n",
    "df_daily['dur_values_normalized'].replace('[nan, nan, nan, nan, nan]','[np.nan,np.nan,np.nan,np.nan,np.nan]', inplace=True)\n",
    "df_daily['dur_values_normalized'] = df_daily['dur_values_normalized'].map(lambda x: eval(x))\n",
    "df_daily['duration_last-firsttransition_mn'] = df_daily['duration_last-firsttransition_mn'].astype(float)\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301289, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>system</th>\n",
       "      <th>Zone</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>next_record_date</th>\n",
       "      <th>previous_record_date</th>\n",
       "      <th>previous_duration</th>\n",
       "      <th>next_zone</th>\n",
       "      <th>previous_zone</th>\n",
       "      <th>previous_previous_zone</th>\n",
       "      <th>correction_is_consecutive_equal_initial_zone</th>\n",
       "      <th>is_WG_open</th>\n",
       "      <th>hour</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_71</td>\n",
       "      <td>pen12</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:07:00</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:08:26.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_7</td>\n",
       "      <td>pen11</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:08:12</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:12:16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_10</td>\n",
       "      <td>pen11</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:19:19</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:20:27.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HenID  PenID   system    Zone  model_prediction           Timestamp  \\\n",
       "0  hen_71  pen12  10 - 12  3_Zone               1.0 2020-09-29 09:07:00   \n",
       "1   hen_7  pen11  10 - 12  3_Zone               1.0 2020-09-29 09:08:12   \n",
       "2  hen_10  pen11  10 - 12  3_Zone               1.0 2020-09-29 09:19:19   \n",
       "\n",
       "        date         next_record_date previous_record_date previous_duration  \\\n",
       "0 2020-09-29  2020-09-29 09:08:26.000                  NaN               NaN   \n",
       "1 2020-09-29  2020-09-29 09:12:16.000                  NaN               NaN   \n",
       "2 2020-09-29  2020-09-29 09:20:27.000                  NaN               NaN   \n",
       "\n",
       "  next_zone previous_zone previous_previous_zone  \\\n",
       "0    3_Zone           NaN                    NaN   \n",
       "1    3_Zone           NaN                    NaN   \n",
       "2    3_Zone           NaN                    NaN   \n",
       "\n",
       "   correction_is_consecutive_equal_initial_zone  is_WG_open  hour      time  \n",
       "0                                         False       False     9  09:07:00  \n",
       "1                                         False       False     9  09:08:00  \n",
       "2                                         False       False     9  09:19:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned data of the tracking system movements\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp', 'date'], dayfirst=True) \n",
    "df = df[df['Timestamp']<=max_date_adaptability+dt.timedelta(days=2)] #add two days to have the next observations as well when doing the 1sec ts\n",
    "df['hour'] = df['Timestamp'].map(lambda x: x.hour)\n",
    "df['time'] = df['Timestamp'].map(lambda x: dt.datetime.time(x-dt.timedelta(seconds=x.second)))\n",
    "df = df[df['HenID'].isin(li_selected_hens)] \n",
    "df.drop('duration', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>R-Pen</th>\n",
       "      <th>InitialStartDate</th>\n",
       "      <th>29-09 weight</th>\n",
       "      <th>10-12 juin weight</th>\n",
       "      <th>weight 23-11-2020</th>\n",
       "      <th>weight 04-01-2021</th>\n",
       "      <th>weight 01-02-21</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>percentage_of_gain_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>9</td>\n",
       "      <td>EPI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1696.5</td>\n",
       "      <td>1787.8</td>\n",
       "      <td>1800.9</td>\n",
       "      <td>OFH</td>\n",
       "      <td>49.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_10</td>\n",
       "      <td>11</td>\n",
       "      <td>LEXP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1488.3</td>\n",
       "      <td>1628.4</td>\n",
       "      <td>1602.1</td>\n",
       "      <td>OFH</td>\n",
       "      <td>39.093458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hen_101</td>\n",
       "      <td>5</td>\n",
       "      <td>MEXP</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1625.7</td>\n",
       "      <td>1751.1</td>\n",
       "      <td>1723.4</td>\n",
       "      <td>OFH</td>\n",
       "      <td>50.249538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID  PenID CLASS  R-Pen InitialStartDate  29-09 weight  \\\n",
       "0    hen_1      9   EPI    1.0       2020-06-10        1134.0   \n",
       "1   hen_10     11  LEXP    1.0       2020-06-10        1070.0   \n",
       "3  hen_101      5  MEXP    3.0       2020-06-10        1082.0   \n",
       "\n",
       "   10-12 juin weight  weight 23-11-2020  weight 04-01-2021  weight 01-02-21  \\\n",
       "0               57.0             1696.5             1787.8           1800.9   \n",
       "1               70.4             1488.3             1628.4           1602.1   \n",
       "3               66.0             1625.7             1751.1           1723.4   \n",
       "\n",
       "  Treatment  percentage_of_gain_weight  \n",
       "0       OFH                  49.603175  \n",
       "1       OFH                  39.093458  \n",
       "3       OFH                  50.249538  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#focal birds info (one row per bird)\n",
    "df_FB = pd.read_csv(os.path.join(path_extracted_data,id_run+'df_FOCALBIRDS.csv'), sep=';', parse_dates=['InitialStartDate'],\n",
    "                     dayfirst=True) \n",
    "df_FB = df_FB[df_FB['HenID'].isin(li_selected_hens)]\n",
    "df_FB['percentage_of_gain_weight'] = df_FB.apply(lambda x: (x['weight 23-11-2020']-x['29-09 weight'])/x['29-09 weight']*100, axis=1)\n",
    "print(df_FB.shape)\n",
    "df_FB.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute differences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that the main difference with the 1_Treatment&ClassAdaptability_computation is that here we want to compute within any pen, not only between two birds from the same pen. Thus we do it separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#intersection of two list\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "lst1 = [15, 9, 10, 56, 23, 78, 5, 4, 9] \n",
    "lst2 = [9, 4, 5, 36, 47, 26, 10, 45, 87] \n",
    "print(intersection(lst1, lst2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute MLPS vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 9, 30, 0, 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing time series...\n",
      "in this time series there is 132 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:07:00, and the ending date will be: 2020-11-22 22:44:55\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:07:00, and the ending date will be: 2020-11-22 23:59:59\n",
      "Total running time: 1.15 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract bined-zone-ts of MLP & overall-duration/zone-ts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [56:35<00:00, 679.19s/it]\n"
     ]
    }
   ],
   "source": [
    "#for efficiency purpose let's compute the bined time series first\n",
    "#note that we will have more entries than needed, as the distrubances days are not removed in the raw-cleaned movements\n",
    "#dataframe.\n",
    "dico_bin_zone_level_h = {} \n",
    "dico_bin_level_h = {}\n",
    "dmin = dt.datetime(2020,9,30)\n",
    "dmax = dt.datetime(2020,11,22)\n",
    "\n",
    "print('computing time series...')\n",
    "df_ts = time_series_henColumn_tsRow(df[(df['date']<=dmax)&(df['HenID'].isin(li_selected_hens))], \n",
    "                                    config, col_ts='Zone', ts_with_all_hen_value=False, save=False,  hen_time_series=False)\n",
    "df_ts = df_ts[df_ts['date']>=dmin]\n",
    "def duration_normalized_perZone(x):\n",
    "    c = Counter(x)\n",
    "    t = len(x)\n",
    "    return [c['1_Zone']/t, c['2_Zone']/t, c['3_Zone']/t, c['4_Zone']/t, c['5_Zone']/t]\n",
    "#small example\n",
    "#li = ['1_Zone','3_Zone','3_Zone','4_Zone','5_Zone','5_Zone','1_Zone']\n",
    "#duration_normalized_perZone(li)\n",
    "\n",
    "print('Extract bined-zone-ts of MLP & overall-duration/zone-ts...')\n",
    "for nbr_binmn in tqdm.tqdm(li_binmn):\n",
    "    \n",
    "    #update results\n",
    "    dico_bin_zone_level_h[nbr_binmn] = {}\n",
    "    dico_bin_level_h[nbr_binmn] = {}\n",
    "    \n",
    "    #reduce to the interval we want\n",
    "    mi = min(df_ts['Timestamp'].tolist())\n",
    "    ma = max(df_ts['Timestamp'].tolist())\n",
    "    #extend the end to the end of the day in case it case the last day available fo the chicken\n",
    "    Daterange = pd.date_range(start = mi, end = ma, freq = str(nbr_binmn)+'MIN')    \n",
    "    df_date = pd.DataFrame({str(nbr_binmn)+'mn_timestamp':Daterange})\n",
    "    new_timestamp = str(nbr_binmn)+'mn_timestamp'\n",
    "    df_date[new_timestamp] = df_date[new_timestamp].map(lambda x: pd.to_datetime(x))\n",
    "    df_ts_ = pd.merge_asof(df_ts, df_date, left_on=['Timestamp'], right_on=[new_timestamp], direction='forward')\n",
    "    #groupby the interval that we want with the number of minutes in nestbox\n",
    "    li_hen = [v for v in df_ts.columns if 'hen_' in v]\n",
    "    \n",
    "    ################# overall mlp #################\n",
    "    dico_bin_level_h[nbr_binmn] = {}\n",
    "    df_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: duration_normalized_perZone(x)).reset_index()\n",
    "    df_sim['date'] = df_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "    #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "    df_sim = df_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "    #print(df_zone_sim.shape)\n",
    "    #display(df_zone_sim.head(3))\n",
    "\n",
    "    #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "    df_sim_ = pd.melt(df_sim, id_vars=['date'], value_vars=li_hen)\n",
    "    #variable column has the henIDs\n",
    "    #print(df_zone_sim_.shape)\n",
    "    #display(df_zone_sim_.head(3))\n",
    "    for d, df__ in df_sim_.groupby(['date']):\n",
    "        #update results\n",
    "        dico_bin_level_h[nbr_binmn][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))   \n",
    "        \n",
    "    ################# zone-ts over each zone #################\n",
    "    for ZONE in df['Zone'].unique():\n",
    "\n",
    "        #update results\n",
    "        dico_bin_zone_level_h[nbr_binmn][ZONE] = {}\n",
    "\n",
    "        df_zone_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: sum([i==ZONE for i in x])/60).reset_index()\n",
    "        df_zone_sim['date'] = df_zone_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "\n",
    "        #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "        df_zone_sim = df_zone_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "        #print(df_zone_sim.shape)\n",
    "        #display(df_zone_sim.head(3))\n",
    "\n",
    "        #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "        df_zone_sim_ = pd.melt(df_zone_sim, id_vars=['date'], value_vars=li_hen)\n",
    "        #variable column has the henIDs\n",
    "        #print(df_zone_sim_.shape)\n",
    "        #display(df_zone_sim_.head(3))\n",
    "        for d, df__ in df_zone_sim_.groupby(['date']):\n",
    "            #update results\n",
    "            dico_bin_zone_level_h[nbr_binmn][ZONE][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))\n",
    "#save dictionaries\n",
    "pickle.dump(dico_bin_zone_level_h, open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                 id_run+'dico_bin_zone_level_h_SAMEDAYS.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(dico_bin_level_h, open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                 id_run+'dico_bin_level_h_SAMEDAYS.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5mn_timestamp</th>\n",
       "      <th>hen_1</th>\n",
       "      <th>hen_10</th>\n",
       "      <th>hen_101</th>\n",
       "      <th>hen_102</th>\n",
       "      <th>hen_103</th>\n",
       "      <th>hen_104</th>\n",
       "      <th>hen_105</th>\n",
       "      <th>hen_106</th>\n",
       "      <th>hen_107</th>\n",
       "      <th>...</th>\n",
       "      <th>hen_9</th>\n",
       "      <th>hen_90</th>\n",
       "      <th>hen_91</th>\n",
       "      <th>hen_92</th>\n",
       "      <th>hen_94</th>\n",
       "      <th>hen_95</th>\n",
       "      <th>hen_96</th>\n",
       "      <th>hen_97</th>\n",
       "      <th>hen_98</th>\n",
       "      <th>hen_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30 00:00:00</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-30 00:05:00</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-30 00:10:00</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-30 00:15:00</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-30 00:20:00</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15547</th>\n",
       "      <td>2020-11-22 23:35:00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15548</th>\n",
       "      <td>2020-11-22 23:40:00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>2020-11-22 23:45:00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>2020-11-22 23:50:00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>2020-11-22 23:55:00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15552 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            5mn_timestamp                      hen_1  \\\n",
       "0     2020-09-30 00:00:00  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "1     2020-09-30 00:05:00  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "2     2020-09-30 00:10:00  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3     2020-09-30 00:15:00  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "4     2020-09-30 00:20:00  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "...                   ...                        ...   \n",
       "15547 2020-11-22 23:35:00  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548 2020-11-22 23:40:00  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549 2020-11-22 23:45:00  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550 2020-11-22 23:50:00  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551 2020-11-22 23:55:00  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                          hen_10                    hen_101  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "15548  [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "15549  [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "15550  [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "15551  [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "\n",
       "                         hen_102                    hen_103  \\\n",
       "0      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "4      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                         hen_104                    hen_105  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                         hen_106                    hen_107  ...  \\\n",
       "0      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]  ...   \n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]  ...   \n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]  ...   \n",
       "3      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]  ...   \n",
       "4      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]  ...   \n",
       "...                          ...                        ...  ...   \n",
       "15547  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  ...   \n",
       "15548  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  ...   \n",
       "15549  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  ...   \n",
       "15550  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  ...   \n",
       "15551  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  ...   \n",
       "\n",
       "                           hen_9                     hen_90  \\\n",
       "0      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "4      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                          hen_91                     hen_92  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "15548  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "15549  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "15550  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "15551  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "\n",
       "                          hen_94                     hen_95  \\\n",
       "0      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "3      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "4      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                          hen_96                     hen_97  \\\n",
       "0      [0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "3      [0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "4      [0.0, 0.0, 0.0, 0.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "...                          ...                        ...   \n",
       "15547  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15548  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15549  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15550  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "15551  [0.0, 0.0, 0.0, 0.0, 1.0]  [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                          hen_98                     hen_99  \n",
       "0      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "1      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "2      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "3      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "4      [0.0, 0.0, 1.0, 0.0, 0.0]  [0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "...                          ...                        ...  \n",
       "15547  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "15548  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "15549  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "15550  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "15551  [0.0, 0.0, 0.0, 1.0, 0.0]  [0.0, 0.0, 0.0, 0.0, 1.0]  \n",
       "\n",
       "[15552 rows x 133 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTEST = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: duration_normalized_perZone(x)).reset_index()\n",
    "dfTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#simply download it if already computed\n",
    "dico_bin_zone_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                 id_run+'dico_bin_zone_level_h_SAMEDAYS.pkl'), 'rb'))\n",
    "dico_bin_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap,id_run+'dico_bin_level_h_SAMEDAYS.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the distance across pairs of MLPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ALL HENS ONLY CHI2\n",
    "#compute the chi2-distance & DTW for each bird with all other birds (because we need this exact same pair to do the visual)\n",
    "random.seed(rv)\n",
    "#for efficiency and testing select a subset of animals to be 50 hens, but later we dontn want to restrcit to the pen nor the\n",
    "#number of animals\n",
    "nbr_hens = 60\n",
    "#randomly pick more than one element from the list without repeating elements.\n",
    "#li_selected_hens_rv = random.sample(li_selected_hens, nbr_hens)\n",
    "li_df = []\n",
    "li_zone = df['Zone'].unique()\n",
    "df.sort_values(['Timestamp'], inplace=True)\n",
    "li_date = set(df_daily['level'].tolist())\n",
    "df_doa = df_daily[['level','DOA','WOA']].drop_duplicates()\n",
    "df_doa.head(3)\n",
    "df_daily_h = df_daily[df_daily['HenID'].isin(li_selected_hens)].copy()\n",
    "for d1 in tqdm.tqdm(sorted(list(li_date))):\n",
    "    doa = df_doa[df_doa['level']==d1]['DOA'].values[0]\n",
    "    woa = df_doa[df_doa['level']==d1]['WOA'].values[0]\n",
    "    li_hen_d1 = df_daily_h[df_daily_h['level']==d1]['HenID'].unique()\n",
    "    #its a symmetric measure, so we only do each combination once\n",
    "    for i,h1 in enumerate(li_hen_d1):\n",
    "\n",
    "        #for each hen we want to compute its difference with all other birds \n",
    "        for h2 in li_hen_d1[i+1:]:\n",
    "            \n",
    "            ############ Overall aviary usage similarity across days\n",
    "            l1_chi2 = df_daily_h[(df_daily_h['HenID']==h1)&(df_daily_h['level']==d1)]['dur_values_normalized'].values[0]\n",
    "            l2_chi2 = df_daily_h[(df_daily_h['HenID']==h2)&(df_daily_h['level']==d1)]['dur_values_normalized'].values[0]\n",
    "\n",
    "            dico_ = {'level':d1, 'level+1':d1, 'henID1':h1, 'henID2':h2, \n",
    "                     'dur_values_normalized_henID1':l1_chi2,'dur_values_normalized_henID2':l2_chi2,\n",
    "                     'chi2distance':chi2_distance(l1_chi2,l2_chi2),'DOA':doa,'WOA':woa}\n",
    "            li_df.append(dico_)\n",
    "\n",
    "#turn inter and intra distances into a dataframe                \n",
    "df_interintra = pd.DataFrame(li_df)\n",
    "#df_interintra = df_interintra[~df_interintra['chi2distance'].isnull()]\n",
    "df_interintra = df_interintra.sort_values('DOA', ascending=True)\n",
    "df_interintra['weeks_in_laying_barn'] = df_interintra['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_interintra['DTW_15_all'] = df_interintra[['DTW_15_1_Zone', 'DTW_15_2_Zone', 'DTW_15_3_Zone','DTW_15_4_Zone','DTW_15_5_Zone']].sum(axis=1)\n",
    "df_interintra.to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+str(rv)+'_df_interintra_SAMEDAY_ALLCHI2.csv'), sep=';', index=False)\n",
    "print(df_interintra.shape)\n",
    "display(df_interintra.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hen_96' in [h for h in li_selected_hens if h!='hen_96']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "  0%|                                                                                           | 0/29 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-8e7885b3bd28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m                         \u001b[1;31m#compute distance measure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[1;31m#psi: #of start and end points of a sequence can be ignored if this would lead to a lower distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                         \u001b[0mdtw_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarping_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1_dtw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_dtw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdico_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnbr_binmn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, max_step=0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dtaidistance\\dtw.py\u001b[0m in \u001b[0;36mwarping_paths\u001b[1;34m(s1, s2, window, max_dist, max_step, max_length_diff, penalty, psi)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpsi\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mpsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mdtw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m     \u001b[1;31m# dtw[0, 0] = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopyto\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#compute the CHI2DISTANCE & DTW for each bird with all other birds (because we need this exact same pair to do the visual)\n",
    "random.seed(rv)\n",
    "#for efficiency and testing select a subset of animals to be 50 hens, but later we dontn want to restrcit to the pen nor the\n",
    "#number of animals\n",
    "nbr_hens = 70\n",
    "#randomly pick more than one element from the list without repeating elements.\n",
    "#for simplicity we will remove hen_96 as not here on the first day and we are not using all hens\n",
    "li_selected_hens_rv = random.sample([h for h in li_selected_hens if h!='hen_96'], nbr_hens)\n",
    "li_df = []\n",
    "li_zone = df['Zone'].unique()\n",
    "df.sort_values(['Timestamp'], inplace=True)\n",
    "df_daily_h = df_daily[df_daily['DOA']<=119+30].copy()\n",
    "li_date = set(df_daily_h['level'].tolist())\n",
    "df_doa = df_daily[['level','DOA','WOA']].drop_duplicates()\n",
    "df_doa.head(3)\n",
    "df_daily_h = df_daily_h[df_daily_h['HenID'].isin(li_selected_hens_rv)].copy()\n",
    "\n",
    "for d1 in tqdm.tqdm(sorted(list(li_date))):\n",
    "    doa = df_doa[df_doa['level']==d1]['DOA'].values[0]\n",
    "    woa = df_doa[df_doa['level']==d1]['WOA'].values[0]\n",
    "    li_hen_d1 = df_daily_h[df_daily_h['level']==d1]['HenID'].unique()\n",
    "    #its a symmetric measure, so we only do each combination once\n",
    "    for i,h1 in enumerate(li_hen_d1):\n",
    "\n",
    "        #for each hen we want to compute its difference with all other birds \n",
    "        for h2 in li_hen_d1[i+1:]:\n",
    "            \n",
    "            ############ Overall aviary usage similarity across days\n",
    "            l1_chi2 = df_daily_h[(df_daily_h['HenID']==h1)&(df_daily_h['level']==d1)]['dur_values_normalized'].values[0]\n",
    "            l2_chi2 = df_daily_h[(df_daily_h['HenID']==h2)&(df_daily_h['level']==d1)]['dur_values_normalized'].values[0]\n",
    "\n",
    "            dico_ = {'level':d1, 'level+1':d1, 'henID1':h1, 'henID2':h2, \n",
    "                     'dur_values_normalized_henID1':l1_chi2,'dur_values_normalized_henID2':l2_chi2,\n",
    "                     'chi2distance':chi2_distance(l1_chi2,l2_chi2),'DOA':doa,'WOA':woa}\n",
    "\n",
    "            ############# Specifics' zones usage similarity across days\n",
    "            for nbr_binmn in li_binmn:\n",
    "                #ALL zone together with chi2distance\n",
    "                l1_chi2 = dico_bin_level_h[nbr_binmn][d1][h1]\n",
    "                l2_chi2 = dico_bin_level_h[nbr_binmn][d1][h2]\n",
    "                dico_['nbr_obs_chi2all_'+str(nbr_binmn)] = len(l1_chi2)\n",
    "                li_chi2 = [chi2_distance(l1_chi2[i],l2_chi2[i]) for i in range(0,len(l1_chi2))]\n",
    "                dico_['li_chi2_'+str(nbr_binmn)] = li_chi2\n",
    "                dico_['chi2distance_ALL_'+str(nbr_binmn)] = sum(li_chi2)\n",
    "                \n",
    "                #per zone with DTW\n",
    "                for ZONE in li_zone:\n",
    "                    dtw_value = np.nan\n",
    "                    try:\n",
    "                        l1_dtw = np.array(dico_bin_zone_level_h[nbr_binmn][ZONE][d1][h1], dtype=np.double)\n",
    "                        l2_dtw = np.array(dico_bin_zone_level_h[nbr_binmn][ZONE][d1][h2], dtype=np.double)\n",
    "                        #compute distance measure\n",
    "                        #psi: #of start and end points of a sequence can be ignored if this would lead to a lower distance\n",
    "                        dtw_value, paths = dtw.warping_paths(l1_dtw, l2_dtw, window=dico_window[nbr_binmn], psi=0, penalty=penalty) #, max_step=0\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        sys.exit()\n",
    "                        pass #dont do anything\n",
    "                    dico_['DTW_'+str(nbr_binmn)+'_'+ZONE] = round(dtw_value,1)  \n",
    "                    dico_['nbr_obs_l1_'+str(nbr_binmn)+'_'+ZONE] = len(l1_dtw)\n",
    "                    dico_['nbr_obs_l2_'+str(nbr_binmn)+'_'+ZONE] = len(l2_dtw)\n",
    "            li_df.append(dico_)\n",
    "\n",
    "#turn inter and intra distances into a dataframe                \n",
    "df_interintra = pd.DataFrame(li_df)\n",
    "#df_interintra = df_interintra[~df_interintra['chi2distance'].isnull()]\n",
    "df_interintra = df_interintra.sort_values('DOA', ascending=True)\n",
    "df_interintra['weeks_in_laying_barn'] = df_interintra['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_interintra['DTW_15_all'] = df_interintra[['DTW_15_1_Zone', 'DTW_15_2_Zone', 'DTW_15_3_Zone','DTW_15_4_Zone','DTW_15_5_Zone']].sum(axis=1)\n",
    "df_interintra.to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+str(rv)+'_df_interintra_SAMEDAY_ALL.csv'), sep=';', index=False)\n",
    "print(df_interintra.shape)\n",
    "display(df_interintra.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the similarity between two individuals over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_interintra['chi2distance']);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "consistent similarites across hens : types of routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59890, 87)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level+1</th>\n",
       "      <th>henID1</th>\n",
       "      <th>henID2</th>\n",
       "      <th>dur_values_normalized_henID1</th>\n",
       "      <th>dur_values_normalized_henID2</th>\n",
       "      <th>chi2distance</th>\n",
       "      <th>DOA</th>\n",
       "      <th>WOA</th>\n",
       "      <th>DTW_5_3_Zone</th>\n",
       "      <th>...</th>\n",
       "      <th>nbr_obs_l2_30_5_Zone</th>\n",
       "      <th>DTW_30_4_Zone</th>\n",
       "      <th>nbr_obs_l1_30_4_Zone</th>\n",
       "      <th>nbr_obs_l2_30_4_Zone</th>\n",
       "      <th>DTW_30_1_Zone</th>\n",
       "      <th>nbr_obs_l1_30_1_Zone</th>\n",
       "      <th>nbr_obs_l2_30_1_Zone</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "      <th>DTW_15_all</th>\n",
       "      <th>hen_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>hen_1</td>\n",
       "      <td>hen_10</td>\n",
       "      <td>[0.0, 0.6557638888888889, 0.12111111111111111,...</td>\n",
       "      <td>[0.0, 0.40243055555555557, 0.5327083333333333,...</td>\n",
       "      <td>0.233889</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "      <td>52.6</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>15.3</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>239.4</td>\n",
       "      <td>hen_1-hen_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>hen_21</td>\n",
       "      <td>hen_88</td>\n",
       "      <td>[0.0, 0.4275, 0.25274305555555554, 0.0, 0.3197...</td>\n",
       "      <td>[0.0, 0.0, 0.1578125, 0.01628472222222222, 0.8...</td>\n",
       "      <td>0.344674</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7.8</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>181.7</td>\n",
       "      <td>hen_21-hen_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>hen_21</td>\n",
       "      <td>hen_89</td>\n",
       "      <td>[0.0, 0.4275, 0.25274305555555554, 0.0, 0.3197...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.515431</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>194.8</td>\n",
       "      <td>hen_21-hen_89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        level     level+1  henID1  henID2  \\\n",
       "0  2020-09-30  2020-09-30   hen_1  hen_10   \n",
       "1  2020-09-30  2020-09-30  hen_21  hen_88   \n",
       "2  2020-09-30  2020-09-30  hen_21  hen_89   \n",
       "\n",
       "                        dur_values_normalized_henID1  \\\n",
       "0  [0.0, 0.6557638888888889, 0.12111111111111111,...   \n",
       "1  [0.0, 0.4275, 0.25274305555555554, 0.0, 0.3197...   \n",
       "2  [0.0, 0.4275, 0.25274305555555554, 0.0, 0.3197...   \n",
       "\n",
       "                        dur_values_normalized_henID2  chi2distance  DOA  WOA  \\\n",
       "0  [0.0, 0.40243055555555557, 0.5327083333333333,...      0.233889  119   17   \n",
       "1  [0.0, 0.0, 0.1578125, 0.01628472222222222, 0.8...      0.344674  119   17   \n",
       "2                          [0.0, 0.0, 0.0, 0.0, 1.0]      0.515431  119   17   \n",
       "\n",
       "   DTW_5_3_Zone  ...  nbr_obs_l2_30_5_Zone  DTW_30_4_Zone  \\\n",
       "0          52.6  ...                    44           15.3   \n",
       "1          34.8  ...                    44            7.8   \n",
       "2          30.9  ...                    44            0.0   \n",
       "\n",
       "   nbr_obs_l1_30_4_Zone  nbr_obs_l2_30_4_Zone  DTW_30_1_Zone  \\\n",
       "0                    44                    44            0.0   \n",
       "1                    44                    44            0.0   \n",
       "2                    44                    44            0.0   \n",
       "\n",
       "   nbr_obs_l1_30_1_Zone  nbr_obs_l2_30_1_Zone  weeks_in_laying_barn  \\\n",
       "0                    44                    44                     1   \n",
       "1                    44                    44                     1   \n",
       "2                    44                    44                     1   \n",
       "\n",
       "   DTW_15_all       hen_pair  \n",
       "0       239.4   hen_1-hen_10  \n",
       "1       181.7  hen_21-hen_88  \n",
       "2       194.8  hen_21-hen_89  \n",
       "\n",
       "[3 rows x 87 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interintra = pd.read_csv(os.path.join(path_extracted_data_visual_adap, id_run+str(rv)+'_df_interintra_SAMEDAY_ALL.csv'), \n",
    "                            sep=';') \n",
    "print(df_interintra.shape)\n",
    "df_interintra.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "li_dist = ['chi2distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2415, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>DOA</th>\n",
       "      <th>hen_pair</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>129</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1-hen_10</td>\n",
       "      <td>0.233889</td>\n",
       "      <td>0.322369</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.618510</td>\n",
       "      <td>0.542879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.211068</td>\n",
       "      <td>0.172145</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.326435</td>\n",
       "      <td>0.530965</td>\n",
       "      <td>0.180796</td>\n",
       "      <td>0.283903</td>\n",
       "      <td>0.209466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1-hen_106</td>\n",
       "      <td>0.127232</td>\n",
       "      <td>0.431147</td>\n",
       "      <td>0.970045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103968</td>\n",
       "      <td>0.161584</td>\n",
       "      <td>0.533122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166779</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.504362</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.499636</td>\n",
       "      <td>0.484103</td>\n",
       "      <td>0.465004</td>\n",
       "      <td>0.268076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1-hen_107</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.486301</td>\n",
       "      <td>0.976684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540559</td>\n",
       "      <td>0.951906</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.056286</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.098733</td>\n",
       "      <td>0.054507</td>\n",
       "      <td>0.337689</td>\n",
       "      <td>0.476191</td>\n",
       "      <td>0.332984</td>\n",
       "      <td>0.298625</td>\n",
       "      <td>0.251993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "DOA       hen_pair       119       120       121  122  123  124       125  \\\n",
       "0     hen_1-hen_10  0.233889  0.322369  0.008576  NaN  NaN  NaN  0.004816   \n",
       "1    hen_1-hen_106  0.127232  0.431147  0.970045  NaN  NaN  NaN  0.103968   \n",
       "2    hen_1-hen_107  0.019990  0.486301  0.976684  NaN  NaN  NaN  0.540559   \n",
       "\n",
       "DOA       126       129  ...       140       141       142       143  \\\n",
       "0    0.618510  0.542879  ...  0.000000  0.032912  0.211068  0.172145   \n",
       "1    0.161584  0.533122  ...  0.076409       NaN  0.166779  0.194591   \n",
       "2    0.951906  0.999611  ...  0.003599  0.056286  0.104309  0.098733   \n",
       "\n",
       "DOA       144       145       146       147       148       149  \n",
       "0    0.091667  0.326435  0.530965  0.180796  0.283903  0.209466  \n",
       "1    0.504362  0.400006  0.499636  0.484103  0.465004  0.268076  \n",
       "2    0.054507  0.337689  0.476191  0.332984  0.298625  0.251993  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:15, 12.83s/it]"
     ]
    }
   ],
   "source": [
    "#with regression line\n",
    "for V in li_dist:\n",
    "    \n",
    "    df_pair = df_interintra.pivot(index='hen_pair', columns='DOA', values=V).reset_index()\n",
    "    print(df_pair.shape)\n",
    "    display(df_pair.head(3))\n",
    "\n",
    "    li_DOA = list(range(119,max(df_interintra['DOA'].tolist())+1))\n",
    "    li_DOA = list(range(119,119+18))\n",
    "    col_ = len(li_DOA)\n",
    "    lign_ = len(li_DOA)\n",
    "    fig = plt.figure(figsize=(3*lign_, 3*col_))\n",
    "    i = 1\n",
    "    #enumerate across x\n",
    "    for k1,D1 in tqdm.tqdm(enumerate(li_DOA)):\n",
    "        #enumerate across y\n",
    "        for k2,D2 in enumerate(li_DOA):\n",
    "\n",
    "            if k2<=k1:\n",
    "                plt.subplot(lign_,col_,i)\n",
    "                plt.tight_layout()\n",
    "                i = i+1\n",
    "                plt.xticks([]) #remove xlabel annotations\n",
    "                plt.yticks([])\n",
    "                plt.axis('off');\n",
    "            else:\n",
    "                #initialize subplot\n",
    "                plt.subplot(lign_,col_,i)\n",
    "                plt.tight_layout()\n",
    "                i = i+1\n",
    "                plt.xticks([]) #remove xlabel annotations\n",
    "                plt.yticks([])\n",
    "                plt.axis('off');\n",
    "\n",
    "                #data\n",
    "                if (D1 in df_pair.columns) & (D2 in df_pair.columns) :\n",
    "                    df_ = df_pair[[D1,D2]]\n",
    "                    df_ = df_[~(df_.isnull().any(axis=1))]\n",
    "                    x = np.array(df_[D1].tolist())\n",
    "                    y = np.array(df_[D2].tolist())\n",
    "                    #if at least 10 observations\n",
    "                    if (len(x)>0) & (len(x)==len(y)):\n",
    "                        #measures\n",
    "                        Explvarscore = explained_variance_score(x, y)\n",
    "                        RMSE = math.sqrt(mean_squared_error(x, y))\n",
    "                        MAE = mean_absolute_error(x, y)\n",
    "                        #Spearman rank-order correlation coefficient is a nonparametric measure of the monotonicity of the relationship between two datasets\n",
    "                        #rcoeff2, p_value2 = pearsonr(x, y)\n",
    "                        rcoeff2, p_value2 = spearmanr(x, y)\n",
    "\n",
    "                        #linear model & it's the 95% CI\n",
    "                        slope, intercept = np.polyfit(x, y, 1) #degree=1: fit a linear model\n",
    "                        #TODO: check assumption??? or not as not really using it besides visual?\n",
    "                        y_model = np.polyval([slope, intercept], x) #evaluate the y_pred by the model\n",
    "                        x_mean = np.mean(x) ; y_mean = np.mean(y)\n",
    "                        n = x.size                        # number of samples\n",
    "                        dof = n - 2                       # degrees of freedom: size-#parameters\n",
    "                        t_ = stats.t.ppf(0.975, dof)       # Students statistic of interval confidence\n",
    "                        residual = y - y_model\n",
    "\n",
    "                        ############### Plot\n",
    "                        plt.rcParams.update({'font.size': 11})\n",
    "\n",
    "                        #plot middle line and 95% IC\n",
    "                        x_line = np.linspace(np.min(x), np.max(x), 100)\n",
    "                        y_line = np.polyval([slope, intercept], x_line)\n",
    "                        # confidence interval\n",
    "                        std_error = (np.sum(residual**2) / dof)**.5   # Standard deviation of the error\n",
    "                        ci = t_ * std_error * (1/n + (x_line - x_mean)**2 / np.sum((x - x_mean)**2))**.5\n",
    "                        plt.plot(x_line, y_line, color='black', linewidth=5)\n",
    "                        #ax.fill_between(x_line, y_line + ci, y_line - ci, alpha=0.5, color='black') #label = '95% confidence interval', \n",
    "                        plt.xlim(0,1)\n",
    "                        plt.ylim(0,1)\n",
    "                        #add text\n",
    "                        #plt.set_xlabel(D1)\n",
    "                        #plt.set_ylabel(D2)\n",
    "                        #ax.text(0, max(y)-int(0.12*max(y))+epsi, 'Explained variance score = ' + str(np.round(Explvarscore,2)))\n",
    "                        #ax.text(0, max(y)-int(0.24*max(y))+epsi, 'RMSE = ' + str(np.round(RMSE,2)) +\\\n",
    "                        #                                    '     MAE = ' + str(np.round(MAE,2)))\n",
    "                        plt.text(0.03, 0.9-int(0.36*0.9), 'spearmanr coef = ' + str(np.round(rcoeff2,2)))\n",
    "                        plt.text(0.03, 0.8-int(0.36*0.8), 'spearmanr p-value = ' + str(np.round(p_value2,3)))\n",
    "\n",
    "                        #plot points if less or equal to 20 days\n",
    "                        if len(li_DOA)<=20:\n",
    "                            #plot points with size equal to the amount of points (as count data)\n",
    "                            # count the occurrences of each point\n",
    "                            c = Counter(zip(x,y))\n",
    "                            # create a list of the sizes, here multiplied by 10 for scale\n",
    "                            s = [0.35*c[(xx,yy)] for xx,yy in zip(x,y)]\n",
    "                            if p_value2<0.001:\n",
    "                                plt.scatter(x, y, s=s, color='red') \n",
    "                            elif p_value2<0.01:\n",
    "                                plt.scatter(x, y, s=s, color='orange') \n",
    "                            elif p_value2<0.05:\n",
    "                                plt.scatter(x, y, s=s, color='yellow') \n",
    "                            elif p_value2>0.01:\n",
    "                                plt.scatter(x, y, s=s, color='blue') \n",
    "                            else:\n",
    "                                plt.scatter(x, y, s=s, color='green')\n",
    "                            #plt.legend(bbox_to_anchor=(1, .25), fontsize=12);\n",
    "\n",
    "                            #add diagonal line\n",
    "                            #ax.axline((0, 0), slope=1, c=\"black\", ls=\"--\", zorder=0)\n",
    "                        plt.title('x: '+str(D1)+'  y: '+str(D2))\n",
    "    #save\n",
    "    plt.savefig(os.path.join(path_extracted_data_visual_adap, 'HensSimilaritiesAcrosstime_'+V+'_'+str(col_)+'.png'), dpi=400, \n",
    "                bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
