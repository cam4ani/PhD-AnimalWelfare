{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.0, the latest is 0.2.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.3.8, the latest is 0.4.0.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from scipy import stats\n",
    "import random\n",
    "import pickle\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "#repeated measures correlation\n",
    "import pingouin as pg\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "#plot\n",
    "import joypy # for ridgeplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import kmeans_clustering, sampen, chi2_distance, ts_visual, correct_key, chi2_distance, most_frequent, mssd\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALLDATA_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "path_extracted_data = config.path_extracted_data\n",
    "id_run = config.id_run\n",
    "path_extracted_data_adap = os.path.join(path_extracted_data,'Adaptability')\n",
    "print(id_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download estimates - Individuality plasticity, intercept, variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#download ind.plasticity over time\n",
    "df_pred = pd.read_csv(os.path.join(path_extracted_data_adap,'IndividualPredictability.csv'), sep=',')\n",
    "print(df_pred.shape)\n",
    "display(df_pred.head(3))\n",
    "print(list(df_pred.columns))\n",
    "li_col = [x for x in df_pred.columns if 'r_HenID__sigma' in x]\n",
    "df_pred = df_pred[li_col]\n",
    "df_pred['run'] = df_pred.index\n",
    "df_pred = pd.melt(df_pred, id_vars=['run'], value_vars=li_col)\n",
    "df_pred['HenID'] = df_pred['variable'].map(lambda x: x.split('[')[1].split(',')[0])\n",
    "#\"Importantly, in order to assess whether individuals differ in variance the residual part of the model iscalculated on the log \n",
    "#scale! In order to interpret rIIV in biological terms we backtransform rIIV by takingit’s original scale by taking its exponent\"\n",
    "df_pred['Predictability'] = df_pred['value'].map(lambda x: np.exp(x))\n",
    "print(df_pred.shape)\n",
    "df_pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var.res = exp(posterior_samples(m3_brm)$\"sd_HenID__sigma_Intercept\")^2\n",
    "mean(var.res);HPDinterval(as.mcmc(var.res),0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download ind plasticity and intercepts\n",
    "df_BT = pd.read_csv(os.path.join(path_extracted_data_adap,'IndividualBehaviouralType.csv'), sep=',')\n",
    "print(df_BT.shape)\n",
    "df_BT.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download ind plasticity and intercepts\n",
    "df_ind = pd.read_csv(os.path.join(path_extracted_data_adap,'IndividualPlasticity.csv'), sep=',')\n",
    "display(df_ind['term'].unique())\n",
    "dico_ = {'(Intercept)':'BLUP_int', 'poly(cDIB, 2)1':'BLUP_slopes1', 'poly(cDIB, 2)2':'BLUP_slopes2'}\n",
    "df_ind['term'] = df_ind['term'].map(lambda x: dico_[x])\n",
    "print(df_ind.shape)\n",
    "print(df_ind['groupFctr'].unique(), df_ind['term'].unique())\n",
    "df_ind.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select individuals to highlight in visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 5 hens to highlight within the plot: two most extremes intercept (min, max), two most extreme plasticity (min, max) \n",
    "#and one?\n",
    "#Behaviroual type\n",
    "li = df_BT.sort_values('mean', ascending=True)['groupID'].tolist()\n",
    "li_int = [li[-1], li[0]]\n",
    "print(li_int)\n",
    "#Plasticity\n",
    "li = df_ind[df_ind['term']=='BLUP_slopes2'].sort_values('mean', ascending=True)['groupID'].tolist()\n",
    "li_plasticity = [li[-1], li[0]]\n",
    "print(li_plasticity)\n",
    "#predictability\n",
    "li = df_pred.groupby('HenID')['Predictability'].agg(lambda x: np.mean(x)).reset_index().sort_values('Predictability')['HenID'].tolist()\n",
    "li_pred = [li[-1], li[0]]\n",
    "print(li_pred)\n",
    "li_hen_visual = list(set(li_int+li_plasticity+li_pred))\n",
    "\n",
    "#add random ones s that total sum to 5\n",
    "#random.seed(0)\n",
    "#li_r = random.sample([x for x in df_ind['groupID'].unique() if x not in li_hen_visual], 5-len(li_hen_visual))\n",
    "#li_hen_visual = li_hen_visual + li_r\n",
    "print('selected hens: %s' %' '.join(li_hen_visual))\n",
    "#df_ind['HenID '] = df_ind['HenID'].map(lambda x: 'Others' if x not in li_hen_visual else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose color: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "li_nicecolor = ['lime','yellow','fuchsia','orange','cyan','blue','crimson','olive','orangered']\n",
    "li_all_hen =  df_ind['groupID'].unique()\n",
    "pal_ = {henID:'black' for henID in li_all_hen}\n",
    "pal_ = {'Other Hens':'black'}\n",
    "#pal_['hen_48:pen4'] = 'violet'\n",
    "#pal_['hen_47:pen12'] = 'fuchsia'\n",
    "#pal_['hen_69:pen8'] = 'cyan'\n",
    "#pal_['hen_57:pen10'] = 'blue'\n",
    "for i,henID in enumerate(li_hen_visual):\n",
    "    pal_[henID] = li_nicecolor[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behavioural type\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "df_plt = df_BT.sort_values(['mean'])\n",
    "df_plt[' '] = df_plt['groupID'].map(lambda x: x if x in li_hen_visual else 'Other Hens')\n",
    "df_plt['color'] = df_plt[' '].map(lambda x: pal_[x])\n",
    "#hue_order = li_hen_visual + ['Other Hens']\n",
    "ax = sns.boxplot(x='groupID', y='mean', data=df_plt, color='grey');\n",
    "ax.errorbar(df_plt['groupID'], df_plt['mean'], yerr=df_plt['sd'],fmt=' ', zorder=-1, alpha=0.5, \n",
    "            color=df_plt['color'].tolist());\n",
    "plt.xticks([]) #remove xlabel annotations\n",
    "plt.xlabel('HenID')\n",
    "plt.ylabel('Intercepts BLUP estimates');\n",
    "plt.axhline(y=0, linewidth=2, color = 'k')\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'estimatesintercepts.png'), bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plasticity\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "df_plt = df_ind[df_ind['term']=='BLUP_slopes2'].sort_values(['mean'])\n",
    "df_plt[' '] = df_plt['groupID'].map(lambda x: x if x in li_hen_visual else 'Other Hens')\n",
    "df_plt['color'] = df_plt[' '].map(lambda x: pal_[x])\n",
    "ax = sns.boxplot(x='groupID', y='mean', data=df_plt, color='grey');\n",
    "ax.errorbar(df_plt['groupID'], df_plt['mean'], yerr=df_plt['sd'],fmt=' ', zorder=-1, alpha=0.5, \n",
    "            color=df_plt['color'].tolist());\n",
    "plt.xticks([]) #remove xlabel annotations\n",
    "plt.xlabel('HenID')\n",
    "plt.ylabel('Slopes BLUP estimates');\n",
    "plt.axhline(y=0, linewidth=2, color = 'k')\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'estimatesplasticity.png'), bbox_inches='tight')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictability\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "df_pred_summarized = df_pred.groupby('HenID')['Predictability'].agg(lambda x: list(x)).reset_index()\n",
    "df_pred_summarized['Predictability_mean'] = df_pred_summarized['Predictability'].map(lambda x: np.mean(x))\n",
    "df_pred_summarized['Predictability_sd'] = df_pred_summarized['Predictability'].map(lambda x: np.std(x))\n",
    "display(df_pred_summarized.head(3))\n",
    "df_plt = df_pred_summarized.sort_values(['Predictability_mean']).copy()\n",
    "df_plt[' '] = df_plt['HenID'].map(lambda x: x if x in li_hen_visual else 'Other Hens')\n",
    "df_plt['color'] = df_plt[' '].map(lambda x: pal_[x])\n",
    "#hue_order = li_hen_visual + ['Other Hens']\n",
    "ax = sns.boxplot(x='HenID', y='Predictability_mean', data=df_plt, color='grey');\n",
    "ax.errorbar(df_plt['HenID'], df_plt['Predictability_mean'], yerr=df_plt['Predictability_sd'],fmt=' ', zorder=-1, alpha=0.5, \n",
    "            color=df_plt['color'].tolist());\n",
    "plt.xticks([]) #remove xlabel annotations\n",
    "plt.xlabel('HenID')\n",
    "plt.ylabel('Variability BLUP estimates');\n",
    "plt.axhline(y=0, linewidth=2, color = 'k')\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'estimatespredictability.png'), bbox_inches='tight')\n",
    "plt.show();\n",
    "display(df_pred_summarized[df_pred_summarized['HenID'].isin(li_hen_visual)])\n",
    "#hens with higher rIIV are less predictable than individualswith lower rIIV (Fig )\n",
    "#The most predictable individual (hen 39) has an average residual variance of 0.01 around its behavioral mean, whereas the \n",
    "#least predictable individual (hen 109) has an average residual variance of 0.27km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_all = {k.split(':')[0]:v for k,v in pal_.items()}\n",
    "hue_order_all=[h.split(':')[0] for h in li_hen_visual]+['Other Hens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download ind.plasticity over time\n",
    "df_PL = pd.read_csv(os.path.join(path_extracted_data_adap,'EstimatedPlasticity.csv'), sep=',')\n",
    "#adapt hen and colors\n",
    "df_PL['HenID '] = df_PL['HenID'].map(lambda x: 'Other Hens' if x not in [h.split(':')[0] for h in li_hen_visual] else x)\n",
    "display(df_PL['HenID '].value_counts())\n",
    "print(df_PL.shape)\n",
    "df_PL.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot plasticity over time\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.25)\n",
    "sns.scatterplot(x='DIB', y='PC1', data=df_PL[df_PL['HenID ']!='Other Hens'], hue='HenID ', palette=pal_all, \n",
    "                hue_order=hue_order_all, legend=False);\n",
    "sns.lineplot(x='DIB', y='pred_HenID', data=df_PL, hue='HenID ', linestyle=\"dashed\", palette=pal_all, hue_order=hue_order_all,\n",
    "            legend=False);\n",
    "#remove all borders\n",
    "sns.despine(bottom = True, left = True)\n",
    "#plt.title('Individual plasticity');\n",
    "plt.grid()\n",
    "plt.text(11, 1, '─ ─ ─ estimated slopes', color='black')\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'RawAdnEstimatedPlasticty.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We observe a general positive trend in the average vertical travel distance per hour as number of days post-transfer increases, but also that variance in the average vertical travel distance per hour is greater at the first days post-transferd compared to the 40th day post-transfer onward and there appears to be some non-linearity, and therefore we will investigate whether the fixed effect of number of days post-transfer on the average vertical travel distance per hour could be modelled with either a linear model or a quadratic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#plot plasticity over time\n",
    "#TODO: add pred_HenID1.4\n",
    "sns.lineplot(x='DIB', y='pred_HenID1.4', data=df_PL, hue='HenID ', linestyle=\"dashed\", palette=pal_all, hue_order=hue_order_all);\n",
    "plt.title('Individual plasticity');\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'EstimatedPlastictyOvertime.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#behavioural type\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "g = sns.FacetGrid(df_PL, row=\"HenID \", hue=\"HenID \", aspect=7.5, height=0.8, palette=pal_all)\n",
    "#densities\n",
    "g.map(sns.kdeplot, \"PC1\", bw_adjust=.5, clip_on=False, fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"PC1\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "g.map(label, \"PC1\")\n",
    "# Set the subplots to overlap\n",
    "g.fig.subplots_adjust(hspace=-.5)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True);\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'Rawdensity.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictability\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.25)\n",
    "sns.scatterplot(x='DIB', y='PC1', data=df_PL[df_PL['HenID ']!='Other Hens'], hue='HenID ', palette=pal_all, \n",
    "                hue_order=hue_order_all, legend=False);\n",
    "#sns.lineplot(x='DIB', y='pred_HenID', data=df_PL[df_PL['HenID ']!='Other Hens'], hue='HenID ', linestyle=\"dashed\", palette=pal_all, hue_order=hue_order_all,\n",
    "#            legend=False);\n",
    "#add max error\n",
    "df_ = df_PL.groupby('HenID')[['pred_HenID','PC1']].agg(lambda x: list(x)).reset_index()\n",
    "df_['diff'] = df_.apply(lambda x: [abs(x['pred_HenID'][i]-x['PC1'][i]) for i in range(0,len(x['pred_HenID']))], axis=1)\n",
    "df_['max_error'] = df_['diff'].map(lambda x: max(x))\n",
    "display(df_.head(3))\n",
    "df_PL['max_error'] = df_PL['HenID'].map(lambda x: df_[df_['HenID']==x]['max_error'].values[0])\n",
    "for henID in li_hen_visual:\n",
    "    y = df_PL[df_PL['HenID ']==henID]['pred_HenID']\n",
    "    err = df_PL[df_PL['HenID ']==henID]['max_error']\n",
    "    x = df_PL[df_PL['HenID ']==henID]['DIB']\n",
    "    plt.plot(x, y-err, color=pal_[henID])\n",
    "    plt.plot(x, y+err, color=pal_[henID])\n",
    "    plt.fill_between(x, y-err, y+err, alpha=0.1, color=pal_[henID])\n",
    "#plt.text(11, 1.4, '─ ─ ─ estimated slopes', color='black')\n",
    "#remove all borders\n",
    "sns.despine(bottom = True, left = True)\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'RawVariability.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all individual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BT.rename(columns={'mean':'BehaviouralType'},inplace=True)\n",
    "print(df_BT.shape)\n",
    "df_BT.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indall = pd.merge(df_ind.pivot(columns='term', index='groupID',values='mean').reset_index(), \n",
    "                     df_pred_summarized, left_on='groupID', right_on='HenID', how='outer')\n",
    "df_indall.rename(columns={'mean':'predictability'}, inplace=True)\n",
    "print(df_indall.shape)\n",
    "df_indall = pd.merge(df_indall, df_BT[['groupID','BehaviouralType']], on='groupID', how='outer')\n",
    "print(df_indall.shape)\n",
    "df_indall.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pearsonr(df_indall['BLUP_int'].tolist(), df_indall['BehaviouralType'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_int'].tolist(), df_indall['BLUP_slopes1'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_slopes1'].tolist(), df_indall['BLUP_slopes2'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_int'].tolist(), df_indall['BLUP_slopes2'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_int'].tolist(), df_indall['Predictability_mean'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_slopes2'].tolist(), df_indall['Predictability_mean'].tolist()))\n",
    "print(pearsonr(df_indall['BLUP_slopes1'].tolist(), df_indall['Predictability_mean'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_indall['HenID '] = df_indall['HenID'].map(lambda x: 'Other Hens' if x not in li_hen_visual else x)\n",
    "sns.pairplot(df_indall[['HenID ','BLUP_int','BLUP_slopes1','BLUP_slopes2','Predictability_mean','BehaviouralType']], hue='HenID ', palette=pal_all, diag_kind=\"hist\");\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'BLUPestiamtes.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#correaltion\n",
    "sns.set(rc={'figure.figsize':(6.5,5)})\n",
    "df_corr = df_ind.pivot(columns='term',index='groupID', values='mean').reset_index()\n",
    "df_corr['HenID '] = df_corr['groupID'].map(lambda x: 'Other Hens' if x not in li_hen_visual else x)\n",
    "sns.scatterplot(x='BLUP_int', y='BLUP_slopes', data=df_corr, hue='HenID ', palette=pal_all, hue_order=hue_order_all,\n",
    "               legend=False);\n",
    "plt.text(-1.3, -0.037, 'corr=-0.85', size=15)\n",
    "plt.savefig(os.path.join(path_extracted_data_adap,'RSlopesVSestiamtes.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe for stats ~ health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_selected_hens = pickle.load(open(os.path.join(path_extracted_data_adap, 'li_selected_hens.pkl'), 'rb'))\n",
    "print(len(li_selected_hens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MVT = pd.read_csv(os.path.join(path_extracted_data_adap,'df_MVT_4individuality.csv'), sep=';')\n",
    "print(df_MVT.shape)\n",
    "df_MVT[df_MVT['HenID']=='hen_39']\n",
    "df_MVT.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add info on the first week\n",
    "df_MVT_ALL = pd.read_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables_verified.csv'), sep=';', \n",
    "                     parse_dates=['level'], dayfirst=True) \n",
    "print(df_MVT_ALL.shape)\n",
    "df_MVT_ALL = df_MVT_ALL[df_MVT_ALL['HenID'].isin(li_selected_hens)]\n",
    "#restrict to the adaptability study timeframe\n",
    "df_MVT_ALL = df_MVT_ALL[df_MVT_ALL['level']<=config.max_date_adaptability]\n",
    "print(df_MVT_ALL.shape)\n",
    "#make sure we have their mvt\n",
    "df_MVT_ALL = df_MVT_ALL[~df_MVT_ALL['perc_duration_5_Zone'].isnull()]\n",
    "print(df_MVT_ALL.shape)\n",
    "#df_HA[['HAID','date']].drop_duplicates()\n",
    "df_MVT_ALL.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HA&KBF&weight\n",
    "df_HA = pd.read_csv(os.path.join(path_extracted_data, 'df_all_HA.csv'), sep=';', parse_dates=['date'], dayfirst=True) \n",
    "print(df_HA.shape)\n",
    "df_HA = df_HA[df_HA['HenID'].isin(li_selected_hens)]\n",
    "#display(df_HA.groupby(['HAID'])['date'].agg(lambda x: set(x)).reset_index())\n",
    "display(df_HA['HAID'].value_counts())\n",
    "print(df_HA.shape)\n",
    "df_HA.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='HAID', y='weight', data=df_HA.sort_values(['HAID']), hue='HenID', legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### add commn mvt var ####################\n",
    "df_MVT['InitialWeight_kg'] = df_MVT['InitialWeight'].map(lambda x: x/1000)\n",
    "df_4stat = df_MVT.groupby(['HenID'])[['perc_1_Zone_while_WG_open','vertical_travel_distance_perh',\n",
    "                                      'perc_duration_5_Zone','InitialWeight_kg','RPen']].agg(lambda x: np.nanmedian(x)).reset_index()\n",
    "#note: InitialWeight and RPen: have same value all the time, so mean/median is good too\n",
    "print(df_4stat.shape)\n",
    "df_4stat.head(3)\n",
    "\n",
    "#################### add nbr days within first three without mvt ####################\n",
    "m = df_MVT_ALL['DIB'].min()\n",
    "df_nomvt = df_MVT_ALL[df_MVT_ALL['DIB'].isin([m,m+1,m+2])].groupby('HenID')['Total_number_zone'].agg(lambda x: list(x)).reset_index()\n",
    "df_nomvt['nbr_first3days_no_mvt'] = df_nomvt['Total_number_zone'].agg(lambda x: sum([i==1 for i in list(x)]))\n",
    "display(df_nomvt['nbr_first3days_no_mvt'].value_counts(normalize=True))\n",
    "print(df_nomvt.shape)\n",
    "df_nomvt.head(3)\n",
    "print(df_4stat.shape)\n",
    "df_4stat = pd.merge(df_4stat, df_nomvt[['HenID','nbr_first3days_no_mvt']], on='HenID', how='outer')\n",
    "print(df_4stat.shape)\n",
    "\n",
    "#################### add BLUP estimates ####################\n",
    "print(df_4stat.shape)\n",
    "df_4stat = pd.merge(df_4stat, df_indall[['HenID','BehaviouralType','BLUP_slopes2','Predictability_mean']], on='HenID', how='outer')\n",
    "print(df_4stat.shape)\n",
    "\n",
    "#################### add HA5 ####################\n",
    "print(df_4stat.shape)\n",
    "df_4stat = pd.merge(df_4stat, df_HA[df_HA['HAID']=='HA5'][['HenID','PenID','CLASS','Treatment','severity','weight',\n",
    "                                                           'Feathers']], on='HenID', how='outer')\n",
    "print(df_4stat.shape)\n",
    "\n",
    "#save\n",
    "df_4stat = df_4stat[~df_4stat['severity'].isnull()]\n",
    "print(df_4stat.shape)\n",
    "df_4stat = df_4stat[~df_4stat['nbr_first3days_no_mvt'].isnull()]\n",
    "print(df_4stat.shape)\n",
    "\n",
    "df_4stat.to_csv(os.path.join(path_extracted_data_adap,'df_MVT_4stat.csv'), index=False, sep=';')\n",
    "print(df_4stat.shape)\n",
    "df_4stat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4stat[df_4stat.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='Predictability_mean',x='Treatment',data=df_4stat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
