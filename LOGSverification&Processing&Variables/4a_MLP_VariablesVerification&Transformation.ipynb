{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "import pickle #to download MLP vectors\n",
    "from scipy.stats import entropy, variation\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import preprocessing_Origins, nbrh_WG_open\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook serves for two things\n",
    "1) verify the variables\n",
    "2) check things in variables when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n",
      "ALLDATA_\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "dico_garden_opening_hour = config.dico_garden_opening_hour\n",
    "id_run = config.id_run\n",
    "mindur_toaccountforZ4 = config.mindur_toaccountforZ4\n",
    "dico_matching = config.dico_matching\n",
    "print(id_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2681720, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>system</th>\n",
       "      <th>Zone</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>next_record_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>previous_record_date</th>\n",
       "      <th>previous_duration</th>\n",
       "      <th>next_zone</th>\n",
       "      <th>previous_zone</th>\n",
       "      <th>previous_previous_zone</th>\n",
       "      <th>correction_is_consecutive_equal_initial_zone</th>\n",
       "      <th>is_WG_open</th>\n",
       "      <th>duration_mn</th>\n",
       "      <th>is_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>pen9</td>\n",
       "      <td>8 - 9</td>\n",
       "      <td>2_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:50:00</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 17:56:25</td>\n",
       "      <td>0 days 08:06:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>486.416667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>pen9</td>\n",
       "      <td>8 - 9</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 17:56:25</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-30 09:55:59</td>\n",
       "      <td>0 days 02:52:35</td>\n",
       "      <td>2020-09-29 09:50:00</td>\n",
       "      <td>0 days 08:06:25</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>2_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>959.566667</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>pen9</td>\n",
       "      <td>8 - 9</td>\n",
       "      <td>5_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-30 09:55:59</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09-30 11:34:30</td>\n",
       "      <td>0 days 01:32:11</td>\n",
       "      <td>2020-09-30 09:51:57</td>\n",
       "      <td>0 days 00:04:02</td>\n",
       "      <td>5_Zone</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>98.516667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID PenID system    Zone  model_prediction           Timestamp  \\\n",
       "0  hen_1  pen9  8 - 9  2_Zone               1.0 2020-09-29 09:50:00   \n",
       "1  hen_1  pen9  8 - 9  3_Zone               1.0 2020-09-29 17:56:25   \n",
       "2  hen_1  pen9  8 - 9  5_Zone               1.0 2020-09-30 09:55:59   \n",
       "\n",
       "        date     next_record_date         duration previous_record_date  \\\n",
       "0 2020-09-29  2020-09-29 17:56:25  0 days 08:06:25                  NaN   \n",
       "1 2020-09-29  2020-09-30 09:55:59  0 days 02:52:35  2020-09-29 09:50:00   \n",
       "2 2020-09-30  2020-09-30 11:34:30  0 days 01:32:11  2020-09-30 09:51:57   \n",
       "\n",
       "  previous_duration next_zone previous_zone previous_previous_zone  \\\n",
       "0               NaN    3_Zone           NaN                    NaN   \n",
       "1   0 days 08:06:25    3_Zone        2_Zone                    NaN   \n",
       "2   0 days 00:04:02    5_Zone        3_Zone                 3_Zone   \n",
       "\n",
       "   correction_is_consecutive_equal_initial_zone  is_WG_open  duration_mn  \\\n",
       "0                                         False       False   486.416667   \n",
       "1                                         False       False   959.566667   \n",
       "2                                         False       False    98.516667   \n",
       "\n",
       "   is_day  \n",
       "0    True  \n",
       "1   False  \n",
       "2    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned mvt data\n",
    "df_init = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', parse_dates=['Timestamp', 'date']) \n",
    "print(df_init.shape)\n",
    "df_init.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily var\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables.csv'), sep=';',\n",
    "                 parse_dates=['level', 'FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                             'FirstTimestamp_4_Zone','FirstTimestamp_5_Zone'],\n",
    "                 dayfirst=True) \n",
    "df_daily = df_daily[df_daily['level']!=dt.datetime(2021,7,25)]\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#daily var IN BETWEEN CHECKS\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, id_run+'_daily__pen12_variables.csv'), sep=';',\n",
    "                 parse_dates=['level', 'FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                             'FirstTimestamp_4_Zone','FirstTimestamp_5_Zone'],\n",
    "                 dayfirst=True) \n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_daily[df_daily['vertical_travel_distance_dawn']==0].shape)\n",
    "print(df_daily[df_daily['vertical_travel_distance_dawn']>0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[['list_Z4','mid_cum_Z4_sec','list_of_zones','list_of_durations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_daily.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation - Could be added in UTILS if another run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tracking system ID\n",
    "df_daily['TrackingSystemID'] = df_daily['PenID'].map(lambda x: config.dico_pen_ts[x])\n",
    "display(df_daily['TrackingSystemID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add if animal is sleeping up \n",
    "df_daily['Is_Sleeping_UP'] = df_daily['night_Max_duration_zones'].isin(['5_Zone','4_Zone'])\n",
    "display(df_daily['Is_Sleeping_UP'].value_counts(normalize=True))\n",
    "#better than binary: height of sleeping\n",
    "print(df_daily.shape)\n",
    "df_daily = df_daily[~df_daily['night_Max_duration_zones'].isnull()]\n",
    "df_daily['SleepingHeight'] = df_daily['night_Max_duration_zones'].map(lambda x: int(x.split('_')[0])-2)#-2: litter (zon2: equal to 0 tiers underneath)\n",
    "display(df_daily['SleepingHeight'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nbr transitions per hour. \n",
    "#df_daily['nbr_h_WGopen'] = df_daily['level'].map(lambda x: nbrh_WG_open(x, config))\n",
    "li_ = ['vertical_travel_distance','nbr_stays_2_Zone','nbr_stays_3_Zone','nbr_stays_4_Zone','nbr_stays_5_Zone']\n",
    "for v in li_:\n",
    "    df_daily[v+'_perh'] = df_daily.apply(lambda x: x[v]/x['nbr_h_per_day'], axis=1)\n",
    "    df_daily['nbr_stays_1_Zone_perh'] = df_daily.apply(lambda x: x['nbr_stays_1_Zone']/x['nbr_h_WGopen'] if x['nbr_h_WGopen']!=0 else np.nan, axis=1)\n",
    "df_daily[['vertical_travel_distance_perh','vertical_travel_distance', 'nbr_stays_3_Zone', 'nbr_stays_3_Zone_perh',\n",
    "        'nbr_h_per_day']].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#uncommon/extreme behavior\n",
    "df_daily['uncommon_behavior'] = df_daily.apply(lambda x: sum([x['Total_number_zone']<=2])>=1, axis=1)\n",
    "display(df_daily[df_daily['level']>dt.datetime(2020,11,10)]['uncommon_behavior'].value_counts(normalize=True))\n",
    "df_daily[(df_daily['uncommon_behavior']>0)&(df_daily['level']>dt.datetime(2020,11,10))][['level','HenID','uncommon_behavior','SleepingHeight','nestboxes_related_behavior',\n",
    "                                           'Total_number_zone']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#uncommon/extreme behavior\n",
    "df_daily['uncommon_behavior'] = df_daily.apply(lambda x: sum([x['SleepingHeight'] in [0,1], \n",
    "                                                              x['nestboxes_related_behavior']<0,\n",
    "                                                              x['Total_number_zone']<=2,\n",
    "                                                              x['duration_4_Zone']<15*60])>=1, axis=1)\n",
    "display(df_daily[df_daily['level']>dt.datetime(2020,11,10)]['uncommon_behavior'].value_counts(normalize=True))\n",
    "df_daily[(df_daily['uncommon_behavior']>0)&(df_daily['level']>dt.datetime(2020,11,10))][['level','HenID','uncommon_behavior','SleepingHeight','nestboxes_related_behavior',\n",
    "                                           'Total_number_zone']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only since 2h start in the morning\n",
    "df_daily['time_midduratioZ4_h'] = df_daily['mid_cum_Z4_sec'].map(lambda x: x/60/60+2)\n",
    "df_daily.loc[df_daily['level']<dt.datetime(2020,11,13,0,0,0),'time_midduratioZ4_h'] = np.nan\n",
    "plt.hist(df_daily['time_midduratioZ4_h']);\n",
    "df_daily[['list_Z4', 'mid_cum_Z4_sec','nbr_h_per_day','time_midduratioZ4_h']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_cum_Z4_sec(li_Z4):\n",
    "    li = list(np.cumsum(li_Z4))\n",
    "    m = int(max(li)/2) #round down \n",
    "    if m>0:\n",
    "        ind_ = li.index(m) + 1 #+1 for index 0\n",
    "        return(ind_)\n",
    "    #if never went in nestboxes then put np.nan\n",
    "    return np.nan\n",
    "#small example\n",
    "li = [1,1,4,4,4,1,1,2,2,2,3,3,3,1,4,2,2,2,2,5,5,5,4,4,4]\n",
    "li = [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "mid_cum_Z4_sec(li) #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbr_early_visit_Z4(li):\n",
    "    li_z = [x[0] for x in itertools.groupby(li)]\n",
    "    return (sum(li_z))\n",
    "#small example\n",
    "li = [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "nbr_early_visit_Z4(li) #[1, 2, 3, 4, 2, 4, 1, 2]\n",
    "\n",
    "def nbr_early_visit_Z4_moreXsec(li, mindur_toaccountforZ4):\n",
    "    #add 0 in the list in case it starts with 1\n",
    "    li = [0]+li\n",
    "    #print('_'.join([str(i) for i in li]))\n",
    "    #print('_'.join([str(i) for i in li]).split('0_1'))\n",
    "    #split each time hen visited the nestbox and sum each of those instances adding 1 , but removing first element, as its only 0\n",
    "    li_dur = [j.count(\"1\")+1 for j in '_'.join([str(i) for i in li]).split('0_1')[1:]] \n",
    "    return(len([i for i in li_dur if i>=mindur_toaccountforZ4]))\n",
    "#small example\n",
    "li = [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1] #3\n",
    "li = [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1] #4\n",
    "nbr_early_visit_Z4_moreXsec(li, mindur_toaccountforZ4=2) #[1, 2, 3, 4, 2, 4, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['nbr_visit_Z4_Morning'] = df_daily['list_Z4'].map(lambda x: nbr_early_visit_Z4(eval(x)[0:((8-2)*60*60)]))\n",
    "plt.hist(df_daily['nbr_visit_Z4_Morning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['nbr_visit_Z4_Morning_more'+str(mindur_toaccountforZ4)+'sec'] = df_daily['list_Z4'].map(lambda x: nbr_early_visit_Z4_moreXsec(eval(x)[0:((8-2)*60*60)],\n",
    "                                                                                                           mindur_toaccountforZ4))\n",
    "plt.hist(df_daily['nbr_visit_Z4_Morning_more'+str(mindur_toaccountforZ4)+'sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['nbr_visit_Z4_Morning_more15sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval(df_daily['list_Z4'].iloc[1]))/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval(df_daily['list_Z4'].iloc[1])[0:((8-2)*60*60)])/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_daily[''] = df_daily['list_Z4'].map(lambda x: eval(x)[0:((8-2)*60*60)])\n",
    "df_daily['mid_cum_Z4_sec_Morning'] = df_daily['list_Z4'].map(lambda x: mid_cum_Z4_sec(eval(x)[0:((8-2)*60*60)]))\n",
    "df_daily['duration_until8_inZ4'] = df_daily['list_Z4'].map(lambda x: sum(eval(x)[0:((8-2)*60*60)]))\n",
    "#nan before the light start at 2h!\n",
    "df_daily.loc[df_daily['level']<dt.datetime(2020,11,13,0,0,0),'mid_cum_Z4_sec_Morning'] = np.nan\n",
    "df_daily['mid_cum_Z4_h_Morning'] = df_daily['mid_cum_Z4_sec_Morning'].map(lambda x: x/60/60+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily[(df_daily['level']>dt.datetime(2020,11,13))]['mid_cum_Z4_h_Morning']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily[(df_daily['level']>dt.datetime(2020,11,13))]['nbr_visit_Z4_Morning']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily[(df_daily['level']>dt.datetime(2020,11,13))]['nbr_visit_Z4_Morning_more'+str(mindur_toaccountforZ4)+'sec']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = df_daily.groupby(['HenID'])[['nbr_visit_Z4_Morning','mid_cum_Z4_h_Morning']].mean().reset_index()\n",
    "print(df_plt.shape)\n",
    "display(df_plt.head(3))\n",
    "plt.scatter(df_plt['nbr_visit_Z4_Morning'].tolist(), df_plt['mid_cum_Z4_h_Morning'].tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily['duration_until8_inZ4']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_daily[(df_daily['level']>dt.datetime(2020,11,13))&(df_daily['duration_until8_inZ4']<15*60)][['duration_until8_inZ4',\n",
    "                                                                                                   'HenID','level',\n",
    "                                                                                                   'mid_cum_Z4_h_Morning',\n",
    "                                                                                               'nbr_visit_Z4_Morning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "586/38253*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10*60*60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add vertical distance full light and /inside hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add vertical travel distance during full light\n",
    "df_daily['vertical_travel_distance_fulllight'] = df_daily.apply(lambda x: x['vertical_travel_distance']-x['vertical_travel_distance_dusk'], axis=1)\n",
    "#we substract the dusk timing:\n",
    "li_light_dusk_ = config.li_light_dusk_\n",
    "nbr_dusk_sec = (max(li_light_dusk_)-min(li_light_dusk_)).seconds\n",
    "print('dusk phase lasted for %d minutes' %(nbr_dusk_sec/60))\n",
    "df_daily['vertical_travel_distance_fulllight_perinsideh'] = df_daily.apply(lambda x: x['vertical_travel_distance_fulllight']/(15-(x['duration_1_Zone']+nbr_dusk_sec)/60/60),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add order of going to the litter in the morning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sorted so that smallest comes first\n",
    "dico_level_sortedlistdate = dict(df_daily.groupby(['level','PenID'])['FirstTimestamp_2_Zone'].agg(lambda x: sorted([i for i in list(x) if i is not pd.NaT])))\n",
    "df_daily['order_firstlitter'] = df_daily.apply(lambda x: dico_level_sortedlistdate[(x['level'],x['PenID'])].index(x['FirstTimestamp_2_Zone']) if x['FirstTimestamp_2_Zone'] is not pd.NaT else np.nan, axis=1)\n",
    "df_daily['order_firstlitter_percent'] = df_daily.apply(lambda x: dico_level_sortedlistdate[(x['level'],x['PenID'])].index(x['FirstTimestamp_2_Zone'])/\\\n",
    "                                           len(dico_level_sortedlistdate[(x['level'],x['PenID'])]) if x['FirstTimestamp_2_Zone'] is not pd.NaT else np.nan, axis=1)\n",
    "\n",
    "#small verification\n",
    "df_daily[df_daily['PenID']==10][['order_firstlitter','order_firstlitter_percent','FirstTimestamp_2_Zone','level','PenID',\n",
    "                                 'HenID']].sort_values(['FirstTimestamp_2_Zone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#verify that when an animal slept in the litter then its the first animal to be in litter.\n",
    "#find such instance (i.e. the day after sleeping height=0!)\n",
    "display(df_daily[(df_daily['SleepingHeight']==0)&(df_daily['PenID']==10)][['order_firstlitter','order_firstlitter_percent',\n",
    "                                                                   'FirstTimestamp_2_Zone','level','PenID','HenID',\n",
    "                                                                   'SleepingHeight']])\n",
    "df_daily[(df_daily['level'].isin([dt.datetime(2020,10,6),dt.datetime(2020,10,16),dt.datetime(2020,10,22),\n",
    "                                  dt.datetime(2020,10,28)]))&(df_daily['HenID']=='hen_143')][['order_firstlitter','order_firstlitter_percent',\n",
    "                                                                   'FirstTimestamp_2_Zone','level','PenID','HenID',\n",
    "                                                                   'SleepingHeight']]\n",
    "#correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add order of going to the top floor in the evening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#compute last timestamp:\n",
    "#why: will be usefull to produce other variables, to verify the code and to use it for some zones\n",
    "df_ = df_init[df_init['Zone']=='5_Zone'].groupby(['HenID', 'date'])['Timestamp'].agg(lambda x: max(list(x))).reset_index()\n",
    "df_.rename(columns={'Timestamp':'LastTimestampToptier','date':'level'}, inplace=True)\n",
    "display(df_)\n",
    "df_daily = pd.merge(df_daily, df_, how='left', on=['HenID','level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#ATTENTION: LastTimestampToptier does not mean that the bird stayed there after!! so have to be combined with their sleeping height\n",
    "#Note that if the hen arrived up at 16h59, but then was kikked away at 17h01: we dont care as long as its sleeping height is the top floor.\n",
    "#sorted so that smallest comes first\n",
    "dico_level_sortedlistdate = dict(df_daily.groupby(['level','PenID'])['LastTimestampToptier'].agg(lambda x: sorted([i for i in list(x) if i is not pd.NaT])))\n",
    "df_daily['order_firstgoingup'] = df_daily.apply(lambda x: dico_level_sortedlistdate[(x['level'],x['PenID'])].index(x['LastTimestampToptier']) if x['LastTimestampToptier'] is not pd.NaT else np.nan, axis=1)\n",
    "df_daily['order_firstgoingup_percent'] = df_daily.apply(lambda x: dico_level_sortedlistdate[(x['level'],x['PenID'])].index(x['LastTimestampToptier'])/\\\n",
    "                                           len(dico_level_sortedlistdate[(x['level'],x['PenID'])]) if x['LastTimestampToptier'] is not pd.NaT else np.nan, axis=1)\n",
    "df_daily['LastTimestampToptier_time'] = df_daily['LastTimestampToptier'].map(lambda x: dt.datetime.time(x))\n",
    "#small verification\n",
    "df_daily[df_daily['PenID']==10][['order_firstgoingup','order_firstgoingup_percent','LastTimestampToptier','LastTimestampToptier_time',\n",
    "                                 'level','PenID','HenID','SleepingHeight']].sort_values(['LastTimestampToptier'])\n",
    "#ISSUE: might not be there anymore!!! should be done with ts!!!!! but then waht if an animal arrive when its dark? bold or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#would be 0 if they did not slept up, 1 would mean and \n",
    "#in that case, the bird that went up at 6h30 or the one that did not slept in top tier have the save value:30\n",
    "df_daily['lastminutessleepingUP'] = df_daily.apply(lambda x: x['SleepingHeight']==3 & x['LastTimestampToptier'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#(day_Z5 /day – night_Z5/night) / (day_Z5 /day + night_Z5/night)\n",
    "def Z5_diurnality(dur_day, dur_night, nbr_h_per_day):\n",
    "    n = dur_day/nbr_h_per_day - dur_night/(24-nbr_h_per_day)\n",
    "    p = dur_day/nbr_h_per_day + dur_night/(24-nbr_h_per_day)\n",
    "    #if never spent time in Z5 then return: neutral nght versus day behavior\n",
    "    if p==0:\n",
    "        return 0\n",
    "    return n/p  \n",
    "\n",
    "df_daily['Z5diuranility'] = df_daily.apply(lambda x: Z5_diurnality(dur_day=x['duration_5_Zone'],\n",
    "                                                                   dur_night=x['night_duration_Z5'],\n",
    "                                                                   nbr_h_per_day=x['nbr_h_per_day']), axis=1)\n",
    "plt.hist(df_daily['Z5diuranility']);\n",
    "df_daily[['night_duration_Z5','duration_5_Zone','Z5diuranility']].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#coefficient of variation: ratio of standard deviation to mean. np.std(x) / np.mean(x)\n",
    "df_daily['CVduration'] = df_daily['list_of_durations'].map(lambda x: variation(eval(x)))\n",
    "display(df_daily[df_daily['CVduration'].isnull()])\n",
    "df_daily[['list_of_durations','list_of_zones','latency_1_Zone_h','latency_4_Zone_h','latency_2_Zone_h','CVduration']]\n",
    "plt.hist(df_daily['CVduration']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add daily HA using interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KBF&severity\n",
    "df_HA = pd.read_csv(os.path.join(path_extracted_data, 'df_all_HA.csv'), sep=';', parse_dates=['date'], dayfirst=True) \n",
    "df_HA['FeatherDamage'] = df_HA['Feathers'].map(lambda x: 100-x)\n",
    "df_HA['date_HA'] = df_HA['date'].copy()\n",
    "df_HA = df_HA[~df_HA['HenID'].isnull()] #two isntances\n",
    "print(df_HA.shape)\n",
    "#display(df_HA.groupby(['HAID'])['date'].agg(lambda x: set(x)).reset_index())\n",
    "display(df_HA['HAID'].value_counts())\n",
    "#info on date\n",
    "display(df_HA.groupby(['HAID','date','WOA','DOA'])['HenID'].count().reset_index())\n",
    "print(df_HA.shape)\n",
    "df_HA.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#focal birds information (one row per focal bird)\n",
    "df_FB = pd.read_csv(os.path.join(path_extracted_data, id_run+'df_FOCALBIRDS.csv'), sep=';',\n",
    "                    parse_dates=['InitialStartDate'], dayfirst=True)\n",
    "print(df_FB.shape)\n",
    "df_FB.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inter_HA(HenID, DOA, df_HA, df_FB, str_ha):\n",
    "    if str_ha not in df_HA.columns:\n",
    "        print('error, specify an exist column name')\n",
    "        sys.exit()\n",
    "    #available HA days, for that specific hen\n",
    "    li_DOA = np.array(df_HA[(df_HA['HenID']==HenID)&(~df_HA[str_ha].isnull())]['DOA'].unique())\n",
    "    if len(li_DOA)==0:\n",
    "        return np.nan\n",
    "    mi = min(li_DOA)\n",
    "    ma = max(li_DOA)\n",
    "        \n",
    "    #if its an exact date (never happen, except for last date, which we put to be the date previous the real HA)\n",
    "    if DOA in li_DOA:\n",
    "        return df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==DOA)][str_ha].iloc[0]\n",
    "    \n",
    "    #if its at the lower boundery, then add the timestamp 0 when they moved to the laying barn\n",
    "    #(if its at the higher boundery, then add the KBF from that time (but this should never happend))\n",
    "    #we wont allow a to big difference either\n",
    "    #the day previous can be assumed as the same as the actual health measured ont eh day after\n",
    "    if (DOA<mi) & (mi-DOA==1):\n",
    "        x1 = 119\n",
    "        wdoa119 = df_FB[df_FB['HenID']==HenID]['29-09 weight'].iloc[0]\n",
    "        x2 = li_DOA[li_DOA > DOA].min() #smallest above \n",
    "        #we actually only allows this when the highiest above is HA 1, i.e. 173 DOA\n",
    "        if x2==173:\n",
    "            return(df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==mi)][str_ha].iloc[0])        \n",
    "\n",
    "    if (DOA<mi) & (str_ha=='weight'):\n",
    "        x1 = 119\n",
    "        wdoa119 = df_FB[df_FB['HenID']==HenID]['29-09 weight'].iloc[0]\n",
    "        x2 = li_DOA[li_DOA > DOA].min() #smallest above \n",
    "        #we actually only allows this when the highiest above is HA 1, i.e. 173 DOA\n",
    "        if x2==173:\n",
    "            return(np.interp(DOA, xp=(x1,x2), fp=(wdoa119, df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==x2)][str_ha].iloc[0])))        \n",
    "    if (DOA<mi) & (str_ha=='FeatherDamage'):\n",
    "        fdoa119 = 0 #assume 0 for all when transfer to LB\n",
    "        x1 = 119\n",
    "        x2 = li_DOA[li_DOA > DOA].min() #smallest above\n",
    "        #we actually only allows this when the highiest above is HA 1, i.e. 173 DOA\n",
    "        if x2==173:\n",
    "            return(np.interp(DOA, xp=(x1,x2), fp=(0, df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==x2)][str_ha].iloc[0])))        \n",
    "    if DOA<mi:\n",
    "        #print(DOA)\n",
    "        #x1 = df_daily[df_daily['DIB']==1]['DOA'].iloc[0] #119 doa\n",
    "        #x2 = li_DOA[li_DOA > DOA].min() #smallest above \n",
    "        #return(np.interp(DOA, xp=(x1,x2), fp=(0, df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==x2)][str_ha].iloc[0])))        \n",
    "        return np.nan\n",
    "        \n",
    "    #if its at the higher boundery, then add the KBF from that time (can happen with for example early death)\n",
    "    if DOA>ma:\n",
    "        return(df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==ma)][str_ha].iloc[0])        \n",
    "\n",
    "    #else:\n",
    "    x1 = li_DOA[li_DOA < DOA].max() #largest below\n",
    "    x2 = li_DOA[li_DOA > DOA].min() #smallest above \n",
    "    #print(x1,x2,DOA,HenID)\n",
    "    return(np.interp(DOA, xp=(x1,x2), \n",
    "                     fp=(df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==x1)][str_ha].iloc[0],\n",
    "                         df_HA[(df_HA['HenID']==HenID)&(df_HA['DOA']==x2)][str_ha].iloc[0])))\n",
    "        \n",
    "df_daily['KBF_interp'] = df_daily.apply(lambda x: inter_HA(HenID=x['HenID'], DOA=x['DOA'], \n",
    "                                                           df_HA=df_HA, df_FB=df_FB, str_ha='severity'), axis=1)\n",
    "\n",
    "print('FeatherDamage')\n",
    "df_daily['FeatherDamage_interp'] = df_daily.apply(lambda x: inter_HA(HenID=x['HenID'], DOA=x['DOA'], \n",
    "                                                              df_HA=df_HA, df_FB=df_FB, str_ha='FeatherDamage'), axis=1)\n",
    "print('weight')\n",
    "df_daily['weight_interp'] = df_daily.apply(lambda x: inter_HA(HenID=x['HenID'], DOA=x['DOA'], \n",
    "                                                              df_HA=df_HA, df_FB=df_FB, str_ha='weight'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='DOA', y='KBF_interp', hue='Treatment', data=df_daily);\n",
    "plt.show()\n",
    "sns.lineplot(x='DOA', y='FeatherDamage_interp',  hue='Treatment', data=df_daily);\n",
    "plt.show()\n",
    "sns.lineplot(x='DOA', y='weight_interp', hue='Treatment', data=df_daily);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='DOA', y='severity', hue='Treatment', data=df_HA);\n",
    "plt.show()\n",
    "sns.lineplot(x='DOA', y='FeatherDamage',  hue='Treatment', data=df_HA);\n",
    "plt.show()\n",
    "sns.lineplot(x='DOA', y='weight', hue='Treatment', data=df_HA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add daily HA using BLUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initweight = df_FB[['HenID','29-09 weight']].copy()\n",
    "df_initweight['DIB'] = 0\n",
    "df_initweight = df_initweight.rename(columns={'29-09 weight':'weight'})\n",
    "df_initweight['FeatherDamage'] = 0\n",
    "df_initweight['severity'] = 0\n",
    "display(df_initweight.head(3))\n",
    "df_HA['DIB'] = df_HA['DOA'].map(lambda x: x-118)\n",
    "df_hablups = df_HA[['HenID','DOA','DIB','severity','FeatherDamage','weight']].copy()\n",
    "display(df_hablups.head(3))\n",
    "print(df_initweight.shape, df_hablups.shape)\n",
    "df_hablups = pd.concat([df_initweight, df_hablups])\n",
    "print(df_hablups.shape)\n",
    "display(df_hablups.head(3))\n",
    "df_hablups = df_hablups[~df_hablups['DIB'].isnull()]\n",
    "print(df_hablups.shape)\n",
    "df_hablups.to_csv(os.path.join(path_extracted_data,'df_hablups_all.csv'), index=False, sep=',')\n",
    "df_ = df_hablups.groupby(['HenID'])['weight'].count().reset_index()\n",
    "li_hen = df_[df_['weight']>3]['HenID'].tolist()#with at least 3 observation (i.e. 2 as the first one does not really count for severity and feather)\n",
    "df_hablups[df_hablups['HenID'].isin(li_hen)].to_csv(os.path.join(path_extracted_data,'df_hablups.csv'), index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding (henID;WIB) serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['HenID_WIB'] = df_daily.apply(lambda x: x['HenID']+'-WIB'+str(x['WIB']), axis=1)\n",
    "df_daily[['HenID_WIB','HenID','WIB']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct food reactivity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_related_behavior should be replaced by food_related_behavior4 from the 28.03.2021 due to summer time changed that\n",
    "#probably changed the computer programe timing too\n",
    "df_daily['food_related_behavior_final'] = np.where(df_daily['level']<dt.datetime(2021,3,27,0,0,0), \n",
    "                                                   df_daily['food_related_behavior'], df_daily['food_related_behavior4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small verification: CORRECT!\n",
    "li_food = ['food_related_behavior_final','food_related_behavior4']\n",
    "for b in li_food:\n",
    "    plt.figure(figsize=(15,5))\n",
    "    sns.pointplot(y=b, x='DOA', color='red', data=df_daily);\n",
    "    sns.pointplot(y='food_related_behavior', x='DOA',  data=df_daily);\n",
    "    plt.title(b)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_related_behavior should be replaced by food_related_behavior4 from the 28.03.2021 due to summer time changed that\n",
    "#probably changed the computer programe timing too\n",
    "df_daily['food_related_behavior_rp_final'] = np.where(df_daily['level']<dt.datetime(2021,3,27,0,0,0), \n",
    "                                                   df_daily['food_related_behavior_rp'], df_daily['food_related_behavior_rp4'])\n",
    "df_daily['food_related_behavior_rm_final'] = np.where(df_daily['level']<dt.datetime(2021,3,27,0,0,0), \n",
    "                                                   df_daily['food_related_behavior_rm'], df_daily['food_related_behavior_rm4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt = pd.melt(df_daily[df_daily['level']>config.date_consistent_barn_schedule], id_vars=['HenID','WOA','level','PenID'], \n",
    "        value_vars=['food_related_behavior_final','food_related_behavior_rp_final','food_related_behavior_rm_final'],\n",
    "        value_name='food_behavior')\n",
    "df_plt['is_positive'] = df_plt['food_behavior'].map(lambda x: int(x>0))\n",
    "display(df_plt.head(3))\n",
    "#display(df_plt.groupby(['variable'])['is_positive'].agg(lambda x: sum(x)/len(x)*100).reset_index())\n",
    "df_plt_ = df_plt.groupby(['variable','level'])['is_positive'].agg(lambda x: sum(x)/len(x)*100).reset_index()\n",
    "display(df_plt_.head(3))\n",
    "df_plt_.groupby(['variable']).agg(mean_is_positive=pd.NamedAgg(column='is_positive', aggfunc=lambda x: np.nanmean(x)),\n",
    "           sd_is_positive=pd.NamedAgg(column='is_positive', aggfunc=lambda x: np.std(x))).reset_index()\n",
    "#weekly average +-SD of the mean daily food-related behavior across individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plt[df_plt['food_behavior']==-1].groupby(['variable','HenID']).count().reset_index().sort_values(['WOA']).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_plt[(df_plt['food_behavior']==-1)&(df_plt['HenID']=='hen_173')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[(df_daily['HenID']=='hen_173')&(df_daily['level']==dt.datetime(2020,12,12))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[(df_daily['level']>config.date_consistent_barn_schedule)&\\\n",
    "         (df_daily['food_related_behavior_final']==-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for penid in df_plt['PenID'].unique():\n",
    "    plt.figure(figsize=(12,4))\n",
    "    pal_ = {'food_related_behavior_rm_final':'darkorange',\n",
    "            'food_related_behavior_rp_final':'indianred',\n",
    "            'food_related_behavior_final':'steelblue'}\n",
    "    sns.histplot(df_plt[df_plt['PenID']==penid], x='food_behavior', kde=False, hue='variable');\n",
    "    plt.title(penid)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "pal_ = {'food_related_behavior_rm_final':'darkorange',\n",
    "        'food_related_behavior_rp_final':'indianred',\n",
    "        'food_related_behavior_final':'steelblue'}\n",
    "sns.histplot(df_plt, x='food_behavior', kde=False, hue='variable', palette=pal_);\n",
    "plt.savefig(os.path.join(path_extracted_data, 'FoodRI_density.png'),dpi=300,format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#almost non are 0\n",
    "df_plt[df_plt['food_behavior']==0].shape[0]/df_plt[df_plt['food_behavior']!=0].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.pointplot(y='food_related_behavior_final', x='DOA', color=pal_['food_related_behavior_final'], data=df_daily, \n",
    "              estimator=np.median);\n",
    "sns.pointplot(y='food_related_behavior_rm_final', x='DOA', color=pal_['food_related_behavior_rm_final'], data=df_daily, \n",
    "              estimator=np.median);\n",
    "sns.pointplot(y='food_related_behavior_rp_final', x='DOA', color=pal_['food_related_behavior_rp_final'], data=df_daily, \n",
    "              estimator=np.median);\n",
    "plt.axhline(y=0, linewidth=2, color = 'k')\n",
    "plt.title('median estimate of food reactivity index')\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(path_extracted_data, 'FoodRI_overtime_median.png'),dpi=300,format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.pointplot(y='food_related_behavior_final', x='DOA', color=pal_['food_related_behavior_final'], data=df_daily, \n",
    "              estimator=np.mean,  s=0.1);\n",
    "sns.pointplot(y='food_related_behavior_rm_final', x='DOA', color=pal_['food_related_behavior_rm_final'], data=df_daily, \n",
    "              estimator=np.mean, s=0.1);\n",
    "sns.pointplot(y='food_related_behavior_rp_final', x='DOA', color=pal_['food_related_behavior_rp_final'], data=df_daily, \n",
    "              estimator=np.mean, s=0.1);\n",
    "plt.axhline(y=0, linewidth=2, color = 'k')\n",
    "plt.title('mean estimate of food reactivity index')\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(path_extracted_data, 'FoodRI_overtime_mean.png'),dpi=300,format='png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates tracked and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify this was remove\n",
    "df_daily[~((df_daily['level']<dt.datetime(2021,6,14))|(df_daily['level']>dt.datetime(2021,7,3)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify this was remove\n",
    "df_daily[((df_daily['HenID']=='hen_158')&(df_daily['level']>dt.datetime(2021,5,1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify this was remove\n",
    "df_daily[((df_daily['HenID']=='hen_56')&(df_daily['level']>dt.datetime(2020,11,29))&\\\n",
    "                    (df_daily['level']<dt.datetime(2021,1,4)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify hen_129 is not here althought it was in focal bird with 0 workign tracked days!\n",
    "if df_daily[df_daily['HenID']=='hen_129'].shape[0]>0:\n",
    "    print('ERROR')\n",
    "    sys.exit()\n",
    "df_daily[df_daily['HenID']=='hen_129']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['level']==dt.datetime(2020,9,30)][['PenID','nbr_h_per_day','correct_amount_of_hour','level']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[['PenID','nbr_h_per_day','correct_amount_of_hour','level','Total_number_transition','verification_daily_total_duration']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[['level','DIB','WIB','DOA','WOA']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_var = list(df_daily.columns)\n",
    "li_general = ['HenID', 'level','PenID']\n",
    "li_var_TODO = li_var #keep track of the columns that still needs to be verified\n",
    "len(li_var_TODO)\n",
    "#display(list(li_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all column with nan\n",
    "#df_daily.columns[df_daily.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hens variables + disturbances days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_hens = ['CLASS','TagID','FocalLegringName','R-Pen','InitialStartDate']\n",
    "print(li_hens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific bird (in pen 9, should not be  here on the 3,4,5, 8, 9 th of OCtober it should have NO data at all\n",
    "h = 'hen_90'\n",
    "d = dt.datetime(2020,10,10)\n",
    "df_daily[(df_daily['HenID']==h)&(df_daily['level']<=d)][li_general+li_hens+['duration_5_Zone',\n",
    "                                                                            'night_Max_duration_zones']].sort_values(['level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that the day with weird device day (can be find here: *_df_alldeviceinfo) are removed\n",
    "#hen_147 - tag 82: 25.01-03.02 not working (due to rfid installation and then tag bugging) \n",
    "h = 'hen_147'\n",
    "dmin = dt.datetime(2021,1,24)\n",
    "dmax = dt.datetime(2021,2,10)\n",
    "df_daily[(df_daily['HenID']==h)&(df_daily['level']<=dmax)&(df_daily['level']>=dmin)][li_general+li_hens].sort_values(['level'])\n",
    "#TO CHECK: Pen ID here even when the day variables is not here?\n",
    "#TO DO AT THE END OF THE STUDY: check each indivudal case of GAP: e.g. tag 171 (hen 133) had big gaps on the 11.01.2021\n",
    "#sometimes its nan due to the student that wrote +-30/70 (weight 04-01-2021, pen 12)\n",
    "#CORRECT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_hens]\n",
    "len(li_var_TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# food related behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be better checked visually in 4.b. notebook (more easy)\n",
    "display(df_daily[df_daily['food_related_behavior_final']>0.5].tail(3))\n",
    "h = 'hen_29'\n",
    "d = dt.datetime(2020,10,19)\n",
    "df = df_init[(df_init['HenID']==h)&((df_init['date']==d)|(df_init['date']==(d+dt.timedelta(days=1))))]\n",
    "display(df_daily[(df_daily['HenID']==h)&((df_daily['level']==d)|\\\n",
    "                                         (df_daily['level']==(d+dt.timedelta(days=1))))][li_general+['food_related_behavior_final']].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Night"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that \"nbr_transition_at_h*\" is a night variables, meaning that its at h8 of the level after (i.e. but during the night following the actual level). It was computed so thath we have 0 when the hour is not during the night, so ATTENTION for now we have for the hours>2 in the morning sometimes 0 just because the light was off, not because there was no transitions!!!!\n",
    "night_Max_duration_zones: is the zone where the hen stayed the longest consecutively (not the one with total longest duration: we prefer 4h than 3h and 2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['night_duration_Z5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_night = [i for i in li_var_TODO if ('night' in i)]+['SleepingHeight']\n",
    "li_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['SleepingHeight'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another bird, based on:\n",
    "#display(df_daily[df_daily['level']==dt.datetime(2020,10,7)].head(3))\n",
    "h = 'hen_130'\n",
    "d = dt.datetime(2020,10,7) #day of a change in the light schedule of the day: on the 7th it turned off at 18h and on the 8th it \n",
    "#turned on at 8h (not 9h sas it was on the 7th)\n",
    "df = df_init[(df_init['HenID']==h)&((df_init['date']==d)|(df_init['date']==(d+dt.timedelta(days=1))))]\n",
    "display(df_daily[(df_daily['HenID']==h)&((df_daily['level']==d)|(df_daily['level']==(d+dt.timedelta(days=1))))][li_general+li_night].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 'hen_131'\n",
    "d = dt.datetime(2020,10,7) #day of a change in the light schedule of the day: on the 7th it turned off at 18h and on the 8th it \n",
    "#turned on at 8h (not 9h sas it was on the 7th)\n",
    "df = df_init[(df_init['HenID']==h)&((df_init['date']==d)|(df_init['date']==(d+dt.timedelta(days=1))))]\n",
    "display(df_daily[(df_daily['HenID']==h)&((df_daily['level']==d)|(df_daily['level']==(d+dt.timedelta(days=1))))][li_general+li_night].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_night]\n",
    "print(len(li_var_TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transitions in aviary (zone 1, zone 2, zone 3, zone 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first timestamp in each zones and latency"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When its nan it means: never went to that zone that day\n",
    "FirstTimestamp_*_Zone: is the first timestamp when the bird was in that zone. If the bird was laready in this zone before the \"day \" started, it will be counted as well. Hence it's not necessarily due to a transition, but simply due to where is the bird at each time of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_latency = [i for i in li_var if 'latency_' in i]\n",
    "li_first_timestamp = [i for i in li_var if 'FirstTimestamp' in i]+['Total_number_zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random bird\n",
    "h = 'hen_89'\n",
    "d = dt.datetime(2020,11,18) #until 17h\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "X = df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)]\n",
    "display(X[li_general+li_first_timestamp+li_latency])\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific bird\n",
    "#df_daily[li_general+li_first_timestamp].head(3)\n",
    "h = 'hen_130'\n",
    "d = dt.datetime(2020,10,6)\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']<=d)]\n",
    "X = df_daily[(df_daily['HenID']==h)&(df_daily['level']<=d)]\n",
    "display(X[li_general+li_first_timestamp+li_latency+['verification_daily_total_duration']])\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#specific bird\n",
    "#df_daily[li_general+li_first_timestamp].head(3)\n",
    "h = 'hen_90'\n",
    "d = dt.datetime(2020,10,6) #3,4,5 : tracking should not be used\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "X = df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)]\n",
    "display(X[li_general+li_first_timestamp].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#specific bird that went in wg!\n",
    "#df_daily[li_general+li_first_timestamp].head(3)\n",
    "h = 'hen_109'\n",
    "d = dt.datetime(2021,3,10) #3,4,5 : tracking should not be used\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "X = df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)]\n",
    "display(X[li_general+li_first_timestamp].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "14*60*60+57*60+17  #= 53837 correct\n",
    "#-->correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_first_timestamp]\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_latency]\n",
    "len(li_var_TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transitions & stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_transition_rest = ['vertical_travel_distance','Total_number_transition','vertical_travel_distance_dawn',\n",
    "                      'vertical_travel_distance_dusk','vertical_travel_distance_fulllight_perinsideh',\n",
    "                      'vertical_travel_distance_fulllight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[(df_daily['vertical_travel_distance_dawn'].isnull())&(df_daily['level']>config.date_consistent_barn_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in li_transition_rest:\n",
    "    plt.hist(df_daily[x])\n",
    "    plt.title(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['vertical_travel_distance_dawn']>0][li_transition_rest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stay\n",
    "li_nbr_stays = ['nbr_stays_1_Zone', 'nbr_stays_2_Zone', 'nbr_stays_3_Zone', 'nbr_stays_4_Zone', 'nbr_stays_5_Zone']\n",
    "df_daily[li_nbr_stays+['nbr_stays_total','nbr_h_per_day','Total_number_transition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duration\n",
    "li_dur = ['duration_1_Zone', 'duration_2_Zone', 'duration_3_Zone', 'duration_4_Zone', 'duration_5_Zone']\n",
    "li_perc = ['perc_'+c for c in li_dur]\n",
    "df_daily[li_dur+li_perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify Total_number_zone==1 if and only if Total_number_transitions==0\n",
    "display(df_daily[df_daily['Total_number_transition']==0][['Total_number_transition','HenID','level','Total_number_zone']].head(3))\n",
    "display(df_daily[df_daily['Total_number_zone']==1][['Total_number_transition','HenID','level','Total_number_zone']].head(3))\n",
    "if df_daily[(df_daily['Total_number_zone']==1)|(df_daily['Total_number_transition']==0)].shape[0]!=df_daily[(df_daily['Total_number_zone']==1)&(df_daily['Total_number_transition']==0)].shape[0]:\n",
    "    print('ERROR: you dont have: Total_number_zone==1 if and only if Total_number_transitions==0')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#random bird\n",
    "h = 'hen_130'\n",
    "d = dt.datetime(2020,10,7)\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_transition_rest].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#another random bird\n",
    "h = 'hen_30'\n",
    "d = dt.datetime(2020,10,4) #9h-18h\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['Timestamp']<=dt.datetime(2020,10,4,18,0,0))]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_transition_rest].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#vertical_travel_distance: 23 is correct (note: it came from 5 to 2 at 12:20:20)\n",
    "#down_missingZone_mvtPerc corret: 2/20*100=10% (one from 5 to 2 and one from 4 to 2), we had 20 transitions\n",
    "#--> correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same bird\n",
    "h = 'hen_30'\n",
    "d = dt.datetime(2020,10,4) #9h-18h\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['Timestamp']<=dt.datetime(2020,10,4,18,0,0))]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_nbr_stays].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#vertical_travel_distance: 23 is correct (note: it came from 5 to 2 at 12:20:20)\n",
    "#total_number of transition: 21 rows including 2 repetitives so its 20\n",
    "#stay_longer_60sec_4_Zone: correct, it did not counted the one of <60seconds\n",
    "#down_missingZone_mvtPerc corret: 2/21*100=9,5% (one from 5 to 2 and one from 4 to 2)\n",
    "#stay_longer_60sec_4_Zone: correct, it did not counted the one of <60seconds\n",
    "#note that the stay_* is at amximum one mroe thant the total number of transition\n",
    "#total_number of transition: 21 rows including a repetition of 3_zone so its 20\n",
    "#--> correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_nbr_stays]\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_transition_rest]\n",
    "#li_var_TODO = [i for i in li_var_TODO if i not in li_nbr_stays_perh]\n",
    "print(len(li_var_TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_dur = [i for i in li_var_TODO if ('duration' in i)&('Nestbox' not in i)&('WG' not in i)&('night' not in i)]\n",
    "li_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[['duration_3_Zone','verification_daily_total_duration','perc_duration_3_Zone']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#same bird\n",
    "h = 'hen_130'\n",
    "d = dt.datetime(2020,10,7) #9h-18h is the day\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_dur].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#duration_*_zone, correct:\n",
    "display(dt.datetime(2020,10,7,9,3,45)-dt.datetime(2020,10,7,9,0,0),#zone 3 #225\n",
    "dt.datetime(2020,10,7,9,7,11)-dt.datetime(2020,10,7,9,3,45), #zone 2 #206\n",
    "dt.datetime(2020,10,7,9,7,35)-dt.datetime(2020,10,7,9,7,11), #zone 3 #24\n",
    "dt.datetime(2020,10,7,9,9,45)-dt.datetime(2020,10,7,9,7,35), #zone 4 #130\n",
    "dt.datetime(2020,10,7,18,0,0)-dt.datetime(2020,10,7,9,9,45)) #zone 5 #31815\n",
    "#rest also correct\n",
    "#--> correct (should all be in seconds except when explicitely written \"_mn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_dur]\n",
    "print(len(li_var_TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nestbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_nb = [i for i in li_var_TODO if ('nestbox' in i.lower())|('z4' in i.lower())]\n",
    "li_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily['nestboxes_related_behavior']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should be nan:\n",
    "display(df_daily[df_daily['level']>dt.datetime(2021,8,15,0,0,0)]['nestboxes_related_behavior'])\n",
    "#if spent less than 15minutes in total in the nestbox zone: should be 0\n",
    "df_daily[df_daily['duration_4_Zone']<15*60]['nestboxes_related_behavior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ATTENTION: nestboxes_related_behavior only once the barn schedule is stable!\n",
    "display(df_daily[(df_daily['nestboxes_related_behavior']<0)&(df_daily['DIB']>50)].head(2))\n",
    "h = 'hen_134'\n",
    "d = dt.datetime(2021,1,8) #late date to have nestbox usage\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_nb].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "display((dt.datetime(2020,11,22,5,13,10)-dt.datetime(2020,11,22,4,45,21)).total_seconds())\n",
    "display((dt.datetime(2020,11,22,4,45,21)-dt.datetime(2020,11,22,4,15,21)).total_seconds())\n",
    "#CORRECT!\n",
    "#Note that: B10h_Nestbox_nbrvisit is the number of visits DURING DAY TIME in the test box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_nb]\n",
    "print(len(li_var_TODO))\n",
    "display(li_var_TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WG"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "latency in wg: not that we decieded to compute keeping the defintion correct, but then when the WG was open only 3h, all birds had wg<=3, even the one that does not went out. but maybe they would have gone outside if the wg was open longer so its also better to acocunt for this.\n",
    "--> it is important to account for the nbr_h_WGopen as fixd effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency should be FirstTimestamp_1_Zone_sec-duration_sincedaystarted_beforeWGopened_sec: nbr of seconds since opened\n",
    "df_daily[['level','nbr_h_WGopen','FirstTimestamp_1_Zone','FirstTimestamp_1_Zone_sec','duration_sincedaystarted_beforeWGopened_sec','latency_1_Zone_h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check when close: all is nan\n",
    "df_daily[df_daily['nbr_h_WGopen']==0][['HenID','nbr_h_WGopen','level','FirstTimestamp_1_Zone','FirstTimestamp_1_Zone_sec','duration_sincedaystarted_beforeWGopened_sec',\n",
    "                                       'latency_1_Zone_h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latency for birds never going outside\n",
    "df_daily[(df_daily['level']>dt.datetime(2021,2,2))&(df_daily['FirstTimestamp_1_Zone'].isnull())][['level','FirstTimestamp_1_Zone','FirstTimestamp_1_Zone_sec','duration_sincedaystarted_beforeWGopened_sec','latency_1_Zone_h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_wg = [i for i in li_var_TODO if 'WG' in i]+[i for i in df_daily.columns if '1_Zone' in i]+['duration_1_Zone']\n",
    "li_wg\n",
    "#'in_WG_15mnAfterOpening', 'Max_duration_WG', latency1_zone, perc_1_Zone_while_WG_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#should nly be nan as WG not opened\n",
    "print(config.date_first_opening_WG)\n",
    "df_daily[df_daily['level']<config.date_first_opening_WG][['HenID','level']+li_wg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily['nbr_h_WGopen']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['nbr_h_WGopen']<3][['level','nbr_h_WGopen','latency_1_Zone_h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['level']>=config.date_first_opening_WG][['HenID','level','is_mvt_night']+li_wg].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bird based on : df_daily[df_daily['Max_duration_WG']>0].tail(15)\n",
    "h = 'hen_98'\n",
    "d = dt.datetime(2021,1,10)  #10h a 16h20(to be checked with new data)\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_wg].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "#-->correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random bird\n",
    "h = 'hen_12'\n",
    "d = dt.datetime(2021,1,9)  #10h a 16h20(to be checked with new data)\n",
    "df = df_init[(df_init['HenID']==h)&(df_init['date']==d)]\n",
    "display(df_daily[(df_daily['HenID']==h)&(df_daily['level']==d)][li_general+li_wg].sort_values(['level']))\n",
    "display(tuple(zip(df['Timestamp'].tolist(),df['Zone'].tolist())))\n",
    "display(dt.datetime(2021,1,15,9,14)-dt.datetime(2021,1,15,8,58),\n",
    "       dt.datetime(2021,1,15,10,55)-dt.datetime(2021,1,15,9,23))\n",
    "#Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the list of variable that we still need to verify\n",
    "li_var_TODO = [i for i in li_var_TODO if i not in li_wg]\n",
    "print(len(li_var_TODO))\n",
    "display(li_var_TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_daily[['distribution_entropy','list_of_zones','dur_values_normalized','dur_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "#Note: order does not matter, number of 0min in a zone does not matter\n",
    "print(entropy([0.0, 0.0, 780.0, 325.0, 31295.0], base=2),\n",
    "entropy([0.0, 206.0, 249.0, 130.0, 31815.0,0,0,0,0], base=2),\n",
    "entropy([0.0, 206.0, 249.0, 130.0, 31815.0], base=2),\n",
    "entropy([1/6, 1/6, 1/6, 1/6, 1/6, 1/6], base=2),\n",
    "entropy([1/5, 1/5, 1/5, 1/5, 1/5], base=2),\n",
    "entropy([1/4, 1/4, 1/4, 1/4], base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max entropy with 5 zones\n",
    "nbr_zone = 5\n",
    "print(math.log(nbr_zone, 2), entropy([1,1,1,1,1],base=2))\n",
    "if round(math.log(nbr_zone, 2),8)!=round(entropy([1,1,1,1,1],base=2),8):\n",
    "    print('ERROR 1')\n",
    "    sys.exit()\n",
    "if df_daily['distribution_entropy'].max()>math.log(nbr_zone, 2):\n",
    "    print('ERROR 2')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_daily['distribution_entropy']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['verification_daily_total_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['verification_daily_total_duration']==28800]['level'].value_counts() #on the 30 septemebr: 9h-17h was the \n",
    "#light on: 8h=28'800\n",
    "#2020-09-30: first full day, but for the chicken that never moved since they enter the day before, they still hav no data\n",
    "#Correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_daily[df_daily['verification_daily_total_duration']<28800]['HenID'].value_counts())\n",
    "df_daily[df_daily['verification_daily_total_duration']<28800]['level'].value_counts()\n",
    "#2020-09-30: first full day, but for the chicken that never moved since they enter the day before, they still hav no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[df_daily['verification_daily_total_duration']<28800][li_general+['verification_daily_total_duration']+\\\n",
    "                                                               li_first_timestamp]\n",
    "#can appear in any zone... we dont know from when on, where th ebird was before going there, so we can only remove those days\n",
    "#for those specific chickens\n",
    "#TODO at the end of experiment: CHECK ALL CASES ONE BY ONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and last verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_dur = ['duration_1_Zone','duration_2_Zone','duration_3_Zone','duration_4_Zone','duration_5_Zone']\n",
    "for x in li_dur:\n",
    "    df_daily[x+'_min'] = df_daily[x].map(lambda x: x/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to control for\n",
    "df_daily['Has_been_toptier_wholeday'] = df_daily['perc_duration_5_Zone'].map(lambda x: x==100)\n",
    "df_daily['Has_been_toptier_wholeday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['PenID'] = df_daily['PenID'].map(lambda x: 'pen'+str(x))\n",
    "df_daily['PenID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_d_week = {0:'monday',\n",
    "               1:'tuesday',\n",
    "               2:'wednesday',\n",
    "               3:'thursday',\n",
    "               4:'friday',\n",
    "               5:'saturday',\n",
    "               6:'sunday'}\n",
    "df_daily['weekday'] = df_daily['level'].map(lambda x : dico_d_week[x.weekday()]) #monday=0,...\n",
    "df_daily[df_daily['weekday']=='sunday']['level'].max() #check manually: correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily[['HenID_WIB','HenID','KBF_interp','FeatherDamage_interp','weight_interp',\n",
    "          'latency_1_Zone_h','nbr_h_WGopen',\n",
    "          'time_midduratioZ4_h',\n",
    "          'Is_Sleeping_UP','Has_been_toptier_wholeday', \n",
    "          'vertical_travel_distance_fulllight_perinsideh',\n",
    "          'food_related_behavior_final', 'food_related_behavior_rp_final','food_related_behavior_rm_final']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_ = df_daily.drop(['list_of_zones','dur_values_normalized','list_Z4']+li_dur,axis=1)\n",
    "df_daily_.to_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables_verified.csv'),sep=';',index=False)\n",
    "print(df_daily_.shape)\n",
    "df_daily_.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['time_wg_open_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
