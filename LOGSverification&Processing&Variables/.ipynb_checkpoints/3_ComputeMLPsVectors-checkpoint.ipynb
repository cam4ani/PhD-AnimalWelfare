{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from scipy import stats\n",
    "from numpy import inf\n",
    "import networkx as nx\n",
    "from dtaidistance import dtw\n",
    "import random\n",
    "\n",
    "#save and load dictionaries/lists\n",
    "import pickle\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "#clustering\n",
    "from sklearn.cluster import KMeans #only numerical var\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import kmodes\n",
    "from kmodes.kmodes import KModes #with categorical var as well\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import kmeans_clustering, ZoneVariable, time_series_henColumn_tsRow, FB_daily, corr_from_dep2feature,\\\n",
    "corr_from_feature2feature, correlationGraph, ZoneVariable, DataRepresentation1, sampen, chi2_distance, is_day, correct_key\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "id_run = config.id_run\n",
    "dico_pen_tr = config.dico_pen_tr\n",
    "li_binmn = config.li_binmn\n",
    "penalty = config.penalty\n",
    "dico_window = config.dico_window\n",
    "birth_date = config.birth_date\n",
    "dico_night_hour = config.dico_night_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2448062, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>system</th>\n",
       "      <th>Zone</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>next_record_date</th>\n",
       "      <th>previous_record_date</th>\n",
       "      <th>previous_duration</th>\n",
       "      <th>next_zone</th>\n",
       "      <th>previous_zone</th>\n",
       "      <th>previous_previous_zone</th>\n",
       "      <th>correction_is_consecutive_equal_initial_zone</th>\n",
       "      <th>is_WG_open</th>\n",
       "      <th>hour</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_71</td>\n",
       "      <td>pen12</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:07:00</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:08:26.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_7</td>\n",
       "      <td>pen11</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:08:12</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:12:16.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_10</td>\n",
       "      <td>pen11</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-29 09:19:19</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 09:20:27.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>09:19:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HenID  PenID   system    Zone  model_prediction           Timestamp  \\\n",
       "0  hen_71  pen12  10 - 12  3_Zone               1.0 2020-09-29 09:07:00   \n",
       "1   hen_7  pen11  10 - 12  3_Zone               1.0 2020-09-29 09:08:12   \n",
       "2  hen_10  pen11  10 - 12  3_Zone               1.0 2020-09-29 09:19:19   \n",
       "\n",
       "        date         next_record_date previous_record_date previous_duration  \\\n",
       "0 2020-09-29  2020-09-29 09:08:26.000                  NaN               NaN   \n",
       "1 2020-09-29  2020-09-29 09:12:16.000                  NaN               NaN   \n",
       "2 2020-09-29  2020-09-29 09:20:27.000                  NaN               NaN   \n",
       "\n",
       "  next_zone previous_zone previous_previous_zone  \\\n",
       "0    3_Zone           NaN                    NaN   \n",
       "1    3_Zone           NaN                    NaN   \n",
       "2    3_Zone           NaN                    NaN   \n",
       "\n",
       "   correction_is_consecutive_equal_initial_zone  is_WG_open  hour      time  \n",
       "0                                         False       False     9  09:07:00  \n",
       "1                                         False       False     9  09:08:00  \n",
       "2                                         False       False     9  09:19:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the cleaned-movement data\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp', 'date'], dayfirst=True) \n",
    "df['hour'] = df['Timestamp'].map(lambda x: x.hour)\n",
    "df['time'] = df['Timestamp'].map(lambda x: dt.datetime.time(x-dt.timedelta(seconds=x.second)))\n",
    "df.drop('duration', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute MLPS vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attention: note that here we use all mlps, we should be removing the one we dont want for each analysis after. Indeed if no mvt one days: is it because unwanted days or because no mvt provided by the animal?\n",
    "TODO: check each subsequent analysis accordingly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the daily-hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 28 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:20:21, and the ending date will be: 2021-05-10 08:42:27\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:20:21, and the ending date will be: 2021-05-10 23:59:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time: 3.78 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object tqdm.__iter__ at 0x000001A23C3F3200>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\camil\\anaconda3\\lib\\site-packages\\tqdm\\std.py\", line 1215, in __iter__\n",
      "    self.last_print_n = last_print_n\n",
      "KeyboardInterrupt: \n",
      "  0%|                                                                                            | 0/8 [04:43<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d07a1635e673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m#restrict to the day ONLY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdf_ts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_day'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mis_day\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdico_night_hour\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mdf_ts_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ts_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   3968\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m         \"\"\"\n\u001b[1;32m-> 3970\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   3972\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   1142\u001b[0m             \u001b[0mmap_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1144\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5541\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5542\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5543\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5544\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     ) -> \"BlockManager\":\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   2095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m         \u001b[1;31m# delegate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2097\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_can_hold_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2017\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m             \u001b[1;31m# DTA/TDA constructor and astype can handle 2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2019\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_holder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeLikeArrayMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;31m# -----------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masi8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_string_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py\u001b[0m in \u001b[0;36m_box_values\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[0mapply\u001b[0m \u001b[0mbox\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \"\"\"\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_box_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for efficiency purpose let's compute the bined time series first\n",
    "#note that we will have more entries than needed, as the distrubances days are not removed in the raw-cleaned movements\n",
    "#dataframe.\n",
    "dico_pen_bin_zone_level_h = {}\n",
    "dico_pen_bin_level_h = {}\n",
    "def duration_normalized_perZone(x):\n",
    "    c = Counter(x)\n",
    "    t = len(x)\n",
    "    return [c['1_Zone']/t, c['2_Zone']/t, c['3_Zone']/t, c['4_Zone']/t, c['5_Zone']/t]\n",
    "#small example\n",
    "#li = ['1_Zone','3_Zone','3_Zone','4_Zone','5_Zone','5_Zone','1_Zone']\n",
    "#duration_normalized_perZone(li)\n",
    "\n",
    "for p, df_pen in tqdm.tqdm(df.groupby('PenID')):\n",
    "    \n",
    "    #update results\n",
    "    dico_pen_bin_zone_level_h[p] = {}\n",
    "    dico_pen_bin_level_h[p] = {}\n",
    "    \n",
    "    #compute time series\n",
    "    df_ts = time_series_henColumn_tsRow(df_pen, config, col_ts='Zone', ts_with_all_hen_value=False, save=False, \n",
    "                                        hen_time_series=False)\n",
    "    \n",
    "    for nbr_binmn in tqdm.tqdm(li_binmn):\n",
    "        \n",
    "        #update results\n",
    "        dico_pen_bin_zone_level_h[p][nbr_binmn] = {}\n",
    "        dico_pen_bin_level_h[p][nbr_binmn] = {}\n",
    "                \n",
    "        #reduce to the interval we want\n",
    "        mi = min(df_ts['Timestamp'].tolist())\n",
    "        ma = max(df_ts['Timestamp'].tolist())\n",
    "        #extend the end to the end of the day in case it case the last day available fo the chicken\n",
    "        Daterange = pd.date_range(start = mi, end = ma, freq = str(nbr_binmn)+'MIN')    \n",
    "        df_date = pd.DataFrame({str(nbr_binmn)+'mn_timestamp':Daterange})\n",
    "        new_timestamp = str(nbr_binmn)+'mn_timestamp'\n",
    "        df_date[new_timestamp] = df_date[new_timestamp].map(lambda x: pd.to_datetime(x))\n",
    "        df_ts_ = pd.merge_asof(df_ts, df_date, left_on=['Timestamp'], right_on=[new_timestamp], direction='forward')\n",
    "        \n",
    "        #restrict to the day ONLY\n",
    "        df_ts_['is_day'] = df_ts_['Timestamp'].map(lambda x: is_day(x, config.dico_night_hour))\n",
    "        df_ts_ = df_ts_[df_ts_['is_day']]\n",
    "        \n",
    "        #groupby the interval that we want with the number of minutes in nestbox\n",
    "        li_hen = [v for v in df_ts.columns if 'hen_' in v]\n",
    "        \n",
    "        ################# overall mlp #################\n",
    "        df_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: duration_normalized_perZone(x)).reset_index()\n",
    "        df_sim['date'] = df_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "        #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "        df_sim = df_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "        #print(df_zone_sim.shape)\n",
    "        #display(df_zone_sim.head(3))\n",
    "\n",
    "        #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "        df_sim_ = pd.melt(df_sim, id_vars=['date'], value_vars=li_hen)\n",
    "        #variable column has the henIDs\n",
    "        #print(df_zone_sim_.shape)\n",
    "        #display(df_zone_sim_.head(3))\n",
    "        for d, df__ in df_sim_.groupby(['date']):\n",
    "            #update results\n",
    "            dico_pen_bin_level_h[p][nbr_binmn][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))   \n",
    "            \n",
    "            \n",
    "        ################# zone-ts over each zone #################                \n",
    "        for ZONE in df['Zone'].unique():\n",
    "            \n",
    "            #update results\n",
    "            dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE] = {}\n",
    "                \n",
    "            df_zone_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: sum([i==ZONE for i in x])/60).reset_index()\n",
    "            df_zone_sim['date'] = df_zone_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "\n",
    "            #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "            df_zone_sim = df_zone_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "            #print(df_zone_sim.shape)\n",
    "            #display(df_zone_sim.head(3))\n",
    "            \n",
    "            #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "            df_zone_sim_ = pd.melt(df_zone_sim, id_vars=['date'], value_vars=li_hen)\n",
    "            #variable column has the henIDs\n",
    "            #print(df_zone_sim_.shape)\n",
    "            #display(df_zone_sim_.head(3))\n",
    "            for d, df__ in df_zone_sim_.groupby(['date']):\n",
    "                #update results\n",
    "                dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))\n",
    "#save dictionaries\n",
    "pickle.dump(dico_pen_bin_zone_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                     id_run+'dico_pen_bin_zone_level_h_DAILYLEVEL.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(dico_pen_bin_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_bin_level_h_DAILYLEVEL.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on [2h, 17h59] only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for efficiency purpose let's compute the bined time series first\n",
    "#note that we will have more entries than needed, as the distrubances days are not removed in the raw-cleaned movements\n",
    "#dataframe.\n",
    "dico_pen_bin_zone_level_h = {}\n",
    "dico_pen_bin_level_h = {}\n",
    "def duration_normalized_perZone(x):\n",
    "    c = Counter(x)\n",
    "    t = len(x)\n",
    "    return [c['1_Zone']/t, c['2_Zone']/t, c['3_Zone']/t, c['4_Zone']/t, c['5_Zone']/t]\n",
    "#small example\n",
    "#li = ['1_Zone','3_Zone','3_Zone','4_Zone','5_Zone','5_Zone','1_Zone']\n",
    "#duration_normalized_perZone(li)\n",
    "\n",
    "for p, df_pen in tqdm.tqdm(df.groupby('PenID')):\n",
    "    \n",
    "    #update results\n",
    "    dico_pen_bin_zone_level_h[p] = {}\n",
    "    dico_pen_bin_level_h[p] = {}\n",
    "    \n",
    "    #compute time series\n",
    "    df_ts = time_series_henColumn_tsRow(df_pen, config, col_ts='Zone', ts_with_all_hen_value=False, save=False, \n",
    "                                        hen_time_series=False)\n",
    "    \n",
    "    for nbr_binmn in tqdm.tqdm(li_binmn):\n",
    "        \n",
    "        #update results\n",
    "        dico_pen_bin_zone_level_h[p][nbr_binmn] = {}\n",
    "        dico_pen_bin_level_h[p][nbr_binmn] = {}\n",
    "                \n",
    "        #reduce to the interval we want\n",
    "        mi = min(df_ts['Timestamp'].tolist())\n",
    "        ma = max(df_ts['Timestamp'].tolist())\n",
    "        #extend the end to the end of the day in case it case the last day available fo the chicken\n",
    "        Daterange = pd.date_range(start = mi, end = ma, freq = str(nbr_binmn)+'MIN')    \n",
    "        df_date = pd.DataFrame({str(nbr_binmn)+'mn_timestamp':Daterange})\n",
    "        new_timestamp = str(nbr_binmn)+'mn_timestamp'\n",
    "        df_date[new_timestamp] = df_date[new_timestamp].map(lambda x: pd.to_datetime(x))\n",
    "        df_ts_ = pd.merge_asof(df_ts, df_date, left_on=['Timestamp'], right_on=[new_timestamp], direction='forward')\n",
    "        \n",
    "        #restrict to 2h-17h59 ONLY\n",
    "        df_ts_['is_2h17'] = df_ts_['Timestamp'].map(lambda x: (x.hour>=2)&(x.hour<18))\n",
    "        df_ts_ = df_ts_[df_ts_['is_2h17']]\n",
    "        \n",
    "        #groupby the interval that we want with the number of minutes in nestbox\n",
    "        li_hen = [v for v in df_ts.columns if 'hen_' in v]\n",
    "        \n",
    "        ################# overall mlp #################\n",
    "        df_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: duration_normalized_perZone(x)).reset_index()\n",
    "        df_sim['date'] = df_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "        #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "        df_sim = df_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "        #print(df_zone_sim.shape)\n",
    "        #display(df_zone_sim.head(3))\n",
    "\n",
    "        #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "        df_sim_ = pd.melt(df_sim, id_vars=['date'], value_vars=li_hen)\n",
    "        #variable column has the henIDs\n",
    "        #print(df_zone_sim_.shape)\n",
    "        #display(df_zone_sim_.head(3))\n",
    "        for d, df__ in df_sim_.groupby(['date']):\n",
    "            #update results\n",
    "            dico_pen_bin_level_h[p][nbr_binmn][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))   \n",
    "            \n",
    "            \n",
    "        ################# zone-ts over each zone #################                \n",
    "        for ZONE in df['Zone'].unique():\n",
    "            \n",
    "            #update results\n",
    "            dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE] = {}\n",
    "                \n",
    "            df_zone_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: sum([i==ZONE for i in x])/60).reset_index()\n",
    "            df_zone_sim['date'] = df_zone_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "\n",
    "            #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "            df_zone_sim = df_zone_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "            #print(df_zone_sim.shape)\n",
    "            #display(df_zone_sim.head(3))\n",
    "            \n",
    "            #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "            df_zone_sim_ = pd.melt(df_zone_sim, id_vars=['date'], value_vars=li_hen)\n",
    "            #variable column has the henIDs\n",
    "            #print(df_zone_sim_.shape)\n",
    "            #display(df_zone_sim_.head(3))\n",
    "            for d, df__ in df_zone_sim_.groupby(['date']):\n",
    "                #update results\n",
    "                dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))\n",
    "#save dictionaries\n",
    "pickle.dump(dico_pen_bin_zone_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                     id_run+'dico_pen_bin_zone_level_h_2h-17h59LEVEL.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(dico_pen_bin_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_bin_level_h_2h-17h59LEVEL.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the entire 24h period for generality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#for efficiency purpose let's compute the bined time series first\n",
    "#note that we will have more entries than needed, as the distrubances days are not removed in the raw-cleaned movements\n",
    "#dataframe.\n",
    "dico_pen_bin_zone_level_h = {}\n",
    "dico_pen_bin_level_h = {}\n",
    "def duration_normalized_perZone(x):\n",
    "    c = Counter(x)\n",
    "    t = len(x)\n",
    "    return [c['1_Zone']/t, c['2_Zone']/t, c['3_Zone']/t, c['4_Zone']/t, c['5_Zone']/t]\n",
    "#small example\n",
    "#li = ['1_Zone','3_Zone','3_Zone','4_Zone','5_Zone','5_Zone','1_Zone']\n",
    "#duration_normalized_perZone(li)\n",
    "\n",
    "for p, df_pen in tqdm.tqdm(df.groupby('PenID')):\n",
    "    \n",
    "    #update results\n",
    "    dico_pen_bin_zone_level_h[p] = {}\n",
    "    dico_pen_bin_level_h[p] = {}\n",
    "    \n",
    "    #compute time series\n",
    "    df_ts = time_series_henColumn_tsRow(df_pen, config, col_ts='Zone', ts_with_all_hen_value=False, save=False, \n",
    "                                        hen_time_series=False)\n",
    "    \n",
    "    for nbr_binmn in tqdm.tqdm(li_binmn):\n",
    "        \n",
    "        #update results\n",
    "        dico_pen_bin_zone_level_h[p][nbr_binmn] = {}\n",
    "        dico_pen_bin_level_h[p][nbr_binmn] = {}\n",
    "                \n",
    "        #reduce to the interval we want\n",
    "        mi = min(df_ts['Timestamp'].tolist())\n",
    "        ma = max(df_ts['Timestamp'].tolist())\n",
    "        #extend the end to the end of the day in case it case the last day available fo the chicken\n",
    "        Daterange = pd.date_range(start = mi, end = ma, freq = str(nbr_binmn)+'MIN')    \n",
    "        df_date = pd.DataFrame({str(nbr_binmn)+'mn_timestamp':Daterange})\n",
    "        new_timestamp = str(nbr_binmn)+'mn_timestamp'\n",
    "        df_date[new_timestamp] = df_date[new_timestamp].map(lambda x: pd.to_datetime(x))\n",
    "        df_ts_ = pd.merge_asof(df_ts, df_date, left_on=['Timestamp'], right_on=[new_timestamp], direction='forward')\n",
    "        #groupby the interval that we want with the number of minutes in nestbox\n",
    "        li_hen = [v for v in df_ts.columns if 'hen_' in v]\n",
    "        \n",
    "        ################# overall mlp #################\n",
    "        df_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: duration_normalized_perZone(x)).reset_index()\n",
    "        df_sim['date'] = df_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "        #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "        df_sim = df_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "        #print(df_zone_sim.shape)\n",
    "        #display(df_zone_sim.head(3))\n",
    "\n",
    "        #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "        df_sim_ = pd.melt(df_sim, id_vars=['date'], value_vars=li_hen)\n",
    "        #variable column has the henIDs\n",
    "        #print(df_zone_sim_.shape)\n",
    "        #display(df_zone_sim_.head(3))\n",
    "        for d, df__ in df_sim_.groupby(['date']):\n",
    "            #update results\n",
    "            dico_pen_bin_level_h[p][nbr_binmn][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))   \n",
    "            \n",
    "            \n",
    "        ################# zone-ts over each zone #################                \n",
    "        for ZONE in df['Zone'].unique():\n",
    "            \n",
    "            #update results\n",
    "            dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE] = {}\n",
    "                \n",
    "            df_zone_sim = df_ts_.groupby(new_timestamp)[li_hen].agg(lambda x: sum([i==ZONE for i in x])/60).reset_index()\n",
    "            df_zone_sim['date'] = df_zone_sim[new_timestamp].map(lambda x: dt.datetime(x.year,x.month,x.day))\n",
    "\n",
    "            #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "            df_zone_sim = df_zone_sim.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "            #print(df_zone_sim.shape)\n",
    "            #display(df_zone_sim.head(3))\n",
    "            \n",
    "            #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "            df_zone_sim_ = pd.melt(df_zone_sim, id_vars=['date'], value_vars=li_hen)\n",
    "            #variable column has the henIDs\n",
    "            #print(df_zone_sim_.shape)\n",
    "            #display(df_zone_sim_.head(3))\n",
    "            for d, df__ in df_zone_sim_.groupby(['date']):\n",
    "                #update results\n",
    "                dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE][d] = dict(zip(df__['variable'].tolist(), df__['value'].tolist()))\n",
    "#save dictionaries\n",
    "pickle.dump(dico_pen_bin_zone_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                     id_run+'dico_pen_bin_zone_level_h.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(dico_pen_bin_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_bin_level_h.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#download the two dictionaries\n",
    "dico_pen_bin_zone_level_h = pickle.load(open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_bin_zone_level_h.pkl'), 'rb'))\n",
    "dico_pen_bin_level_h = pickle.load(open(os.path.join(path_extracted_data, \n",
    "                                                     id_run+'dico_pen_bin_level_h.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
