{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from scipy import stats\n",
    "from numpy import inf\n",
    "import networkx as nx\n",
    "from dtaidistance import dtw\n",
    "import random\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "#save and load dictionaries/lists\n",
    "import pickle\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "#clustering\n",
    "from sklearn.cluster import KMeans #only numerical var\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import kmodes\n",
    "from kmodes.kmodes import KModes #with categorical var as well\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import kmeans_clustering, ZoneVariable, time_series_henColumn_tsRow, FB_daily, corr_from_dep2feature,\\\n",
    "corr_from_feature2feature, correlationGraph, ZoneVariable, DataRepresentation1, sampen, chi2_distance, is_day, correct_key\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "id_run = config.id_run\n",
    "dico_pen_tr = config.dico_pen_tr\n",
    "li_binmn = config.li_binmn\n",
    "penalty = config.penalty\n",
    "dico_window = config.dico_window\n",
    "birth_date = config.birth_date\n",
    "dico_night_hour = config.dico_night_hour\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_extracted_data_proximity = os.path.join(path_extracted_data ,'Proximity')\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_extracted_data_proximity):\n",
    "    os.makedirs(path_extracted_data_proximity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the cleaned-movement data\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp', 'date'], dayfirst=True) \n",
    "df['hour'] = df['Timestamp'].map(lambda x: x.hour)\n",
    "df['time'] = df['Timestamp'].map(lambda x: dt.datetime.time(x-dt.timedelta(seconds=x.second)))\n",
    "df.drop('duration', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (103) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (103) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42515, 149)\n",
      "(42515, 149)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(32032, 151)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(32032, 151)\n",
      "(32032, 151)\n",
      "(32032, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>level</th>\n",
       "      <th>duration_1_Zone</th>\n",
       "      <th>duration_2_Zone</th>\n",
       "      <th>duration_3_Zone</th>\n",
       "      <th>duration_4_Zone</th>\n",
       "      <th>duration_5_Zone</th>\n",
       "      <th>verification_daily_total_duration</th>\n",
       "      <th>dur_values</th>\n",
       "      <th>dur_values_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_night20_2_var</th>\n",
       "      <th>list_of_MovementCounter_day</th>\n",
       "      <th>len_MovementCounter_day</th>\n",
       "      <th>MovementCounter_day_amount_nnactivity</th>\n",
       "      <th>MovementCounter_day_max</th>\n",
       "      <th>MovementCounter_day_mean</th>\n",
       "      <th>DOA</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "      <th>nbr_sec_per_day</th>\n",
       "      <th>is_correct_amount_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>30613.0</td>\n",
       "      <td>31998.0</td>\n",
       "      <td>[0.0, 140.0, 1166.0, 79.0, 30613.0]</td>\n",
       "      <td>[0.0, 0.004375273454590912, 0.0364397774860928...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 32400.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>31295.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 780.0, 325.0, 31295.0]</td>\n",
       "      <td>[0.0, 0.0, 0.024074074074074074, 0.01003086419...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID      level  duration_1_Zone  duration_2_Zone  duration_3_Zone  \\\n",
       "0  hen_130 2020-10-04              0.0            140.0           1166.0   \n",
       "1  hen_130 2020-10-05              0.0              0.0              0.0   \n",
       "2  hen_130 2020-10-06              0.0              0.0            780.0   \n",
       "\n",
       "   duration_4_Zone  duration_5_Zone  verification_daily_total_duration  \\\n",
       "0             79.0          30613.0                            31998.0   \n",
       "1              0.0          32400.0                            32400.0   \n",
       "2            325.0          31295.0                            32400.0   \n",
       "\n",
       "                            dur_values  \\\n",
       "0  [0.0, 140.0, 1166.0, 79.0, 30613.0]   \n",
       "1        [0.0, 0.0, 0.0, 0.0, 32400.0]   \n",
       "2    [0.0, 0.0, 780.0, 325.0, 31295.0]   \n",
       "\n",
       "                               dur_values_normalized  ...  \\\n",
       "0  [0.0, 0.004375273454590912, 0.0364397774860928...  ...   \n",
       "1                          [0.0, 0.0, 0.0, 0.0, 1.0]  ...   \n",
       "2  [0.0, 0.0, 0.024074074074074074, 0.01003086419...  ...   \n",
       "\n",
       "  temperature_night20_2_var list_of_MovementCounter_day  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "\n",
       "  len_MovementCounter_day MovementCounter_day_amount_nnactivity  \\\n",
       "0                     NaN                                   NaN   \n",
       "1                     NaN                                   NaN   \n",
       "2                     NaN                                   NaN   \n",
       "\n",
       "  MovementCounter_day_max  MovementCounter_day_mean  DOA weeks_in_laying_barn  \\\n",
       "0                     NaN                       NaN  123                    1   \n",
       "1                     NaN                       NaN  124                    1   \n",
       "2                     NaN                       NaN  125                    1   \n",
       "\n",
       "  nbr_sec_per_day is_correct_amount_time  \n",
       "0           32400                  False  \n",
       "1           32400                   True  \n",
       "2           32400                   True  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>level</th>\n",
       "      <th>duration_1_Zone</th>\n",
       "      <th>duration_2_Zone</th>\n",
       "      <th>duration_3_Zone</th>\n",
       "      <th>duration_4_Zone</th>\n",
       "      <th>duration_5_Zone</th>\n",
       "      <th>verification_daily_total_duration</th>\n",
       "      <th>dur_values</th>\n",
       "      <th>dur_values_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_night20_2_var</th>\n",
       "      <th>list_of_MovementCounter_day</th>\n",
       "      <th>len_MovementCounter_day</th>\n",
       "      <th>MovementCounter_day_amount_nnactivity</th>\n",
       "      <th>MovementCounter_day_max</th>\n",
       "      <th>MovementCounter_day_mean</th>\n",
       "      <th>DOA</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "      <th>nbr_sec_per_day</th>\n",
       "      <th>is_correct_amount_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>30613.0</td>\n",
       "      <td>31998.0</td>\n",
       "      <td>[0.0, 140.0, 1166.0, 79.0, 30613.0]</td>\n",
       "      <td>[0.0, 0.004375273454590912, 0.0364397774860928...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 32400.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>31295.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 780.0, 325.0, 31295.0]</td>\n",
       "      <td>[0.0, 0.0, 0.024074074074074074, 0.01003086419...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID      level  duration_1_Zone  duration_2_Zone  duration_3_Zone  \\\n",
       "0  hen_130 2020-10-04              0.0            140.0           1166.0   \n",
       "1  hen_130 2020-10-05              0.0              0.0              0.0   \n",
       "2  hen_130 2020-10-06              0.0              0.0            780.0   \n",
       "\n",
       "   duration_4_Zone  duration_5_Zone  verification_daily_total_duration  \\\n",
       "0             79.0          30613.0                            31998.0   \n",
       "1              0.0          32400.0                            32400.0   \n",
       "2            325.0          31295.0                            32400.0   \n",
       "\n",
       "                            dur_values  \\\n",
       "0  [0.0, 140.0, 1166.0, 79.0, 30613.0]   \n",
       "1        [0.0, 0.0, 0.0, 0.0, 32400.0]   \n",
       "2    [0.0, 0.0, 780.0, 325.0, 31295.0]   \n",
       "\n",
       "                               dur_values_normalized  ...  \\\n",
       "0  [0.0, 0.004375273454590912, 0.0364397774860928...  ...   \n",
       "1                          [0.0, 0.0, 0.0, 0.0, 1.0]  ...   \n",
       "2  [0.0, 0.0, 0.024074074074074074, 0.01003086419...  ...   \n",
       "\n",
       "  temperature_night20_2_var list_of_MovementCounter_day  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "\n",
       "  len_MovementCounter_day MovementCounter_day_amount_nnactivity  \\\n",
       "0                     NaN                                   NaN   \n",
       "1                     NaN                                   NaN   \n",
       "2                     NaN                                   NaN   \n",
       "\n",
       "  MovementCounter_day_max  MovementCounter_day_mean  DOA weeks_in_laying_barn  \\\n",
       "0                     NaN                       NaN  123                    1   \n",
       "1                     NaN                       NaN  124                    1   \n",
       "2                     NaN                       NaN  125                    1   \n",
       "\n",
       "  nbr_sec_per_day is_correct_amount_time  \n",
       "0           32400                  False  \n",
       "1           32400                   True  \n",
       "2           32400                   True  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily variables (one row per (henID, date))\n",
    "#daily_ALL_Variable_Tranformed\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables.csv'), sep=';',\n",
    "                     parse_dates=['level','FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                              'FirstTimestamp_4_Zone', 'FirstTimestamp_5_Zone', \n",
    "                              'Nestbox_time_of_first_staid_longer_than900sec',\n",
    "                              'duration_last-firsttransition_mn'], dayfirst=True) \n",
    "df_daily['DOA'] = df_daily['level'].map(lambda x: (x-dt.datetime(2020,6,3)).days) \n",
    "df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "df_daily['PenID'] = df_daily['PenID'].map(lambda x: 'pen'+(str(int(x))))\n",
    "#df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: math.ceil(x/7))\n",
    "#first two month seems good from the %of hens not moving plot! and sounds good too (twice longer thatn they need to start moving)\n",
    "print(df_daily.shape)\n",
    "\n",
    "#filter by date\n",
    "df_daily = df_daily[df_daily['level']>dt.datetime(2020,9,29)]\n",
    "\n",
    "#remove days that are not fully recorded\n",
    "df_daily['nbr_sec_per_day'] = df_daily['level'].map(lambda x: dico_night_hour[correct_key(x,dico_night_hour)]['nbr_hour']*60*60)\n",
    "df_daily['is_correct_amount_time'] = df_daily.apply(lambda x: x['nbr_sec_per_day']==x['verification_daily_total_duration'], axis=1)\n",
    "df_daily[(~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull())][['level', 'HenID', 'Total_number_transition', 'dur_values', 'verification_daily_total_duration','nbr_sec_per_day']]\n",
    "print(df_daily.shape)\n",
    "display(df_daily = df_daily[~((~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull()))])\n",
    "print(df_daily.shape)\n",
    "\n",
    "#remove the days where the night had movement recorded but not the days\n",
    "print(df_daily.shape)\n",
    "#display(df_daily[df_daily.isna().any(axis=1)])\n",
    "df_daily = df_daily[~df_daily['verification_daily_total_duration'].isnull()]\n",
    "print(df_daily.shape)\n",
    "\n",
    "df_daily['dur_values_normalized'].replace('[nan, nan, nan, nan, nan]','[np.nan,np.nan,np.nan,np.nan,np.nan]', inplace=True)\n",
    "df_daily['dur_values_normalized'] = df_daily['dur_values_normalized'].map(lambda x: eval(x))\n",
    "df_daily['duration_last-firsttransition_mn'] = df_daily['duration_last-firsttransition_mn'].astype(float)\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute MLPS vectors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attention: note that here we use all mlps, we should be removing the one we dont want for each analysis after. Indeed if no mvt one days: is it because unwanted days or because no mvt provided by the animal?\n",
    "TODO: check each subsequent analysis accordingly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on the daily-hours"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets do a dictionary to have one vector per bird per day, with its zone value: 1,2,2,2,2. at the second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 28 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:20:21, and the ending date will be: 2021-05-10 08:42:27\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:20:21, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 4.25 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▍                                                                        | 1/8 [07:37<53:22, 457.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 28 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:08:12, and the ending date will be: 2021-05-10 08:42:22\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:08:12, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 3.86 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▊                                                              | 2/8 [14:53<45:06, 451.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 31 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:07:00, and the ending date will be: 2021-05-10 08:42:20\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:07:00, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 4.22 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                   | 3/8 [22:34<37:49, 453.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 28 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:32:45, and the ending date will be: 2021-05-10 08:26:44\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:32:45, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 4.54 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 4/8 [30:40<30:54, 463.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 27 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:33:43, and the ending date will be: 2021-05-10 08:26:01\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:33:43, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 5.08 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████▉                               | 5/8 [39:19<24:00, 480.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 29 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:33:48, and the ending date will be: 2021-05-10 08:26:39\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:33:48, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 4.48 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 6/8 [48:22<16:38, 499.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 29 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:52:12, and the ending date will be: 2021-05-10 08:40:33\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:52:12, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 8.69 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▉          | 7/8 [1:02:34<10:04, 604.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in this time series there is 28 hens\n",
      "The initial starting date in over all is: 2020-09-29 09:36:51, and the ending date will be: 2021-05-10 08:39:39\n",
      "But note that birds may have different ending and starting date which should be taken into account when computing variables\n",
      "and after ending the last day at midnight : 2020-09-29 09:36:51, and the ending date will be: 2021-05-10 23:59:59\n",
      "Total running time: 7.32 mn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8/8 [1:15:28<00:00, 566.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#note that we will have more entries than needed, as the distrubances days are not removed in the raw-cleaned movements\n",
    "#dataframe.\n",
    "dico_pen_level_h = {}\n",
    "#we have to do a loop per pen, due to memory issue\n",
    "for p, df_pen in tqdm.tqdm(df.groupby('PenID')):\n",
    "        \n",
    "    #update results\n",
    "    dico_pen_level_h[p] = {}\n",
    "    \n",
    "    #compute time series\n",
    "    df_ts = time_series_henColumn_tsRow(df_pen, config, col_ts='Zone', ts_with_all_hen_value=False, save=False, \n",
    "                                        hen_time_series=False)\n",
    "    \n",
    "    #restrict to the daylight ONLY\n",
    "    df_ts['is_day'] = df_ts['Timestamp'].map(lambda x: is_day(x, config.dico_night_hour))\n",
    "    df_ts = df_ts[df_ts['is_day']]\n",
    "\n",
    "    #list of all hen present in this pen\n",
    "    li_hen = [v for v in df_ts.columns if 'hen_' in v]\n",
    "\n",
    "    ################# create one list per animal #################\n",
    "    #groupby date to have a list of zones per day (rows) for the hens (columns)\n",
    "    df_ts = df_ts.groupby('date')[li_hen].agg(lambda x: list(x)).reset_index()\n",
    "    #melt to have one row per (day, hens) to avoid looping to create the dictionary\n",
    "    df_ts_ = pd.melt(df_ts, id_vars=['date'], value_vars=li_hen)\n",
    "    for d, df__ in df_ts_.groupby(['date']):\n",
    "        #update results: value column is the list of zone\n",
    "        dico_pen_level_h[p][d] = dict(zip(df__['HenID'].tolist(), df__['value'].tolist()))   \n",
    "    \n",
    "#save dictionaries\n",
    "pickle.dump(dico_pen_level_h, open(os.path.join(path_extracted_data, \n",
    "                                                id_run+'dico_pen_level_h_allzoneidseclevel_DAILYLEVEL.pkl'), 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance across pairs of MLPS from same day - for ranging study Mike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the MLPs vectors during day only! as we compare on same day, we can restrict to the exact daily calendar!\n",
    "dico_pen_level_h = pickle.load(open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_level_h_allzoneidseclevel_DAILYLEVEL.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#dico of hen as keys and pen as values\n",
    "dico_h_p = dict(zip(df_daily['HenID'].tolist(), df_daily['PenID'].tolist()))\n",
    "df_ = df_daily.groupby('PenID')['HenID'].agg(lambda x: list(set(x))).reset_index()\n",
    "dico_penid_lihen = dict(zip(df_['PenID'].tolist(), df_['HenID'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#first we have to add 8 random pens with equal amount of animals from all pens (lets say 2)\n",
    "list(df_daily['HenID'].unique())\n",
    "np.random.seed(0) #fix random seed for reproducibility\n",
    "#random.sample(): randomly pick more than one element from the list without repeating elements.\n",
    "dico_randompID_lihen = {}\n",
    "k=1\n",
    "while k<9:\n",
    "    dico_randompID_lihen['pen_R'+str(k)] = []\n",
    "    for p,li_hen_p in dico_penid_lihen.items():\n",
    "        dico_randompID_lihen['pen_R'+str(k)].extend(random.sample(li_hen_p, 2))\n",
    "    k = k+1\n",
    "    \n",
    "#associate to each real penID a random penID for simplicity of next code paragraph\n",
    "dico_preal_prandom = {'pen10':'pen_R1', 'pen11':'pen_R2', 'pen12':'pen_R3', 'pen3':'pen_R4', \n",
    "                      'pen4':'pen_R5', 'pen5':'pen_R6', 'pen8':'pen_R7', 'pen9':'pen_R8'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that we cant say to selet a same number of proximity pre pen-penrandom, as we shoudl deal with animals we have. as they are selected at random, there should be around the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "  0%|                                                                                          | 0/211 [00:00<?, ?it/s]C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      " 16%|███████████▉                                                                | 33/211 [1:09:58<8:14:29, 166.68s/it]"
     ]
    }
   ],
   "source": [
    "#start recording the time it last\n",
    "START_TIME = time.perf_counter()\n",
    "np.random.seed(0) #fix random seed for reproducibility\n",
    "li_df = []\n",
    "li_date = sorted(set(df_daily['level'].tolist()))\n",
    "for d in tqdm.tqdm(li_date):\n",
    "    #list of hens available that day (i.e. functioning tags)\n",
    "    li_hen_d = df_daily[df_daily['level']==d]['HenID'].unique()\n",
    "    #for each pen separately to ensure the correct amount of proximities among animal fram same pen and different to be computed\n",
    "    #In other words, for each pen we will compute (1) the proximities between any hens in that pen and (2) the proximity of\n",
    "    for p, li_hen in dico_penid_lihen.items():\n",
    "        #list of avaialable hens for day \"d\" that belongs to that pen\n",
    "        li_hen_samepen = [x for x in li_hen_d if x in li_hen]\n",
    "        li_hen_d_diffpens = [x for x in li_hen_d if x in dico_randompID_lihen[dico_preal_prandom[p]]]\n",
    "        for LI,type_,penID in [(li_hen_samepen, 'realpen',p),(li_hen_d_diffpens, 'randompen',dico_preal_prandom[p])]:\n",
    "            for i in range(0,len(LI)):\n",
    "                h1 = LI[i]\n",
    "                for h2 in LI[i+1:]:\n",
    "                    #compute the number of commun values in the list of zone over the day\n",
    "                    #turn into numpy arrays to allow for efficien entry by entry comparison of the two vectors\n",
    "                    l1 = np.array(dico_pen_level_h[dico_h_p[h1]][d][h1]) #we cant put p instead of dico_h_p[h1], as we hav ehte random pens as well\n",
    "                    l2 = np.array(dico_pen_level_h[dico_h_p[h2]][d][h2])\n",
    "                    if len(l1)==len(l2):\n",
    "                        li_df.append({'HenID1':h1,'HenID2':h2,'date':d,'verification':(),\n",
    "                                      'total_nbr_sec_involved':len(l1),'nbr_sec_withCommunZone':sum(l1==l2),\n",
    "                                      'PenID1':dico_h_p[h1], 'PenID2':dico_h_p[h2], 'type_':type_,'PenID':penID})\n",
    "                    else:\n",
    "                        li_df.append({'HenID1':h1,'HenID2':h2,'date':d,'verification':(len(l1),len(l2)),\n",
    "                                      'total_nbr_sec_involved':np.nan,'nbr_sec_withCommunZone':np.nan,\n",
    "                                      'PenID1':dico_h_p[h1], 'PenID2':dico_h_p[h2],'type_':type_,'PenID':penID})\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "df_prox = pd.DataFrame(li_df)\n",
    "df_prox['perc_time_with_communZone'] = df_prox.apply(lambda x: x['nbr_sec_withCommunZone']/x['total_nbr_sec_involved']*100, \n",
    "                                                     axis=1)\n",
    "df_prox['hen_pair'] = df_prox.apply(lambda x: '-'.join(sorted([x['HenID1'],x['HenID2']])), axis=1)\n",
    "df_prox['pen_pair'] = df_prox.apply(lambda x: '-'.join(sorted([x['PenID1'],x['PenID2']])), axis=1)\n",
    "#save\n",
    "df_prox.to_csv(os.path.join(path_extracted_data_proximity, 'df_prox.csv'), index=False, sep=';')\n",
    "print(df_prox.shape)\n",
    "df_prox.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prox.to_csv(os.path.join(path_extracted_data_proximity, 'df_prox.csv'), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15526, 13)\n",
      "(15526, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID1</th>\n",
       "      <th>HenID2</th>\n",
       "      <th>date</th>\n",
       "      <th>verification</th>\n",
       "      <th>total_nbr_sec_involved</th>\n",
       "      <th>nbr_sec_withCommunZone</th>\n",
       "      <th>PenID1</th>\n",
       "      <th>PenID2</th>\n",
       "      <th>type_</th>\n",
       "      <th>PenID</th>\n",
       "      <th>perc_time_with_communZone</th>\n",
       "      <th>hen_pair</th>\n",
       "      <th>pen_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_134</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>19</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>hen_131-hen_134</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_138</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>20895</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>72.552083</td>\n",
       "      <td>hen_131-hen_138</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_139</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>1050</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>hen_131-hen_139</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HenID1   HenID2       date verification  total_nbr_sec_involved  \\\n",
       "0  hen_131  hen_134 2020-09-30           ()                   28800   \n",
       "1  hen_131  hen_138 2020-09-30           ()                   28800   \n",
       "2  hen_131  hen_139 2020-09-30           ()                   28800   \n",
       "\n",
       "   nbr_sec_withCommunZone PenID1 PenID2    type_  PenID  \\\n",
       "0                      19  pen10  pen10  realpen  pen10   \n",
       "1                   20895  pen10  pen10  realpen  pen10   \n",
       "2                    1050  pen10  pen10  realpen  pen10   \n",
       "\n",
       "   perc_time_with_communZone         hen_pair     pen_pair  \n",
       "0                   0.065972  hen_131-hen_134  pen10-pen10  \n",
       "1                  72.552083  hen_131-hen_138  pen10-pen10  \n",
       "2                   3.645833  hen_131-hen_139  pen10-pen10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID1</th>\n",
       "      <th>HenID2</th>\n",
       "      <th>date</th>\n",
       "      <th>verification</th>\n",
       "      <th>total_nbr_sec_involved</th>\n",
       "      <th>nbr_sec_withCommunZone</th>\n",
       "      <th>PenID1</th>\n",
       "      <th>PenID2</th>\n",
       "      <th>type_</th>\n",
       "      <th>PenID</th>\n",
       "      <th>perc_time_with_communZone</th>\n",
       "      <th>hen_pair</th>\n",
       "      <th>pen_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_134</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>19</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>0.065972</td>\n",
       "      <td>hen_131-hen_134</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_138</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>20895</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>72.552083</td>\n",
       "      <td>hen_131-hen_138</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_131</td>\n",
       "      <td>hen_139</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>()</td>\n",
       "      <td>28800</td>\n",
       "      <td>1050</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>realpen</td>\n",
       "      <td>pen10</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>hen_131-hen_139</td>\n",
       "      <td>pen10-pen10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HenID1   HenID2       date verification  total_nbr_sec_involved  \\\n",
       "0  hen_131  hen_134 2020-09-30           ()                   28800   \n",
       "1  hen_131  hen_138 2020-09-30           ()                   28800   \n",
       "2  hen_131  hen_139 2020-09-30           ()                   28800   \n",
       "\n",
       "   nbr_sec_withCommunZone PenID1 PenID2    type_  PenID  \\\n",
       "0                      19  pen10  pen10  realpen  pen10   \n",
       "1                   20895  pen10  pen10  realpen  pen10   \n",
       "2                    1050  pen10  pen10  realpen  pen10   \n",
       "\n",
       "   perc_time_with_communZone         hen_pair     pen_pair  \n",
       "0                   0.065972  hen_131-hen_134  pen10-pen10  \n",
       "1                  72.552083  hen_131-hen_138  pen10-pen10  \n",
       "2                   3.645833  hen_131-hen_139  pen10-pen10  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prox = pd.DataFrame(li_df)\n",
    "df_prox['perc_time_with_communZone'] = df_prox.apply(lambda x: x['nbr_sec_withCommunZone']/x['total_nbr_sec_involved']*100, \n",
    "                                                     axis=1)\n",
    "df_prox['hen_pair'] = df_prox.apply(lambda x: '-'.join(sorted([x['HenID1'],x['HenID2']])), axis=1)\n",
    "df_prox['pen_pair'] = df_prox.apply(lambda x: '-'.join(sorted([x['PenID1'],x['PenID2']])), axis=1)\n",
    "print(df_prox.shape)\n",
    "df_prox.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small verification of results\n",
    "#the penID of both hens are the same for type_ =real\n",
    "if df_prox[(df_prox['PenID1']!=df_prox['PenID2'])&(df_prox['type_']=='realpen')].shape[0]!=0:\n",
    "    print('ERROR: VIOLATED: penID of both hens are the same for type_ =real')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check NA (i.e. when the two list of one sec categorical time series do not match)\n",
    "if df_prox[df_prox['nbr_sec_withCommunZone'].isnull()].shape[0]!=0:\n",
    "    print('ERROR: some compared MLPS did not had the same number of observations!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the number of secodns compared\n",
    "sns.lineplot(x='date', y='total_nbr_sec_involved', data=df_prox);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check properly once we have defined dates!!\n",
    "#check number of observations per day per penID\n",
    "df_ = df_prox.groupby(['date','PenID'])['hen_pair'].count().reset_index()\n",
    "df_.groupby('date')['hen_pair'].agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations of proximity per true pen & random pen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets compute the correlation from proximities on day x to proximities on day x+1 and plot these correaltion with x on x a-xis and spearman correlation coefficient on y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!    copy paste from: https://gist.github.com/zhiyzuo/d38159a7c48b575af3e3de7501462e04     !!\n",
    "def pearsonr_ci(x,y,alpha=0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : iterable object such as a list or np.array\n",
    "      Input for correlation calculation\n",
    "    alpha : float\n",
    "      Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "      Pearson's correlation coefficient\n",
    "    pval : float\n",
    "      The corresponding p value\n",
    "    lo, hi : float\n",
    "      The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "\n",
    "    r, p = stats.pearsonr(x,y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(x.size-3)\n",
    "    z = stats.norm.ppf(1-alpha/2)\n",
    "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    return r, p, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize list to save results\n",
    "li = []\n",
    "#put the date into the columns, so that we can correalte date x with date x+1\n",
    "df_pivot = df_prox.pivot(index=['hen_pair','type_','PenID'], values='perc_time_with_communZone', columns='date').reset_index()\n",
    "print(df_pivot.shape)\n",
    "display(df_pivot.head(5))\n",
    "for pendID, df_ in df_pivot.groupby(['PenID']):\n",
    "    li_date_ = [x for x in li_date if x in list(df_.columns)]\n",
    "    for d1 in li_date_: \n",
    "        d2 = d1+dt.timedelta(days=1)\n",
    "        if d2 in li_date_:\n",
    "            df_ = df_.dropna(subset=[d1,d2])\n",
    "            #lets for now set a need of at least 50 obs to compute a correlation\n",
    "            if df_.shape[0]>50:\n",
    "                coeff, p_val = pearsonr(df_[d1].tolist(), df_[d2].tolist()) #coeff, p-val\n",
    "                r, p, lo, hi = pearsonr_ci(np.array(df_[d1].tolist()), np.array(df_[d2].tolist()))\n",
    "                #update results\n",
    "                li.append({'coeff':coeff, 'p_val':p_val, 'd1':d1, 'd2':d2, 'nbr_obs':df_.shape[0],\n",
    "                           'L':lo, 'H':hi,'verif':(r,p),'PenID':pendID})\n",
    "df_corr_res = pd.DataFrame(li)\n",
    "#save\n",
    "df_corr_res.to_csv(os.path.join(path_extracted_data_proximity, 'df_corr_res.csv'), index=False, sep=';')\n",
    "print(df_corr_res.shape)\n",
    "display(df_corr_res.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visual\n",
    "#df_plt = df_corr_res[df_corr_res['nbr_obs']>=80].copy()\n",
    "#future MLPs alltreatment\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "graph = sns.lineplot(x='d1',y='coeff',hue='PenID',data=df_corr_res);\n",
    "graph.axhline(0, color='black')\n",
    "plt.savefig(os.path.join(path_extracted_data_proximity, 'Proximity_correalationdayx&dayx+1.png'), dpi=300,\n",
    "            format='png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
