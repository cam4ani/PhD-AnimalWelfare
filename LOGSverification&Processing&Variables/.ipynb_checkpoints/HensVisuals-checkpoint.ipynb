{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import math\n",
    "#plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UTILS import ts_compare_session, TimeSeriesPlot, DistributionEntropy, sample_entropy, sequence_without_cez, \\\n",
    "list_of_durations, dico_zone_notsortedduration, dico_zone_sortedduration, dico_zone_nbrminStartswith, cum_nbr_boots,\\\n",
    "cum_duration_z\n",
    "import config_mobility as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_extracted_data = config.path_extracted_data\n",
    "id_run = config.id_run\n",
    "nbr_sec = config.nbr_sec\n",
    "li_day_hours = config.li_day_hours \n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "p = r'C:\\Users\\camil\\Desktop\\animals_code\\AVIFORUM\\data\\initial_data_mobility'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_int_event = pd.read_csv(os.path.join(path_extracted_data,'df_int_event.csv'), sep=';')\n",
    "df_not_int_event = pd.read_csv(os.path.join(path_extracted_data,'df_not_int_event.csv'), sep=';')\n",
    "df_int_event = df_int_event.reset_index(drop=True)\n",
    "df_not_int_event = df_not_int_event.reset_index(drop=True)\n",
    "print(df_int_event.shape)\n",
    "print(df_not_int_event.shape)\n",
    "df_event = pd.concat([df_int_event,df_not_int_event])\n",
    "display(df_int_event.head(3))\n",
    "df_not_int_event.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event[(df_event['HenID']=='hen_100')] #& df_event['sessionNumber']==5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split some visual regarding session wihtout keel bone fracture vs session with keel bone fracture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot_path = os.path.join(path_extracted_data, 'visual', 'egg','boots_duration_daytime')\n",
    "plot_path_new = os.path.join(plot_path, 'session_comparison')\n",
    "plot_path_int = os.path.join(plot_path, 'session_comparison', 'KF')\n",
    "plot_path_notint = os.path.join(plot_path, 'session_comparison', 'NKF')\n",
    "plot_path_intafter = os.path.join(plot_path, 'session_comparison', 'KFA')\n",
    "for p in [plot_path_new, plot_path_int, plot_path_notint, plot_path_intafter]:\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for path_visual in glob.glob(os.path.join(plot_path,'*.png')):\n",
    "    HenID = path_visual.split('hen_')[1].split('_')[0]\n",
    "    sessionID = path_visual.split('\\\\')[-1].split('__')[1]\n",
    "    sessionNumber = sessionID[:-1]\n",
    "    is_int = df_event[(df_event['HenID']=='hen_'+str(HenID))&(df_event['sessionNumber']==int(sessionNumber))]['is_interesting_event'].values\n",
    "    is_not_int = df_event[(df_event['HenID']=='hen_'+str(HenID))&(df_event['sessionNumber']==int(sessionNumber))]['is_not_interesting_event'].values\n",
    "    is_intafter = df_event[(df_event['HenID']=='hen_'+str(HenID))&(df_event['sessionNumber']==int(sessionNumber)-1)]['is_interesting_event'].values\n",
    "\n",
    "    name = path_visual.split('\\\\')[-1]\n",
    "    if len(is_int)==1:\n",
    "        if is_int[0]:\n",
    "            shutil.copy(path_visual, os.path.join(plot_path_int, name))\n",
    "    if len(is_not_int)==1:\n",
    "        if is_not_int[0]:\n",
    "            shutil.copy(path_visual, os.path.join(plot_path_notint, name))\n",
    "    if len(is_intafter)==1:\n",
    "        if is_intafter[0]:\n",
    "            shutil.copy(path_visual, os.path.join(plot_path_intafter, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'overall','density')\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    df_ts['time'] = df_ts['Timestamp'].map(lambda x: dt.datetime.time(x))\n",
    "    df_ts['time'] = df_ts['time'].map(lambda x: round(x.hour + x.minute/60,1))\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    #value taken from : sns.color_palette(\"husl\", 5)\n",
    "    palette ={'zone_3':(0.9677975592919913, 0.44127456009157356, 0.5358103155058701),\n",
    "              'zone_2':(0.6804189127793346, 0.6151497514677574, 0.19405452111445337),\n",
    "              'zone_1':(0.20125317221201128, 0.6907920815379025, 0.47966761189275336),\n",
    "              'zone_5':(0.2197995660828324, 0.6625157876850336, 0.7732093159317209),\n",
    "              'zone_4':(0.8004936186423958, 0.47703363533737203, 0.9579547196007522)}\n",
    "    for HenID in li_hen:\n",
    "        title = 'Nestbox density '+HenID+' '+sessID\n",
    "        #if already exists then dont do it\n",
    "        if len(glob.glob(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png')))==1:\n",
    "            continue\n",
    "        fig, ax = plt.subplots(figsize=(19,6))\n",
    "        #lets take the entry of egg zone only, and plot a density of the corrsponding hour\n",
    "        df = df_ts[['day', 'time', HenID]].reset_index(drop=True).copy()\n",
    "        df = df.sort_values(HenID)\n",
    "        #if the hen stayed longer than 1minute in total\n",
    "        if df.shape[0]>60:\n",
    "            #plot: taken from https://seaborn.pydata.org/examples/kde_ridgeplot\n",
    "            sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "            # Initialize the FacetGrid object\n",
    "            g = sns.FacetGrid(df, row=\"day\", hue=HenID, size=3, aspect=5, palette=palette)\n",
    "            g.set(xlim=(2, 18))\n",
    "            # Draw the densities in a few steps\n",
    "            g.map(sns.kdeplot, \"time\", clip_on=False, shade=True, alpha=0.65, lw=1.5, bw=.2).add_legend()\n",
    "            g.map(sns.kdeplot, \"time\", clip_on=False, color=\"w\", lw=2, bw=.2)\n",
    "            #g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "            g.fig.subplots_adjust(hspace=0.1) #set the subplots to overlap #-.25 a little\n",
    "            #g.set_titles(\"\")\n",
    "            g.set(yticks=[])\n",
    "            g.despine(bottom=True, left=True)\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "            plt.close()        \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### density of number of boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'overall','density_nbrboots')\n",
    "dico_did_color = {0:'firebrick', 1:'red', 2:'orange', 3:'gold', 4:'yellow', 5:'khaki'}\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'li_boots_starting_sec_'+h: lambda x: li_boots_starting_sec(list(x),1)} for h in li_hen}).reset_index()\n",
    "    for HenID in li_hen:\n",
    "        for did,d in enumerate(sorted(df_h_all['day'].unique())):\n",
    "            title = '#bouts density - '+HenID+' '+sessID+' '+str(d).split('T')[0]\n",
    "            li = df_h_all[df_h_all['day']==d][HenID]['li_boots_starting_sec_'+HenID].values[0]\n",
    "            #into minutes\n",
    "            li = [round(x/60,1) for x in li]\n",
    "            sns.distplot(li, hist=True, kde=True, bins=int(len(li)/1), color='darkblue', \n",
    "                         hist_kws={'edgecolor':'black'},kde_kws={'linewidth': 4});\n",
    "            if save:\n",
    "                plt.title(title)\n",
    "                plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "            plt.close()      \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total number of boots (with 95% of transition point) ONE PER HEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'overall','nbrboots_daytime')\n",
    "dico_did_color = {0:'firebrick', 1:'red', 2:'orange', 3:'gold', 4:'yellow', 5:'khaki'}\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'cum_nbr_boots_'+h: lambda x: cum_nbr_boots(list(x))} for h in li_hen}).reset_index()\n",
    "    for HenID in li_hen:\n",
    "        title = HenID+' '+sessID+' '\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        for did,d in enumerate(sorted(df_h_all['day'].unique())):\n",
    "            df_h = df_h_all[df_h_all['day']==d]\n",
    "            #find maximum daily number of boots over the whole days\n",
    "            l = df_h_all[HenID].stack().tolist()\n",
    "            my = max([l[k][-1] for k in range(len(l))])\n",
    "            #plot\n",
    "            v = df_h[HenID]\n",
    "            y = v['cum_nbr_boots_'+HenID].values[0]\n",
    "            x = [2]+[(i+1)/60/60+2 for i in range(len(y))]\n",
    "            y = [0]+y\n",
    "            ax.set_xlim(1, 18)\n",
    "            ax.set_ylim(-1, my+max(0.05*my,1))\n",
    "            plt.plot(x, y, dico_did_color[did])\n",
    "            #add info on 95%\n",
    "            p95 = math.ceil(max(y)*0.95) #round up (if a 95% cest au milieu dune boots, on arondi a celle d'apres)\n",
    "            plt.axvline(x=x[y.index(p95)], color=dico_did_color[did], alpha=0.6)\n",
    "            did = did + 1\n",
    "        if save:\n",
    "            plt.title(title)\n",
    "            plt.xlabel('hour of the day'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "        plt.close()      \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total number of boots (with 95% of transition point) ONE PER DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'overall','nbrboots_daytime_1perday')\n",
    "dico_did_color = {0:'firebrick', 1:'red', 2:'orange', 3:'gold', 4:'yellow', 5:'khaki'}\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'cum_nbr_boots_'+h: lambda x: cum_nbr_boots(list(x))} for h in li_hen}).reset_index()\n",
    "    for d in sorted(df_h_all['day'].unique()):\n",
    "        df_h = df_h_all[df_h_all['day']==d]\n",
    "        title = str(d).split('T')[0]+' '+sessID+' '\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        for HenID in li_hen:\n",
    "            #find maximum daily number of boots over the whole days\n",
    "            l = df_h_all[HenID].stack().tolist()\n",
    "            my = max([l[k][-1] for k in range(len(l))])\n",
    "            #plot\n",
    "            v = df_h[HenID]\n",
    "            y = v['cum_nbr_boots_'+HenID].values[0]\n",
    "            x = [2]+[(i+1)/60/60+2 for i in range(len(y))]\n",
    "            y = [0]+y\n",
    "            ax.set_xlim(1, 18)\n",
    "            #ax.set_ylim(-1, my+max(0.05*my,1))\n",
    "            plt.plot(x, y)\n",
    "            #add info on 95%\n",
    "            p95 = math.ceil(max(y)*0.95) #round up (if a 95% cest au milieu dune boots, on arondi a celle d'apres)\n",
    "            plt.axvline(x=x[y.index(p95)], alpha=0.6)\n",
    "        if save:\n",
    "            plt.title(title)\n",
    "            plt.xlabel('hour of the day'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "        plt.close()      \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cumulative duration in nestboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "egg_zone = 'zone_4'\n",
    "p = 0.75\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','cumduration_daytime')\n",
    "dico_did_color = {0:'firebrick', 1:'red', 2:'orange', 3:'gold', 4:'yellow', 5:'khaki'}\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'cum_duration_z_'+h: lambda x: cum_duration_z(list(x),egg_zone)} for h in li_hen}).reset_index()\n",
    "    for HenID in li_hen:\n",
    "        title = HenID+' '+sessID+' '+' (line )'+str(p).split('.')[-1]+'%'\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        for did,d in enumerate(sorted(df_h_all['day'].unique())):\n",
    "            df_h = df_h_all[df_h_all['day']==d]\n",
    "            #find maximum daily number of boots over the whole days\n",
    "            l = df_h_all[HenID].stack().tolist()\n",
    "            my = max([l[k][-1] for k in range(len(l))])\n",
    "            #plot\n",
    "            v = df_h[HenID]\n",
    "            y = v['cum_duration_z_'+HenID].values[0]\n",
    "            x = [2]+[(i+1)/60/60+2 for i in range(len(y))]\n",
    "            y = [0]+y #not putting into h si non plus compliquÃ© pour trouver les p%\n",
    "            ax.set_xlim(1, 18)\n",
    "            ax.set_ylim(0-max(0.05*my,1), my+max(0.05*my,1))\n",
    "            plt.plot(x, y, dico_did_color[did])\n",
    "            #add info on %\n",
    "            p_ = math.ceil(max(y)*p) #round up (if a p% cest au milieu dune boots, on arondi a celle d'apres)\n",
    "            plt.axvline(x=x[y.index(p_)], color=dico_did_color[did], alpha=0.6)\n",
    "            did = did + 1\n",
    "        if save:\n",
    "            plt.title(title)\n",
    "            plt.xlabel('hour of the day'); \n",
    "            plt.ylabel('cumulative duration (sec)');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "        plt.close()      \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','density')\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    df_ts['time'] = df_ts['Timestamp'].map(lambda x: dt.datetime.time(x))\n",
    "    df_ts['time'] = df_ts['time'].map(lambda x: round(x.hour + x.minute/60,1))\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    #sys.exit()\n",
    "    for HenID in li_hen:\n",
    "        title = 'Nestbox density '+HenID+' '+sessID\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        #lets take the entry of egg zone only, and plot a density of the corrsponding hour\n",
    "        df = df_ts[df_ts[HenID]==egg_zone][['day','time']].reset_index(drop=True).copy()\n",
    "        #if the hen stayed longer than 1minute in total\n",
    "        if df.shape[0]>60:\n",
    "            #plot: taken from https://seaborn.pydata.org/examples/kde_ridgeplot\n",
    "            sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "            # Initialize the FacetGrid object\n",
    "            pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\n",
    "            g = sns.FacetGrid(df, row=\"day\", hue=\"day\", aspect=5, palette=pal)\n",
    "            g.set(xlim=(2, 18))\n",
    "            # Draw the densities in a few steps\n",
    "            g.map(sns.kdeplot, \"time\", clip_on=False, shade=True, alpha=1, lw=1.5, bw=.2)\n",
    "            g.map(sns.kdeplot, \"time\", clip_on=False, color=\"w\", lw=2, bw=.2)\n",
    "            g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "            # Define and use a simple function to label the plot in axes coordinates\n",
    "            def label(x, color, label):\n",
    "                ax = plt.gca()\n",
    "                ax.text(0, .2, label, fontweight=\"bold\", color=color,ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "            g.map(label, \"time\")\n",
    "            g.fig.subplots_adjust(hspace=-.25) #set the subplots to overlap\n",
    "            g.set_titles(\"\")\n",
    "            g.set(yticks=[])\n",
    "            g.despine(bottom=True, left=True)\n",
    "            if save:\n",
    "                plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "            plt.close()      \n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nbr boots vs time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "good to see if a lot of boot in the morning before no more for a while and then again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','nbrboots_daytime')\n",
    "dico_did_color = {0:'firebrick', 1:'red', 2:'orange', 3:'gold', 4:'yellow', 5:'khaki'}\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'dico_zone_notsortedduration_'+h: lambda x: dico_zone_notsortedduration(x,1),\n",
    "                                               'dico_zone_nbrminStartswith_'+h:lambda x: dico_zone_nbrminStartswith(x,1)} for h in li_hen}).reset_index()\n",
    "    for HenID in li_hen:\n",
    "        title = HenID+'  '+sessID+'  '\n",
    "        for did,d in enumerate(sorted(df_h_all['day'].unique())):\n",
    "            df_h = df_h_all[df_h_all['day']==d]\n",
    "            v = df_h[HenID]\n",
    "            dur = v['dico_zone_notsortedduration_'+HenID].values[0].get(egg_zone,[0])\n",
    "            #y = np.array([0]+[(i+1)/len(dur)*100 for i in range(len(dur))])\n",
    "            y = np.array([0]+[i+1 for i in range(len(dur))])\n",
    "            #not good to add percentage car number of boots is not enough\n",
    "            c = v['dico_zone_nbrminStartswith_'+HenID].values[0].get(egg_zone,[0])\n",
    "            c = np.array([2]+[i/60/60+2 for i in c]) #put into hours\n",
    "            plt.plot(c,y,dico_did_color[did])\n",
    "            did = did + 1\n",
    "        if save:\n",
    "            plt.title(title+' - nestbox')\n",
    "            plt.xlabel('time'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "        plt.close()      \n",
    "#exemple of dur and \n",
    "#t = [1,1,1,1,2,2,2,3,3,3,4,4,2,2,2,2,1]\n",
    "#dico_zone_notsortedduration(t,1), dico_zone_nbrminStartswith(t,1)\n",
    "# ({1: [4, 1], 2: [3, 4], 3: [3], 4: [2]},\n",
    "# {1: [1, 17], 2: [5, 13], 3: [8], 4: [11]})\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nbr boots vs cumulative duration (color: time of the day)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "including last boots duration as we want to see when he entered the zone for a long time what time it was wihtout needing to compute it. should be pink to stil be possible for laying egg      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one line plot per day with all hens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "time_series_plot = True\n",
    "normalized = True #no choice\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','boots_duration_daytime_1perdayallhens')\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'dico_zone_notsortedduration_'+h: lambda x: dico_zone_notsortedduration(x,1),\n",
    "                                               'dico_zone_nbrminStartswith_'+h:lambda x: dico_zone_nbrminStartswith(x,1)} for h in li_hen}).reset_index()\n",
    "    for d in sorted(df_h_all['day'].unique()):\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        title = 'Nestbox - '+str(d).split('T')[0]+' '+sessID+' '\n",
    "        df_h = df_h_all[df_h_all['day']==d]\n",
    "        if normalized:\n",
    "            title = title+'  normalized'\n",
    "        for HenID in li_hen:\n",
    "            v = df_h[HenID]\n",
    "            dur = v['dico_zone_notsortedduration_'+HenID].values[0].get(egg_zone,[0])\n",
    "            if normalized:\n",
    "                x = np.array([0]+[i/sum(dur)*100 for i in np.cumsum(dur)]) #into minutes\n",
    "                y = np.array([0]+[(i+1)/len(dur)*100 for i in range(len(dur))])\n",
    "            else:\n",
    "                x = np.array([0]+[i for i in np.cumsum(dur)]) #into minutes\n",
    "                y = np.array([0]+list(range(1,len(dur)-1)))\n",
    "            c = v['dico_zone_nbrminStartswith_'+HenID].values[0].get(egg_zone,[0])\n",
    "            c = np.array([i/60 for i in c]) #put into minutes\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"violet\",\"blue\"])\n",
    "            norm = BoundaryNorm(range(0,len(li_day_hours)*60,1), cmap.N)\n",
    "            points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "            lc.set_array(c)\n",
    "            lc.set_linewidth(2)\n",
    "            line = ax.add_collection(lc)\n",
    "            #fig.colorbar(line, ax=ax)\n",
    "            if normalized:\n",
    "                ax.set_xlim(-2, 102)\n",
    "                ax.set_ylim(-2, 102)\n",
    "            #TODO IF NOT NORMALIZED\n",
    "                \n",
    "        if save:\n",
    "            plt.title(title)\n",
    "            plt.xlabel('cumulative #minutes (incl. duration of last boot)'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "        plt.close()      \n",
    "\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one line plot per session for each hen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','boots_duration_daytime')\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    sessID = path_.split('_')[-1].split('.')[0]\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'dico_zone_notsortedduration_'+h: lambda x: dico_zone_notsortedduration(x,1),\n",
    "                                               'dico_zone_nbrminStartswith_'+h:lambda x: dico_zone_nbrminStartswith(x,1)} for h in li_hen}).reset_index()\n",
    "    for HenID in li_hen:\n",
    "        title = HenID+'  '+sessID+'  '\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        d_id = 1\n",
    "        for d in sorted(df_h_all['day'].unique()):\n",
    "            df_h = df_h_all[df_h_all['day']==d]\n",
    "            v = df_h[HenID]\n",
    "            dur = v['dico_zone_notsortedduration_'+HenID].values[0].get(egg_zone,[0])\n",
    "            x = np.array([0]+[i/sum(dur)*100 for i in np.cumsum(dur)]) #into minutes\n",
    "            y = np.array([0]+[(i+1)/len(dur)*100 for i in range(len(dur))])\n",
    "            c = v['dico_zone_nbrminStartswith_'+HenID].values[0].get(egg_zone,[0])\n",
    "            c = np.array([i/60 for i in c]) #put into minutes\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"violet\",\"blue\"])\n",
    "            norm = BoundaryNorm(range(0,len(li_day_hours)*60,1), cmap.N)\n",
    "            points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "            lc.set_array(c)\n",
    "            lc.set_linewidth(d_id)\n",
    "            line = ax.add_collection(lc)\n",
    "            #fig.colorbar(line, ax=ax)\n",
    "            ax.set_xlim(-2, 102)\n",
    "            ax.set_ylim(-2, 102)\n",
    "            #slope: each slope have the same height value, but the length value varie depending on the duration: so the more the slop is \n",
    "            #flat the longer is the boot\n",
    "            #color: the color of each line correpsond to the starting timestamp of the second boot of the line (i.e. the endpoint)\n",
    "            d_id = d_id + 1\n",
    "        if save:\n",
    "            plt.title(title+' - nestbox')\n",
    "            plt.xlabel('cumulative #minutes (incl. duration of last boot)'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'_ALL.png'), format='png')\n",
    "        plt.close()      \n",
    "\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One bubble plot per pen per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE PER DAY WITH ALL HEN\n",
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*.csv'))\n",
    "li_path = [i for i in li_path if '_hen_' not in i]\n",
    "save = True\n",
    "egg_zone = 'zone_4'\n",
    "time_series_plot = True\n",
    "dico_z_color = config.dico_z_color\n",
    "dico_zone_order = config.dico_zone_order\n",
    "path_save = os.path.join(path_extracted_data, 'visual', 'egg','boots_duration_daytime_1perpen')\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "for path_ in tqdm.tqdm(li_path):\n",
    "    #download time series associated to this session\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    #keep only form 2h to 17h\n",
    "    df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "    df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "    li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "    df_h_all = df_ts.groupby(['day']).agg({h: {'dico_zone_notsortedduration_'+h: lambda x: dico_zone_notsortedduration(x,1),\n",
    "                                               'dico_zone_nbrminStartswith_'+h:lambda x: dico_zone_nbrminStartswith(x,1)} for h in li_hen}).reset_index()\n",
    "    for d in df_h_all['day'].unique():\n",
    "        df_h = df_h_all[df_h_all['day']==d]\n",
    "        for HenID in li_hen:\n",
    "            title = str(d).split('T')[0]+' all hens '\n",
    "            #if already exists then dont do it\n",
    "            if len(glob.glob(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png')))==1:\n",
    "                continue\n",
    "            v = df_h[HenID]\n",
    "            dur = v['dico_zone_notsortedduration_'+HenID].values[0].get(egg_zone,[0])\n",
    "            x = np.cumsum(dur)/sum(dur)*100\n",
    "            #x = [i/60 for i in np.cumsum(dur)] #into minutes\n",
    "            y = [(i+1)/len(dur)*100 for i in range(len(dur))]\n",
    "            #y = range(1, len(dur)+1)\n",
    "            c = v['dico_zone_nbrminStartswith_'+HenID].values[0].get(egg_zone,[0])\n",
    "            c = [i/60 for i in c] #put into minutes\n",
    "            norm=plt.Normalize(0,len(li_day_hours)*60)\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"violet\",\"blue\"])\n",
    "            plt.xlim(-5,105)\n",
    "            plt.ylim(-5,105)\n",
    "            #plt.colorbar()\n",
    "            plt.scatter(x, y, c=c, cmap=cmap, norm=norm, s=[(k/60) for k in dur], alpha=0.75) \n",
    "        if save:\n",
    "            plt.title(title+' - nestbox')\n",
    "            plt.xlabel('cumulative #minutes (incl. duration of last boot)'); \n",
    "            plt.ylabel('#boots');\n",
    "            plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "#exemple of dur and \n",
    "#t = [1,1,1,1,2,2,2,3,3,3,4,4,2,2,2,2,1]\n",
    "#dico_zone_notsortedduration(t,1), dico_zone_nbrminStartswith(t,1)\n",
    "# ({1: [4, 1], 2: [3, 4], 3: [3], 4: [2]},\n",
    "# {1: [1, 17], 2: [5, 13], 3: [8], 4: [11]})\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data representation 1: Color series visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "START_TIME = time.clock()\n",
    "# to save time computation we do all chicken together\n",
    "for type_ in ['B', 'A']:\n",
    "    li_path = glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*'+type_+'.csv'))\n",
    "    li_path = [i for i in li_path if '_hen_' not in i]\n",
    "    save = True\n",
    "    time_series_plot = True\n",
    "    dico_z_color = config.dico_z_color\n",
    "    dico_zone_order = config.dico_zone_order\n",
    "    path_save = os.path.join(path_extracted_data, 'visual', 'data_representation','representation_color_and_duration')\n",
    "    if not os.path.exists(path_save):\n",
    "        os.makedirs(path_save)\n",
    "    path_save_ts = os.path.join(path_save, 'time_series_plot')\n",
    "    if not os.path.exists(path_save_ts):\n",
    "        os.makedirs(path_save_ts)\n",
    "        \n",
    "    for path_ in tqdm.tqdm(li_path):\n",
    "        #download time series associated to this session\n",
    "        df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "        #keep only form 2h to 17h\n",
    "        df_ts = df_ts[df_ts['hour'].isin(li_day_hour)]\n",
    "        df_ts = df_ts.where(pd.notnull(df_ts), None)\n",
    "        li_hen = [x for x in df_ts.columns if x.startswith('hen_')]\n",
    "        df_h_all = df_ts.groupby(['day']).agg({h: {'li_zone_'+h: lambda x: sequence_without_cez(x),\n",
    "                                                   'li_duration_'+h: lambda x: list_of_durations(x,1),\n",
    "                                                   'li_ts_'+h: lambda x: list(x)} for h in li_hen}).reset_index()\n",
    "        for d in df_h_all['day'].unique():\n",
    "            df_h = df_h_all[df_h_all['day']==d]\n",
    "            for HenID in li_hen:\n",
    "                title = str(d).split('T')[0]+' '+HenID\n",
    "                #if already exists then dont do it\n",
    "                if len(glob.glob(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png')))==1:\n",
    "                    continue\n",
    "                v = df_h[HenID]\n",
    "                li_dur = v['li_duration_'+HenID].values[0]\n",
    "                li_z = v['li_zone_'+HenID].values[0]\n",
    "                li_ts = v['li_ts_'+HenID].values[0]\n",
    "                \n",
    "                #should not start with nan as it means it had missing dat and we dont want to compare apple with pear here\n",
    "                if li_ts[0]!=None:\n",
    "                    y = [i/2 for i in li_dur] \n",
    "                    x = range(len(y))\n",
    "                    fig = plt.figure()\n",
    "                    ax = plt.subplot(111)\n",
    "                    width=1\n",
    "                    ax.bar(range(len(x)), y, width=width, color=[dico_z_color.get(z,'white') for z in li_z])\n",
    "                    ax.set_xticks(np.arange(len(x)) + width/2)\n",
    "                    ax.bar(range(len(x)), [-i for i in y], width=width, color=[dico_z_color.get(z,'white') for z in li_z])\n",
    "                    ax.set_xticks(np.arange(len(x)) + width/2)\n",
    "                    plt.axis('off') \n",
    "                    plt.grid('off')\n",
    "                    plt.title(title)    \n",
    "                    if save:\n",
    "                        plt.savefig(os.path.join(path_save, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "                    plt.close()\n",
    "                    #plot individual time series for comparison\n",
    "                    if time_series_plot:\n",
    "                        ax = plt.subplot(111)\n",
    "                        ax.set_ylim([min(dico_zone_order.values()), max(dico_zone_order.values())])\n",
    "                        plt.plot(range(len(li_ts)), [dico_zone_order.get(z,'white') for z in li_ts])\n",
    "                        plt.axis('off') \n",
    "                        plt.grid('off')\n",
    "                        if save:\n",
    "                            plt.title(title) \n",
    "                            plt.savefig(os.path.join(path_save_ts, id_run+'_'+title.replace(' ','_')+'.png'), format='png')\n",
    "                            plt.close()\n",
    "        del df_ts\n",
    "        del df_h_all\n",
    "        del df_h\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specific events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: why after 40th only one plot instead of 12??\n",
    "for i in tqdm.tqdm(range(df_int_event.shape[0])):\n",
    "    x = df_int_event.iloc[i]\n",
    "    ts_compare_session(x['HenID'], str(int(x['previous_sessionNumber']))+x['group'], str(int(x['sessionNumber']))+x['group'], \n",
    "                       config, save=True, title='KF1: '+str(x['previous_severity'])+'       KF2: '+str(x['severity']),\n",
    "                       last_folder_name='session_comparison\\\\interesting_event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(df_not_int_event.shape[0])):\n",
    "    x = df_not_int_event.iloc[i]\n",
    "    ts_compare_session(x['HenID'], str(int(x['previous_sessionNumber']))+x['group'], str(int(x['sessionNumber']))+x['group'], \n",
    "                       config, save=True, title='KF1: '+str(x['previous_severity'])+'       KF2:'+str(x['severity']),\n",
    "                       last_folder_name='session_comparison\\\\not_interesting_event')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per hen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_ in tqdm.tqdm(glob.glob(os.path.join(path_extracted_data, id_run+'_TimeSeries_*'+'.csv'))):\n",
    "    \n",
    "    #download time series associated to this session\n",
    "    name_ = path_.split('_')[-1].split('.')[0]\n",
    "    print('-------------------------------------------------------------------------', name_)\n",
    "    df_ts = pd.read_csv(path_, sep=';', parse_dates=['Timestamp', 'day']) \n",
    "    df_ts = df_ts.sort_values('Timestamp', ascending=True)\n",
    "    TimeSeriesPlot(df_ts, config, save=True, last_folder_name='individual_Straight_timeSeries', name_=name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing complexity variable per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now the function is left here and not added in the UTILS.py, as we still need to modify it\n",
    "def entropy_compare_session(HenID, SessionID1, SessionID2, config, title, ValueDelta, EntropyTimeComputation, NbrData, \n",
    "                            last_folder_name='', order=2, metric='chebyshev', save=True):\n",
    "    '''compute and compare the running and shifted values of some complexity variables on hen movement time series for each 2 \n",
    "    consecutives sessions\n",
    "    Note: time series shoud be at seconds level, otherwise meaning of parameter changes\n",
    "    Note: the shifted AND the running variables have at least math.ceil(NbrData/ValueDelta) values in their computation '''\n",
    "    \n",
    "    #initialize variable\n",
    "    path_extracted_data = config.path_extracted_data\n",
    "    dico_zone_order = config.dico_zone_order\n",
    "    id_run = config.id_run\n",
    "    li_day_hours = config.li_day_hours\n",
    "    li_hours_in_plot = config.li_hours_in_plot\n",
    "    NbrValues = math.ceil(NbrData/ValueDelta)\n",
    "    li_color = sns.diverging_palette(255, 133, l=60, n=len(li_day_hours), center=\"dark\")\n",
    "\n",
    "    path_entropy = os.path.join(path_extracted_data,'visual','entropy',last_folder_name)\n",
    "    #create a director if not existing\n",
    "    if not os.path.exists(path_entropy):\n",
    "        os.makedirs(path_entropy)\n",
    "        \n",
    "    ############## open ts of the 2 sessions and initialize plot\n",
    "    df_ts1 = pd.read_csv(os.path.join(path_extracted_data, id_run+'_TimeSeries_'+SessionID1+'.csv'), sep=';', parse_dates=['Timestamp','day']) \n",
    "    df_ts2 = pd.read_csv(os.path.join(path_extracted_data, id_run+'_TimeSeries_'+SessionID2+'.csv'), sep=';', parse_dates=['Timestamp','day']) \n",
    "    nbr_additional_plot = 3\n",
    "    li_hen1 = [i for i in df_ts1.columns if i.startswith('hen_')] ; li_hen2=[i for i in df_ts2.columns if i.startswith('hen_')] \n",
    "    li_zones = sorted(set(list(df_ts1[li_hen1].stack().unique()) +list(df_ts2[li_hen2].stack().unique())))\n",
    "    fig, axs = plt.subplots(len(li_zones)+nbr_additional_plot, 2, constrained_layout=True, figsize=(20,10))\n",
    "    fig.suptitle(title+'\\n ', size=14) \n",
    "    \n",
    "    for df_ts,c in [(df_ts1,0), (df_ts2,1)]:\n",
    "                \n",
    "        ############## clean time series according to the needs\n",
    "        #nan at the begining should not influence entropy (nan in middle cant exist by construction) so lets remove it to have\n",
    "        #timestamp according to this  \n",
    "        df_ts = df_ts[~df_ts[HenID].isnull()]\n",
    "        df_ts[HenID] = df_ts[HenID].map(dico_zone_order).astype(int)\n",
    "        #keep timestamp only during the day\n",
    "        df_ts = df_ts[df_ts['hour'].isin(li_day_hours)]\n",
    "        #restrict the time serie to one value per ValueDelta seconds\n",
    "        dico_ts_zone = dict(zip(df_ts['Timestamp'].tolist(), df_ts[HenID].tolist()))\n",
    "        dico_ts_zone = {ts:v for i,(ts,v) in enumerate(dico_ts_zone.items()) if i%ValueDelta==0}\n",
    "        \n",
    "        ############## initialize some parameters\n",
    "        l = len(dico_ts_zone)\n",
    "        range_ = range(NbrValues, l, EntropyTimeComputation)\n",
    "        li_ts_xaxis = [list(dico_ts_zone.keys())[i] for i in range_]\n",
    "        li_day = df_ts['day'].unique()\n",
    "        \n",
    "        ############## plot the time serie\n",
    "        axs[0,c].plot(dico_ts_zone.keys(), dico_ts_zone.values(), color='gray', linewidth=0.5)\n",
    "        axs[0,c].set_title('Time series', size=11)    \n",
    "        for d in li_day: \n",
    "            for i,h in enumerate(li_hours_in_plot):\n",
    "                day_ = pd.to_datetime(d)\n",
    "                axs[0,c].axvline(x=dt.datetime(day_.year, day_.month, day_.day, h), ymin=min(dico_zone_order.values()), \n",
    "                                 ymax=max(dico_zone_order.values()), linewidth=1, color=li_color[i])\n",
    "\n",
    "        ############## plot all-zones SampEnt and DistributionEnt\n",
    "        #DistribEnt\n",
    "        li_en_running = [DistributionEntropy(list(dico_ts_zone.values())[0:i]) for i in range_]\n",
    "        li_en_shift = [DistributionEntropy(list(dico_ts_zone.values())[(i-NbrValues):i]) for i in range_]\n",
    "        axs[1,c].set_ylim((0,1.8))\n",
    "        axs[1,c].plot(li_ts_xaxis, li_en_shift, color='yellow')\n",
    "        axs[1,c].plot(li_ts_xaxis, li_en_running, color='gold')\n",
    "        axs[1,c].set_title('Distribution Entropy All Zones', size=11)  \n",
    "        for d in li_day: \n",
    "            for i,h in enumerate(li_hours_in_plot):\n",
    "                day_ = pd.to_datetime(d)\n",
    "                axs[1,c].axvline(x=dt.datetime(day_.year, day_.month, day_.day, h), ymin=min(dico_zone_order.values()), \n",
    "                                 ymax=max(dico_zone_order.values()), linewidth=1, color=li_color[i])        #SampEnt (take max as it can return -0)\n",
    "        li_en_running = [max(0,sample_entropy(list(dico_ts_zone.values())[0:i], order=order, \n",
    "                                              metric=metric)) for i in range_]\n",
    "        li_en_shift = [max(0,sample_entropy(list(dico_ts_zone.values())[(i-NbrValues):i], order=order, \n",
    "                                            metric='chebyshev')) for i in range_]\n",
    "        axs[2,c].set_ylim((0,0.5))\n",
    "        axs[2,c].plot(li_ts_xaxis, li_en_shift, color='blue')\n",
    "        axs[2,c].plot(li_ts_xaxis, li_en_running, color='navy')\n",
    "        axs[2,c].set_title('SampEnt All Zones', size=11) \n",
    "        for d in li_day: \n",
    "            for i,h in enumerate(li_hours_in_plot):\n",
    "                day_ = pd.to_datetime(d)\n",
    "                axs[2,c].axvline(x=dt.datetime(day_.year, day_.month, day_.day, h), ymin=min(dico_zone_order.values()), \n",
    "                                 ymax=max(dico_zone_order.values()), linewidth=1, color=li_color[i])        ############## plot per zone sample entropy\n",
    "        for k,zone_ in enumerate(li_zones):\n",
    "            #print(zone_)\n",
    "            dico_z = {k:int(v==dico_zone_order[zone_]) for k,v in dico_ts_zone.items()}\n",
    "            li_en_running = [max(0,sample_entropy(list(dico_z.values())[0:i], order=order, metric=metric)) for i in range_]\n",
    "            li_en_shift = [max(0,sample_entropy(list(dico_z.values())[(i-NbrValues):i], order=order,\n",
    "                                                metric='chebyshev')) for i in range_]\n",
    "            axs[k+nbr_additional_plot,c].set_ylim((0,0.5))\n",
    "            axs[k+nbr_additional_plot,c].plot(li_ts_xaxis, li_en_shift, color='blue')\n",
    "            axs[k+nbr_additional_plot,c].plot(li_ts_xaxis, li_en_running, color='navy')\n",
    "            axs[k+nbr_additional_plot,c].set_title('SampEnt '+str(zone_), size=11)\n",
    "            for d in li_day: \n",
    "                for i,h in enumerate(li_hours_in_plot):\n",
    "                    day_ = pd.to_datetime(d)\n",
    "                    axs[k+nbr_additional_plot,c].axvline(x=dt.datetime(day_.year, day_.month, day_.day, h), ymin=min(dico_zone_order.values()), \n",
    "                                     ymax=max(dico_zone_order.values()), linewidth=1, color=li_color[i])    #save plot\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(path_entropy, id_run+'_entropy_'+HenID+'_'+SessionID1+'_'+SessionID2+'.png'), \n",
    "                    dpi=300, format='png')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValueDelta = config.ValueDelta\n",
    "EntropyTimeComputation = config.EntropyTimeComputation\n",
    "NbrData = config.NbrData\n",
    "\n",
    "#note that it does not make sense to save one csv with each column the entropy of a hen, as we are not computing it for several \n",
    "#hen on the same day. \n",
    "START_TIME = time.clock()\n",
    "for i in tqdm.tqdm(range(df_event.shape[0])):\n",
    "    x = df_event.iloc[i]\n",
    "    h = x['HenID']\n",
    "    event_type = 'not_interesting_event'\n",
    "    if x['is_interesting_event']:\n",
    "        event_type = 'interesting_event'\n",
    "    title = 'Running sample entropy for '+h+'          with KF1: '+str(x['previous_severity'])+\\\n",
    "    '          KF2: '+str(x['severity'])+'          value delta: '+str(ValueDelta)+'          NbrDatan: '+str(NbrData)+\\\n",
    "    '          EntropyTimeComputation: '+str(EntropyTimeComputation)\n",
    "\n",
    "    entropy_compare_session(HenID=h, SessionID1=str(int(x['previous_sessionNumber']))+x['group'], \n",
    "                            SessionID2=str(int(x['sessionNumber']))+x['group'], config=config, title=title, \n",
    "                            last_folder_name='session_comparison\\\\'+event_type,\n",
    "                            order=2, ValueDelta=ValueDelta, EntropyTimeComputation=EntropyTimeComputation, NbrData=NbrData,\n",
    "                            metric='chebyshev', save=True)\n",
    "END_TIME = time.clock()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#remove value of shifted entropy at the begining of each day as it uses the value of the day before\n",
    "#TODO NEXT\n",
    "#add timestamp of max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
