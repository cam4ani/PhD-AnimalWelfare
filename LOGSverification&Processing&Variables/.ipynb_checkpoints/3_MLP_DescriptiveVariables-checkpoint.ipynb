{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import preprocessing_Origins,verification_based_on_initial_record,\\\n",
    "time_series_henColumn_tsRow,is_day,vertical_travel_distance, li_missingZone_mvtPerc_DU, li_event_chaoticmvt_z_d,\\\n",
    "ZoneVariable, HenDailyVariable_Origins, boxplot_distribution_entropy,\\\n",
    "nbr_transition, max_duration_zones, openDevice, kmeans_clustering\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n",
      "correctlightschedule_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "dico_matching = config.dico_matching\n",
    "print(id_run)\n",
    "path_extracted_data_visual = os.path.join(path_extracted_data,'visual')\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_extracted_data_visual):\n",
    "    os.makedirs(path_extracted_data_visual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables at Hen level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#WARNING: we do it at seconds level, so the miliseconds from the general cleaning is not used!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#for being more reproductible, we open the file that was saved from cleaning\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', parse_dates=['Timestamp', 'date']) \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open time series per session and compute the variables for each session (car time series make sence at session level), et en \n",
    "#plus des variables tel que running entropy over the whole session ateach last timestamp of each level make sence only at \n",
    "#session level\n",
    "#once to much data, do this per pen!!! with name=pens!!\n",
    "START_TIME = time.perf_counter()\n",
    "for p in tqdm.tqdm(df['PenID'].unique()):\n",
    "    print(p)\n",
    "    df_daily = HenDailyVariable_Origins(df[df['PenID']==p], config, name_=p, timestamp_name='Timestamp', \n",
    "                                        has_cons_equal_zone=False)\n",
    "    print(df_daily.shape)\n",
    "    df_daily.head(3)\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Concatenate all HenVariables csv into one\n",
    "li_paths_var = glob.glob(os.path.join(path_extracted_data, id_run+'_daily__pen'+'*_variables.csv'))\n",
    "li_df = []\n",
    "if len(li_paths_var)!=8:\n",
    "    print('ERROR: not the correct number of files, there must have one per pen')\n",
    "    sys.exit()\n",
    "for path_var in tqdm.tqdm(li_paths_var):\n",
    "    #for being more reproductible, we open the file that was saved from cleaning\n",
    "    df_ = pd.read_csv(path_var, sep=';',parse_dates=['level', 'FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', \n",
    "                                                     'FirstTimestamp_3_Zone','FirstTimestamp_4_Zone',\n",
    "                                                     'FirstTimestamp_5_Zone']) \n",
    "    print(df_.shape)\n",
    "    li_df.append(df_)\n",
    "df_daily = pd.concat(li_df)\n",
    "df_daily.to_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables.csv'), sep=';', index=False)\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi2distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#computed here as its a variable and not a visual computed out of variable\n",
    "#compute for every level a symmetric chi2distance heatmap\n",
    "if compute_chi2_distance:   \n",
    "\n",
    "    #sort by lowest entropy (i.e. need less info to predict futur. more predictibale should induce more similarities \n",
    "    #(as less different solution)), to potentialy make a nicer visual\n",
    "    df_ = df_daily.groupby(['HenID'])['distribution_entropy'].agg(lambda x:np.mean(x)).reset_index().sort_values(['distribution_entropy'])\n",
    "    li = df_['HenID'].tolist()\n",
    "    axis_label = [i.split('_')[1] for i in li]\n",
    "    #create path to save visual if not existing\n",
    "    path_ = os.path.join(path_extracted_data,'visual','chi2distance')\n",
    "    #create a director if not existing\n",
    "    if not os.path.exists(path_):\n",
    "        os.makedirs(path_)\n",
    "\n",
    "    print('----------------- Compute Chi2 distance....')\n",
    "    for d in li_date:\n",
    "        M = np.zeros(shape=(len(li),len(li)))\n",
    "        for i, h1 in enumerate(li[:-1]):\n",
    "            for j in range(i+1,len(li)):\n",
    "                h2 = li[j]\n",
    "                li_hen_in = df_daily[df_daily['level']==d]['HenID'].unique()\n",
    "                #if both hen have at least one record this day (typically not always all hen have values the first day of session)\n",
    "                if (h1 in li_hen_in) & (h2 in li_hen_in):\n",
    "                    l1 = df_daily[(df_daily['HenID']==h1)&(df_daily['level']==d)]['dur_values_normalized'].values[0]\n",
    "                    l2 = df_daily[(df_daily['HenID']==h2)&(df_daily['level']==d)]['dur_values_normalized'].values[0]\n",
    "                    chi2 = chi2_distance(l1,l2)\n",
    "                    M[i][j] = chi2\n",
    "                    M[j][i] = chi2\n",
    "        #clear old plot\n",
    "        plt.figure()\n",
    "        sns.set(font_scale=0.25) \n",
    "        sns.heatmap(M, cmap=\"YlGnBu\", xticklabels=axis_label, yticklabels=axis_label)\n",
    "        plt.title(d)\n",
    "        if save:\n",
    "            plt.savefig(os.path.join(path_,id_run+'_chi2distance_'+str(d).split('T')[0]+'_daily_'+'.png'), dpi=300,\n",
    "                        format='png',bbox_inches='tight')\n",
    "        #plt.show() \n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TODO NEXT STEPS\n",
    "duration_1_Zone / verification_daily_total_duration --> proportion_time_1_Zone\n",
    "nbr_stays_2_Zone:nbr bouts?\n",
    "skweness : verify if ift make sense, what is the avg of obs taken into avvount?\n",
    "Graph analysis\n",
    "tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
