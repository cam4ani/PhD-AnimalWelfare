{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#modelling\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import preprocessing_Origins, OriginsInitialVerification, is_day, is_WG_open, openDevice, cleaning_processing\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n",
      "correctlightschedule_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "dico_matching = config.dico_matching\n",
    "nbr_maxdur2beremoved = config.nbr_maxdur2beremoved\n",
    "dico_garden_opening_hour = config.dico_garden_opening_hour\n",
    "date_first_opening_WG = config.date_first_opening_WG\n",
    "print(id_run)\n",
    "path_extracted_data_visual = os.path.join(path_extracted_data,'visual')\n",
    "pal_ = config.pal_\n",
    "close_dates = config.close_dates\n",
    "\n",
    "#feature for model\n",
    "li_cont_select = config.li_cont_select\n",
    "li_bin = config.li_bin\n",
    "li_cat_select = config.li_cat_select\n",
    "\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_extracted_data_visual):\n",
    "    os.makedirs(path_extracted_data_visual)\n",
    "    \n",
    "path_extracted_data_cleaning_model = os.path.join(path_extracted_data,'Cleaning','model')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_LF = pd.read_csv(os.path.join(path_extracted_data, id_run+'_LFCounterEqual0.csv'), parse_dates=['date'], dayfirst=True, sep=';') \n",
    "#x0 = df_daily.shape[0]\n",
    "#fillnan with big number to it also means weird values if there is only nan\n",
    "#df_daily['date_2remove_weirdLFcounter'] = df_daily.apply(lambda x: x['level'] in df_LF[(df_LF['LFCounter_nbr_equal0']>=10)&\\\n",
    "#(df_LF['sender']==x['TagID'])]['date'].tolist(), axis=1)\n",
    "print(df_LF.shape)\n",
    "display(df_LF.head(5))\n",
    "display(df_LF.tail(5))\n",
    "df_LF[df_LF['LFCounter_nbr_equal0']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess - add HenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\T\n",
      "<>:2: DeprecationWarning: invalid escape sequence \\T\n",
      "<ipython-input-4-9a81131e2f69>:2: DeprecationWarning: invalid escape sequence \\T\n",
      "  p = glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\TagUpdates\\log*'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000001 has </text> <text style=color:green>359003</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000002 has </text> <text style=color:green>366740</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000003 has </text> <text style=color:green>367076</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000004 has </text> <text style=color:green>366813</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000005 has </text> <text style=color:green>366164</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000006 has </text> <text style=color:green>366755</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000007 has </text> <text style=color:green>366115</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000008 has </text> <text style=color:green>289272</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000009 has </text> <text style=color:green>326571</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000001 has </text> <text style=color:green>371776</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000002 has </text> <text style=color:green>373776</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000003 has </text> <text style=color:green>373919</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000004 has </text> <text style=color:green>373770</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000005 has </text> <text style=color:green>373310</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000006 has </text> <text style=color:green>373635</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000007 has </text> <text style=color:green>374897</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000008 has </text> <text style=color:green>214255</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000001 has </text> <text style=color:green>372191</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000002 has </text> <text style=color:green>374299</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000003 has </text> <text style=color:green>374613</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000004 has </text> <text style=color:green>272849</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000005 has </text> <text style=color:green>128278</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the focalBirdinfo, you have 155 ative tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\Desktop\\animals_code\\PhD-AnimalWelfare\\UTILS.py:458: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_ = df.groupby(['HenID'])['system','PenID','TagID'].agg(lambda x: set(x)).reset_index()\n",
      "  0%|                                                                                           | 0/51 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- DEVICE DATA --------------------\n",
      "process device data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 51/51 [13:31<00:00, 15.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5103153, 21)\n",
      "(46566, 5)\n",
      "(46566, 8)\n",
      "(7300460, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>HenID</th>\n",
       "      <th>Zone</th>\n",
       "      <th>PenID</th>\n",
       "      <th>log_file_name</th>\n",
       "      <th>ts_order</th>\n",
       "      <th>TagID</th>\n",
       "      <th>signalstrength</th>\n",
       "      <th>system</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>zone2</th>\n",
       "      <th>signalstzone2</th>\n",
       "      <th>zone3</th>\n",
       "      <th>zone4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-29 09:07:00</td>\n",
       "      <td>71</td>\n",
       "      <td>Tier 2 (mini 12)</td>\n",
       "      <td>12</td>\n",
       "      <td>log_00000001</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>10</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>09:07:00</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-29 09:08:12</td>\n",
       "      <td>7</td>\n",
       "      <td>Tier 2 (mini 11)</td>\n",
       "      <td>11</td>\n",
       "      <td>log_00000001</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>10 - 12</td>\n",
       "      <td>09:08:12</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  HenID              Zone PenID log_file_name  ts_order  \\\n",
       "0 2020-09-29 09:07:00     71  Tier 2 (mini 12)    12  log_00000001         0   \n",
       "1 2020-09-29 09:08:12      7  Tier 2 (mini 11)    11  log_00000001         1   \n",
       "\n",
       "  TagID  signalstrength   system      time       date  zone2  signalstzone2  \\\n",
       "0   162              10  10 - 12  09:07:00 2020-09-29      2              8   \n",
       "1   140              10  10 - 12  09:08:12 2020-09-29      2              8   \n",
       "\n",
       "   zone3  zone4  \n",
       "0      1      0  \n",
       "1      1      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>HenID</th>\n",
       "      <th>Zone</th>\n",
       "      <th>PenID</th>\n",
       "      <th>log_file_name</th>\n",
       "      <th>ts_order</th>\n",
       "      <th>TagID</th>\n",
       "      <th>signalstrength</th>\n",
       "      <th>system</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>zone2</th>\n",
       "      <th>signalstzone2</th>\n",
       "      <th>zone3</th>\n",
       "      <th>zone4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7300458</th>\n",
       "      <td>2021-07-25 23:56:18</td>\n",
       "      <td>217</td>\n",
       "      <td>Tier 2 + untere Stange</td>\n",
       "      <td>8</td>\n",
       "      <td>log_00000005</td>\n",
       "      <td>124607</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>8 - 9</td>\n",
       "      <td>23:56:18</td>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300459</th>\n",
       "      <td>2021-07-25 23:56:18</td>\n",
       "      <td>173</td>\n",
       "      <td>Tier 2 + untere Stange</td>\n",
       "      <td>8</td>\n",
       "      <td>log_00000005</td>\n",
       "      <td>124608</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>8 - 9</td>\n",
       "      <td>23:56:18</td>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  HenID                    Zone PenID  \\\n",
       "7300458 2021-07-25 23:56:18    217  Tier 2 + untere Stange     8   \n",
       "7300459 2021-07-25 23:56:18    173  Tier 2 + untere Stange     8   \n",
       "\n",
       "        log_file_name  ts_order TagID  signalstrength system      time  \\\n",
       "7300458  log_00000005    124607    75              16  8 - 9  23:56:18   \n",
       "7300459  log_00000005    124608    86              16  8 - 9  23:56:18   \n",
       "\n",
       "              date  zone2  signalstzone2  zone3  zone4  \n",
       "7300458 2021-07-25      4              9      3      1  \n",
       "7300459 2021-07-25      4             11      3      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time: 38.77 mn\n"
     ]
    }
   ],
   "source": [
    "START_TIME = time.perf_counter()\n",
    "p = glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\TagUpdates\\log*'))\n",
    "#print('There is %d log files:\\n  %s'%(len(p),'  \\n  '.join(p)))\n",
    "df = preprocessing_Origins(p, config, save=True, dodevice=True)\n",
    "print(df.shape)\n",
    "display(df.head(2))\n",
    "display(df.tail(2))\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "#--> saves a datfarme named: _PreprocessRecords_forcleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based cleaning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In order to keep maximum information during video cleaning (i.e. each record), we kept consecutives equal zones, so the model was trained to say \"correct record\" even when the duration was small and the next zone was the same zone (instead of correct when the duration was longer and the next zone was a different one). \n",
    "Also, note that if we remove consecutives equal zone before the model filtering, then we might remove a correct record, while keeping a wrong record instead.\n",
    "For these two reasons, we should remove consecutives equal zones AFTER model filtering and not during the general cleaning.\n",
    "Note that the only difference with the preprocessing step in chapter 0, is that we add the milliseconds to the timsetamp in order to have the correct duration per stay first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for being more reproductible, we open the file that was saved from cleaning\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_PreprocessRecords_forcleaning.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp', 'date'], dayfirst=True) #index_col=0) \n",
    "#remove the entries that last less than a second\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset=['Timestamp','HenID'], keep='last')\n",
    "print(min(df['date'].tolist()), max(df['date'].tolist()))\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use same step as in cleaning-validation-effect paper\n",
    "START_TIME = time.perf_counter()\n",
    "df = cleaning_processing(df=df, date_min=dt.datetime(2020, 9, 29), date_max=dt.datetime(2021, 7, 26), config=config)\n",
    "df['time'] = df['Timestamp'].map(lambda x: dt.datetime.time(x))\n",
    "df.rename(columns={'Zone':'Trackingsystem_Zone'}, inplace=True) #thats how it was named in the model \n",
    "#add other variables\n",
    "df['is_dur_bigger_'+str(nbr_maxdur2beremoved)] = df['duration'].map(lambda x: x>=nbr_maxdur2beremoved)\n",
    "display(df['is_dur_bigger_'+str(nbr_maxdur2beremoved)].value_counts(normalize=True))\n",
    "df['is_dur_smaller_60sec'] = df['duration'].map(lambda x: x<60)\n",
    "display(df['is_dur_smaller_60sec'].value_counts(normalize=True))\n",
    "print('saving...')\n",
    "df.to_csv(os.path.join(path_extracted_data,'df_recordsmodelpreprocessing.csv'), sep=';', index=False)\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download model\n",
    "model = CatBoostClassifier()\n",
    "path_ = r'G:\\VPHI\\Welfare\\2- Research Projects\\OFHE2.OriginsE2\\DataOutput\\TrackingSystem\\CleaningAnalysis_\\Cleaning\\model'\n",
    "model.load_model(os.path.join(path_,'FINAL_Catboost'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for more flexibility we open the file that was saved previously\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, 'df_recordsmodelpreprocessing.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp','date'], dayfirst=True) \n",
    "df['is_day'] = df['Timestamp'].map(lambda x:  is_day(x, config.dico_night_hour))\n",
    "df['is_dur_smaller_60sec'] = df['duration'].map(lambda x: x<60)\n",
    "display(df['is_dur_smaller_60sec'].value_counts())\n",
    "df['duration_bounded_mn'] = df['duration'].map(lambda x: min(x,60*60)/60)\n",
    "df['next_duration_bounded_mn'] = df['next_duration'].map(lambda x: min(x,60*60)/60)\n",
    "df['previous_duration_bounded_mn'] = df['previous_duration'].map(lambda x: min(x,60*60)/60)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_ = df[(df['Trackingsystem_Zone']!='1_Zone')&\\\n",
    "         (df['HenID']=='hen_143')&(df['date'].isin([dt.datetime(2020,10,3), \n",
    "                                                    dt.datetime(2020,10,4)]))].copy()\n",
    "print(df_.shape)\n",
    "df_.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### handle nan\n",
    "#add info on nan values in the initial df, in order to replace at the end all prediction based on features involvig at least \n",
    "#one nan, by 1\n",
    "#Indeed, for records with some nan features, we will predict them a 1 all the time its only 0,05% of the time , i.e. when its \n",
    "#first or last transition. Indeed, we dont want to loose any records!\n",
    "df['nbr_nan'] = df.filter(li_cont_select+li_cat_select, axis=1).isnull().sum(axis=1).tolist()\n",
    "display(df['nbr_nan'].value_counts())\n",
    "#fillnan for simplicity, but we will remove those rows predictions anyway\n",
    "#display BEFORE categoricalfeatures\n",
    "display(df[li_cat_select].head(3))\n",
    "df[li_cont_select] = df[li_cont_select].fillna(df[li_cont_select].mean().iloc[0])\n",
    "#display AFTER categoricalfeatures\n",
    "df[li_cat_select] = df[li_cat_select].fillna(df[li_cat_select].mode().iloc[0])\n",
    "#show data\n",
    "display(df[config.li_cont_select].head(3))\n",
    "display(df[config.li_cat_select].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = time.perf_counter()\n",
    "#predict, and if its wintergarten (i.e. 1_Zone) put =1\n",
    "df['model_prediction'] = df.apply(lambda x: model.predict(pd.DataFrame(x[li_cont_select+\\\n",
    "                                                                         li_cat_select]).transpose())[0] if\\\n",
    "                                  x['Trackingsystem_Zone']!='1_Zone' else 1, axis=1)\n",
    "display(df['model_prediction'].value_counts(normalize=True)) #in testing it was 4,9% of wrong records: 42/(42+821)*100)\n",
    "\n",
    "#predict false if <60seconds in WG or at night, else true\n",
    "df.loc[(df['is_dur_smaller_60sec'])&((df['Trackingsystem_Zone']=='1_Zone')|(~df['is_day'])), 'model_prediction'] = 0\n",
    "#always =1 if there was some nan values\n",
    "display(df['model_prediction'].value_counts(normalize=True)) #in testing it was 4,9% of wrong records: 42/(42+821)*100)\n",
    "\n",
    "#always =1 if >15mn or if there was some NAN values\n",
    "df.loc[(df['is_dur_bigger_'+str(nbr_maxdur2beremoved)])|(df['nbr_nan']!=0), 'model_prediction'] = 1\n",
    "display(df['model_prediction'].value_counts(normalize=True)) #in testing it was 4,9% of wrong records: 42/(42+821)*100)\n",
    "\n",
    "#predict=1 if nan\n",
    "df.loc[df['nbr_nan']!=0, 'model_prediction'] = 1\n",
    "display(df['model_prediction'].value_counts(normalize=True)) #in testing it was 4,9% of wrong records: 42/(42+821)*100)\n",
    "\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time for prediction: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "display(display(df.head(3)))\n",
    "#prediction_proba = model.predict_proba(df[df['Trackingsystem_Zone']!='1_Zone'])\n",
    "#df['model_prediction_proba0'] = [round(x[0],2) for x in prediction_proba]\n",
    "#df['model_prediction_proba1'] = [round(x[1],2) for x in prediction_proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#old way\n",
    "########### model filtering keeping 15mns' stays and for WG + night records: predict false if <60seconds else True (TD-method)\n",
    "START_TIME = time.perf_counter()\n",
    "#predict, and if its wintergarten (i.e. 1_Zone) put =1\n",
    "df_ = df[df['Trackingsystem_Zone']!='1_Zone'].copy()\n",
    "predictions = model.predict(df_.filter(li_cont_select+li_cat_select, axis=1))\n",
    "x0 = df[df['Trackingsystem_Zone']=='1_Zone'].shape[0]\n",
    "df_['model_prediction'] = predictions\n",
    "if df_[df_['model_prediction'].isnull()].shape[0]!=0:\n",
    "    print('ERROR')\n",
    "    sys.exit()\n",
    "df = pd.merge(df, df_.filter(['model_prediction','HenID','Timestamp'], axis=1), on=['HenID','Timestamp'], how='left')\n",
    "print(df[df['model_prediction'].isnull()].shape)\n",
    "if df[df['model_prediction'].isnull()].shape[0]!=x0:\n",
    "    print('ERROR: you have some nan in your predictions')\n",
    "    sys.exit()\n",
    "display(df['model_prediction'].value_counts(normalize=True))\n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time for prediction: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "\n",
    "\n",
    "#predict false if <60seconds in WG or at night, else true\n",
    "df.loc[df['Trackingsystem_Zone']=='1_Zone','model_prediction'] = 1\n",
    "df.loc[(df['is_dur_smaller_60sec'])&((df['Trackingsystem_Zone']=='1_Zone')|(~df['is_day'])), 'model_prediction'] = 0\n",
    "\n",
    "#always =1 if >15mn or if there was some NAN values\n",
    "df.loc[(df['is_dur_bigger_'+str(nbr_maxdur2beremoved)])|(df['nbr_nan']!=0), 'model_prediction'] = 1\n",
    "\n",
    "display(df['model_prediction'].value_counts(normalize=True)) #in testing it was 4,9% of wrong records: 42/(42+821)*100)\n",
    "#prediction_proba = model.predict_proba(df[df['Trackingsystem_Zone']!='1_Zone'])\n",
    "#df['model_prediction_proba0'] = [round(x[0],2) for x in prediction_proba]\n",
    "#df['model_prediction_proba1'] = [round(x[1],2) for x in prediction_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will take TIME to save\n",
    "#Note that we cant use the duration info anymore so we are filtering it\n",
    "df.filter(['HenID','PenID','system','Trackingsystem_Zone','model_prediction','Timestamp','date'],\n",
    "          axis=1).to_csv(os.path.join(path_extracted_data, id_run+'_Rawdata&Model.csv'), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove filtered records & consecutives equal zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for being more reproductible, we open the file that was saved from cleaning\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_Rawdata&Model.csv'), sep=';', parse_dates=['Timestamp','date'],\n",
    "                 dayfirst=True) \n",
    "#remove predicted-wrong-records\n",
    "print(df.shape)\n",
    "print(df[df['model_prediction'].isnull()].shape)\n",
    "df = df[df['model_prediction']!=0].copy()\n",
    "print(df.shape)\n",
    "#simply rename the tracking system zone into the model zone :) \n",
    "df.rename(columns={'Trackingsystem_Zone':'Zone'}, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "#ceiz = consecutives equal initial zone\n",
    "print('-----------------------------------------------------------------------------------------------')\n",
    "print('remove consecutives equal zone for the same hen.........')\n",
    "print('-----------------------------------------------------------------------------------------------')\n",
    "\n",
    "li_df = []\n",
    "#more efficient to do it per hen, as it wont need to search in the whole dataframe, and we can simply shift the timestamp column\n",
    "for i, df_hen in tqdm.tqdm(df.groupby(['HenID'])):\n",
    "    #as the next record date (sort by date, then simply shift by one row and add nan at then end)\n",
    "    df_hen = df_hen.sort_values(['Timestamp'], ascending=True)\n",
    "    #same date, one must take the last recorded one & sorting by date might change it. Also it already should be sorted by date\n",
    "    df_hen['next_record_date'] = df_hen['Timestamp'].tolist()[1:]+[np.nan]\n",
    "    #compute duration\n",
    "    df_hen['duration'] = df_hen.apply(lambda x: x['next_record_date']-x['Timestamp'], axis=1)\n",
    "    #compute the last record date in order to put interzone also when the duration is >=nbr_sec_flickering1\n",
    "    df_hen['previous_record_date'] = [np.nan]+df_hen['Timestamp'].tolist()[0:-1]\n",
    "    #compute previous duration in order to put interzone also when the duration is >=nbr_sec_flickering1\n",
    "    df_hen['previous_duration'] = [np.nan]+df_hen['duration'].tolist()[0:-1]\n",
    "    #add next record for the impossible movement\n",
    "    df_hen['next_zone'] = df_hen['Zone'].tolist()[1:]+[np.nan]\n",
    "    #add previous record for the consecutives equal initial zones\n",
    "    df_hen['previous_zone'] = [np.nan]+df_hen['Zone'].tolist()[0:-1]\n",
    "    df_hen['previous_previous_zone'] = [np.nan]+df_hen['previous_zone'].tolist()[0:-1]\n",
    "    li_df.append(df_hen)\n",
    "#put again in one dataframe\n",
    "df = pd.concat(li_df)\n",
    "#dont care about the false positive warning   \n",
    "\n",
    "#True if next zone is equal to the actual zone\n",
    "df['correction_is_consecutive_equal_initial_zone'] = False\n",
    "#if the previous zone is the same, then its cez that should be removed\n",
    "df.loc[df['previous_zone']==df['Zone'], 'correction_is_consecutive_equal_initial_zone'] = True\n",
    "\n",
    "\n",
    "################# save\n",
    "df = df.sort_values(['Timestamp'], ascending=True)\n",
    "#save to verify CEIZ\n",
    "df.to_csv(os.path.join(path_extracted_data, id_run+'_records_GeneralCleaning_VERIFICATION_CEIZ.csv'), sep=';', index=False) \n",
    "df = df[~(df['correction_is_consecutive_equal_initial_zone'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small verification\n",
    "df_hen[['Timestamp','HenID','previous_zone','Zone']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove records in WG when WG was close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_WG_open'] = df['Timestamp'].map(lambda x: is_WG_open(x, dico_garden_opening_hour, date_first_opening_WG, close_dates,\n",
    "                                                            epsi_open=0, epsi_close=20))\n",
    "#we keep the epsi_open=0 as the system appeared to always open between 20sec of 2mn AFTER the indicated time (from video \n",
    "#observation)\n",
    "#we set epsi_close=20 as for video observation we saw that itwoul dbe between + and -15 mn than the indicated time. So we added\n",
    "#some flexibility by puting 20mn.\n",
    "print(df['is_WG_open'].value_counts(normalize=True))\n",
    "display(df[(df['Zone']=='1_Zone')&(df['is_WG_open'])][['Timestamp','is_WG_open']].head(5))\n",
    "display(df[(df['Zone']=='1_Zone')&(~df['is_WG_open'])][['Timestamp','is_WG_open']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove WG when close\n",
    "print(df.shape)\n",
    "df = df[~((~df['is_WG_open'])&(df['Zone']=='1_Zone'))]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(3)\n",
    "df.to_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP comparison (raw vs cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for being more reproductible, we open the file that was saved from cleaning\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_Rawdata&Model.csv'), sep=';', parse_dates=['Timestamp','date'],\n",
    "                 dayfirst=True) \n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model_prediction'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TIME = time.perf_counter()\n",
    "#choose specific dates to plot, November is better as hens starts to move more and the algo have never seen it\n",
    "dmin = dt.datetime(2021,3,10)\n",
    "dmax = dt.datetime(2021,3,20)\n",
    "#df_ = df[(df['date']<dt.datetime(2020,11,16))&(df['date']>dt.datetime(2020,11,10))]\n",
    "df_ = df[(df['date']<=dmax)&(df['date']>=dmin)].copy()\n",
    "print(df_.shape)\n",
    "#only print the hens with at least one transition per day (simplicity and interestignly)\n",
    "#to sort the yaxis\n",
    "dico_zone_order = {'1_Zone':0, '2_Zone':1, '3_Zone':2, '4_Zone':3, '5_Zone':4}\n",
    "li_ts = ['Trackingsystem_Zone','Model_Zone']\n",
    "li_date = df_['date'].unique()\n",
    "#for each batch draw 2 timeseries, the raw one and the model one\n",
    "for henID, df_plt in tqdm.tqdm(df_.groupby(['HenID'])):\n",
    "    df_plt = df_plt.sort_values(['Timestamp']).copy()\n",
    "    c = len(li_ts) ; l = len(li_date)\n",
    "    fig, ax = plt.subplots(figsize=(c*5, l*1))\n",
    "    i = 1\n",
    "    if len(df_plt['date'].unique())==len(li_date):\n",
    "        mi = min(df_plt['Timestamp'].tolist()) ; ma = max(df_plt['Timestamp'].tolist())\n",
    "        Daterange = pd.date_range(start = mi+dt.timedelta(seconds=(60-mi.second)), \n",
    "                                  end = ma-dt.timedelta(seconds=(ma.second+1)), \n",
    "                                  freq = 'S') \n",
    "        df_plt_ = df_plt.copy()\n",
    "        df_plt_.set_index('Timestamp', inplace=True)\n",
    "        df_plt_ = df_plt_.reindex(Daterange, method='ffill').reset_index()\n",
    "        df_plt_.rename(columns={'index':'Timestamp'}, inplace=True)\n",
    "        #add date again, as the reindexing also extended the date\n",
    "        df_plt_['date'] = df_plt_['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "        #remove first & last date\n",
    "        df_plt_ = df_plt_[~df_plt_['date'].isin([max(df_plt_['date'].tolist()),min(df_plt_['date'].tolist())])]\n",
    "        #put xlabel into numbers for the ploting\n",
    "        df_plt_['Trackingsystem_Zone'] = df_plt_['Trackingsystem_Zone'].map(lambda x: int(dico_zone_order[x]))       \n",
    "        for d, df_plt__ in df_plt_.groupby(['date']):\n",
    "            for v in li_ts:\n",
    "                df_plt___ = df_plt__.copy()\n",
    "                if v=='Model_Zone':\n",
    "                    df_plt___ = df_plt___[df_plt___['model_prediction']==1]\n",
    "                plt.subplot(l,c,i)\n",
    "                plt.tight_layout(pad=0.3) #add spacing between each plot\n",
    "                if i%2==1:\n",
    "                    plt.yticks([0,1,2,3,4], ['Winter garden', 'Litter', 'Lower perch','Nestbox','Top floor'])\n",
    "                else:\n",
    "                    plt.yticks([0,1,2,3,4], ['','','','',''])\n",
    "                if i in [1,2]:\n",
    "                    plt.title(v.replace('_',' '), size=13)\n",
    "                i = i+1\n",
    "                plt.plot(df_plt___['Timestamp'].tolist(), df_plt___['Trackingsystem_Zone'].tolist(), \n",
    "                         color=pal_[v], linewidth=1)\n",
    "                li_hour = pd.date_range(start = d,  end = d+dt.timedelta(days=1), freq = 'H')\n",
    "                plt.xticks(li_hour , [str(i.hour)+'h' for i in li_hour], fontsize=5)                \n",
    "                plt.yticks(fontsize=8)\n",
    "                plt.xlabel(str(d).split('T')[0], size=7)\n",
    "                plt.ylim(0, 4.2)  \n",
    "        plt.savefig(os.path.join(path_extracted_data_visual, \n",
    "                                 henID+'_'+str(dmin).split(' ')[0]+'_'+str(dmax).split(' ')[0]+'.png'), \n",
    "                    format='png', bbox_inches='tight', dpi=300)\n",
    "    plt.clf()\n",
    "    plt.close(\"all\")    \n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "#hen4, 22.10.2020: flickering. solved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
