{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from dtaidistance import dtw\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle #to save/load list of selected hens\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import chi2_distance, correct_key\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n",
      "correctlightschedule_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "#id_run = 'chapter0_final_'\n",
    "#path_dataoutput = r'G:\\VPHI\\Welfare\\2- Research Projects\\OFHE2.OriginsE2\\DataOutput'\n",
    "#path_extracted_data = os.path.join(path_dataoutput,'TrackingSystem') \n",
    "#path_extracted_data = os.path.join(path_extracted_data, id_run)\n",
    "dico_night_hour = config.dico_night_hour\n",
    "dico_matching = config.dico_matching\n",
    "li_binmn = config.li_binmn\n",
    "penalty = config.penalty\n",
    "dico_window = config.dico_window\n",
    "path_extracted_data_SNA = config.path_extracted_data_SNA\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_extracted_data_SNA):\n",
    "    os.makedirs(path_extracted_data_SNA)\n",
    "print(id_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#focal birds info (one row per bird)\n",
    "df_FB = pd.read_csv(os.path.join(path_extracted_data,id_run+'df_FOCALBIRDS.csv'), sep=';', parse_dates=['InitialStartDate'],\n",
    "                     dayfirst=True) \n",
    "df_FB['percentage_of_gain_weight'] = df_FB.apply(lambda x: (x['weight 23-11-2020']-x['29-09 weight'])/x['29-09 weight']*100, axis=1)\n",
    "print(df_FB.shape)\n",
    "df_FB.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#cleaned data of the tracking system movements\n",
    "df = pd.read_csv(os.path.join(path_extracted_data, id_run+'_CLEANEDDATA.csv'), sep=';', \n",
    "                 parse_dates=['Timestamp', 'date'], dayfirst=True) \n",
    "df['hour'] = df['Timestamp'].map(lambda x: x.hour)\n",
    "df['time'] = df['Timestamp'].map(lambda x: dt.datetime.time(x-dt.timedelta(seconds=x.second)))\n",
    "df.drop('duration', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (103) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42515, 149)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(42370, 151)\n",
      "(32032, 151)\n",
      "(32032, 151)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>level</th>\n",
       "      <th>duration_1_Zone</th>\n",
       "      <th>duration_2_Zone</th>\n",
       "      <th>duration_3_Zone</th>\n",
       "      <th>duration_4_Zone</th>\n",
       "      <th>duration_5_Zone</th>\n",
       "      <th>verification_daily_total_duration</th>\n",
       "      <th>dur_values</th>\n",
       "      <th>dur_values_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>temperature_night20_2_var</th>\n",
       "      <th>list_of_MovementCounter_day</th>\n",
       "      <th>len_MovementCounter_day</th>\n",
       "      <th>MovementCounter_day_amount_nnactivity</th>\n",
       "      <th>MovementCounter_day_max</th>\n",
       "      <th>MovementCounter_day_mean</th>\n",
       "      <th>DOA</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "      <th>nbr_sec_per_day</th>\n",
       "      <th>is_correct_amount_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>30613.0</td>\n",
       "      <td>31998.0</td>\n",
       "      <td>[0.0, 140.0, 1166.0, 79.0, 30613.0]</td>\n",
       "      <td>[0.0, 0.004375273454590912, 0.0364397774860928...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 32400.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_130</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>31295.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 780.0, 325.0, 31295.0]</td>\n",
       "      <td>[0.0, 0.0, 0.024074074074074074, 0.01003086419...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>32400</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID      level  duration_1_Zone  duration_2_Zone  duration_3_Zone  \\\n",
       "0  hen_130 2020-10-04              0.0            140.0           1166.0   \n",
       "1  hen_130 2020-10-05              0.0              0.0              0.0   \n",
       "2  hen_130 2020-10-06              0.0              0.0            780.0   \n",
       "\n",
       "   duration_4_Zone  duration_5_Zone  verification_daily_total_duration  \\\n",
       "0             79.0          30613.0                            31998.0   \n",
       "1              0.0          32400.0                            32400.0   \n",
       "2            325.0          31295.0                            32400.0   \n",
       "\n",
       "                            dur_values  \\\n",
       "0  [0.0, 140.0, 1166.0, 79.0, 30613.0]   \n",
       "1        [0.0, 0.0, 0.0, 0.0, 32400.0]   \n",
       "2    [0.0, 0.0, 780.0, 325.0, 31295.0]   \n",
       "\n",
       "                               dur_values_normalized  ...  \\\n",
       "0  [0.0, 0.004375273454590912, 0.0364397774860928...  ...   \n",
       "1                          [0.0, 0.0, 0.0, 0.0, 1.0]  ...   \n",
       "2  [0.0, 0.0, 0.024074074074074074, 0.01003086419...  ...   \n",
       "\n",
       "  temperature_night20_2_var list_of_MovementCounter_day  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "\n",
       "  len_MovementCounter_day MovementCounter_day_amount_nnactivity  \\\n",
       "0                     NaN                                   NaN   \n",
       "1                     NaN                                   NaN   \n",
       "2                     NaN                                   NaN   \n",
       "\n",
       "  MovementCounter_day_max  MovementCounter_day_mean  DOA weeks_in_laying_barn  \\\n",
       "0                     NaN                       NaN  123                    1   \n",
       "1                     NaN                       NaN  124                    1   \n",
       "2                     NaN                       NaN  125                    1   \n",
       "\n",
       "  nbr_sec_per_day is_correct_amount_time  \n",
       "0           32400                  False  \n",
       "1           32400                   True  \n",
       "2           32400                   True  \n",
       "\n",
       "[3 rows x 151 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily variables (one row per (henID, date))\n",
    "#daily_ALL_Variable_Tranformed\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, id_run+'_daily_ALL_variables.csv'), sep=';',\n",
    "                     parse_dates=['level','FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                              'FirstTimestamp_4_Zone', 'FirstTimestamp_5_Zone', \n",
    "                              'Nestbox_time_of_first_staid_longer_than900sec',\n",
    "                              'duration_last-firsttransition_mn'], dayfirst=True) \n",
    "df_daily['DOA'] = df_daily['level'].map(lambda x: (x-dt.datetime(2020,6,3)).days) \n",
    "df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: math.ceil(x/7))\n",
    "#first two month seems good from the %of hens not moving plot! and sounds good too (twice longer thatn they need to start moving)\n",
    "print(df_daily.shape)\n",
    "\n",
    "#filter by date\n",
    "df_daily = df_daily[df_daily['level']>dt.datetime(2020,9,29)]\n",
    "\n",
    "#remove days that are not fully recorded\n",
    "df_daily['nbr_sec_per_day'] = df_daily['level'].map(lambda x: dico_night_hour[correct_key(x,dico_night_hour)]['nbr_hour']*60*60)\n",
    "df_daily['is_correct_amount_time'] = df_daily.apply(lambda x: x['nbr_sec_per_day']==x['verification_daily_total_duration'], axis=1)\n",
    "df_daily[(~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull())][['level', 'HenID', 'Total_number_transition', 'dur_values', 'verification_daily_total_duration','nbr_sec_per_day']]\n",
    "print(df_daily.shape)\n",
    "display(df_daily = df_daily[~((~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull()))])\n",
    "print(df_daily.shape)\n",
    "\n",
    "#remove the days where the night had movement recorded but not the days\n",
    "print(df_daily.shape)\n",
    "#display(df_daily[df_daily.isna().any(axis=1)])\n",
    "df_daily = df_daily[~df_daily['verification_daily_total_duration'].isnull()]\n",
    "print(df_daily.shape)\n",
    "\n",
    "df_daily['dur_values_normalized'].replace('[nan, nan, nan, nan, nan]','[np.nan,np.nan,np.nan,np.nan,np.nan]', inplace=True)\n",
    "df_daily['dur_values_normalized'] = df_daily['dur_values_normalized'].map(lambda x: eval(x))\n",
    "df_daily['duration_last-firsttransition_mn'] = df_daily['duration_last-firsttransition_mn'].astype(float)\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance across pairs of MLPS from same day - for daily SNA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lets compute every day a network per zone with nodes=hens, link=DTW_zone_X. For this we need to compute mvt distances between hens on same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#download the MLPs vectors during day only! as we compare on same day, we can restrict to the exact daily calendar!\n",
    "dico_pen_bin_zone_level_h = pickle.load(open(os.path.join(path_extracted_data, \n",
    "                                                 id_run+'dico_pen_bin_zone_level_h_DAILYLEVEL.pkl'), 'rb'))\n",
    "dico_pen_bin_level_h = pickle.load(open(os.path.join(path_extracted_data, \n",
    "                                                     id_run+'dico_pen_bin_level_h_DAILYLEVEL.pkl'), 'rb'))\n",
    "#dico of hen as keys and pen as values\n",
    "df_daily['PenID'] = df_daily['PenID'].map(lambda x: 'pen'+(str(int(x))))\n",
    "dico_h_p = dict(zip(df_daily['HenID'].tolist(), df_daily['PenID'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 11.7,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 30.0,\n",
       " 7.783333333333333]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO pour DTW on devrais avoir un autre vecteur!! avec des 1-0 seulement\n",
    "dico_pen_bin_zone_level_h['pen8'][30]['5_Zone'][dt.datetime(2020,9,29)]['hen_126']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_binmn = [30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the CHI2DISTANCE & DTW for each bird with all other birds\n",
    "#start recording the time it last\n",
    "START_TIME = time.perf_counter()\n",
    "li_df = []\n",
    "#df.sort_values(['Timestamp'], inplace=True)\n",
    "#take (subset of) dates and hens that are available (i.e. for which we comptue the variable on)\n",
    "#df_daily_h = df_daily[(df_daily['DOA']>=150)&(df_daily['DOA']<=380)].copy()\n",
    "li_date = set(df_daily['level'].tolist())\n",
    "li_zone = ['1_Zone', '2_Zone', '3_Zone', '4_Zone', '5_Zone']\n",
    "for d in tqdm.tqdm(sorted(list(li_date))):\n",
    "    li_hen_d = df_daily[df_daily['level']==d]['HenID'].unique()\n",
    "    #we use symmetric measures, so we only do each combination once\n",
    "    for i,h1 in enumerate(li_hen_d):\n",
    "\n",
    "        #lets compute for hen h1 its difference with all other birds\n",
    "        for h2 in li_hen_d[i+1:]:\n",
    "            \n",
    "            try:\n",
    "                ############ Overall aviary usage similarity across days\n",
    "                l1_chi2 = df_daily[(df_daily['HenID']==h1)&(df_daily['level']==d)]['dur_values_normalized'].values[0]\n",
    "                l2_chi2 = df_daily[(df_daily['HenID']==h2)&(df_daily['level']==d)]['dur_values_normalized'].values[0]\n",
    "                dico_ = {'date':d, 'henId':h1, 'henID2':h2, 'chi2distance':chi2_distance(l1_chi2,l2_chi2, remove_warning=True)}\n",
    "                #'dur_values_normalized_henId':l1_chi2,'dur_values_normalized_henID2':l2_chi2,\n",
    "\n",
    "                ############# Specifics' zones usage similarity across days\n",
    "                for nbr_binmn in li_binmn:\n",
    "                    #ALL zone together with chi2distance\n",
    "                    l1_chi2 = dico_pen_bin_level_h[dico_h_p[h1]][nbr_binmn][d][h1]\n",
    "                    l2_chi2 = dico_pen_bin_level_h[dico_h_p[h2]][nbr_binmn][d][h2]\n",
    "                    dico_['nbr_obs_chi2all_'+str(nbr_binmn)] = len(l1_chi2)\n",
    "                    li_chi2 = [chi2_distance(l1_chi2[i],l2_chi2[i], remove_warning=True) for i in range(0,len(l1_chi2))]\n",
    "                    dico_['li_chi2_'+str(nbr_binmn)] = li_chi2\n",
    "                    dico_['chi2distance_ALL_'+str(nbr_binmn)] = np.mean(li_chi2)\n",
    "\n",
    "                    #per zone with DTW\n",
    "                    for ZONE in li_zone:\n",
    "                        dtw_value = np.nan\n",
    "                        try:\n",
    "                            l1_dtw = np.array(dico_pen_bin_zone_level_h[dico_h_p[h1]][nbr_binmn][ZONE][d][h1], dtype=np.double)\n",
    "                            l2_dtw = np.array(dico_pen_bin_zone_level_h[dico_h_p[h2]][nbr_binmn][ZONE][d][h2], dtype=np.double)\n",
    "                            #compute distance measure\n",
    "                            #psi: #of start and end points of a sequence can be ignored if this would lead to a lower distance\n",
    "                            dtw_value, paths = dtw.warping_paths(l1_dtw, l2_dtw, window=dico_window[nbr_binmn], psi=0, penalty=penalty)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            sys.exit()\n",
    "                            pass #dont do anything\n",
    "                        dico_['DTW_'+str(nbr_binmn)+'_'+ZONE] = round(dtw_value,1)  \n",
    "                        dico_['nbr_obs_l1_'+str(nbr_binmn)+'_'+ZONE] = len(l1_dtw)\n",
    "                        dico_['nbr_obs_l2_'+str(nbr_binmn)+'_'+ZONE] = len(l2_dtw)\n",
    "                li_df.append(dico_)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(h1, h2)\n",
    "                print(d)\n",
    "                \n",
    "END_TIME = time.perf_counter()\n",
    "print (\"Total running time: %.2f mn\" %((END_TIME-START_TIME)/60))\n",
    "#turn inter and intra distances into a dataframe                \n",
    "df_inter = pd.DataFrame(li_df)\n",
    "#df_inter = df_inter[~df_inter['chi2distance'].isnull()]\n",
    "df_inter['hen_pair'] = df_inter.apply(lambda x: '-'.join(sorted([x['henId'],x['henID2']])), axis=1)\n",
    "df_inter['DTW_30_all'] = df_inter[['DTW_30_1_Zone', 'DTW_30_2_Zone', 'DTW_30_3_Zone','DTW_30_4_Zone','DTW_30_5_Zone']].sum(axis=1)\n",
    "li_col = list(df_inter.columns)\n",
    "li_remove = [i for i in li_col if i.startswith('li_chi2_')]\n",
    "print(li_remove)\n",
    "li_keep = [i for i in li_col if i not in li_remove]\n",
    "#df_inter.iloc[0:1000].to_csv(os.path.join(path_extracted_data_visual_adap, id_run+'_df_DistanceBetweenHenSim_4verification.csv'), sep=';', index=False)\n",
    "#df_inter.filter(li_keep).to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+'_df_DistanceBetweenHenSim.csv'), sep=';', index=False)\n",
    "df_inter.to_csv(os.path.join(path_extracted_data ,id_run+'_df_DistanceBetweenHenSim_DAILYLEVEL.csv'), sep=';', index=False)\n",
    "print(df_inter.shape)\n",
    "display(df_inter.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_inter.shape)\n",
    "display(df_inter.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance across any pairs of MLPS - for daily clusterID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download MLPs vectors\n",
    "#For now we restrict to 2h-17h in order to always compare same length TS as we will compare across days, the lenght might differ\n",
    "dico_pen_bin_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                     id_run+'dico_pen_bin_level_h_2h-17h59LEVEL.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mvt distances between any two MLPs on any day from any pen\n",
    "dico_hendate_mvt = {}\n",
    "for p,dico_bin_level_h in dico_pen_bin_level_h.items():\n",
    "    for level, dico_hen_mvt in dico_bin_level_h[15].items():\n",
    "        if level!=dt.datetime(2020,9,29):\n",
    "            for henID,limvt in dico_hen_mvt.items():\n",
    "                dico_hendate_mvt[henID+'/'+str(level).split(' ')[0]] = limvt\n",
    "dico_hendate_mvt = OrderedDict(dico_hendate_mvt)\n",
    "li_hendate = list(dico_hendate_mvt.keys())\n",
    "li_mvt = list(dico_hendate_mvt.values())\n",
    "len(dico_hendate_mvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_df = []\n",
    "for i in tqdm.tqdm(range(0,len(li_mvt))):\n",
    "    li_mvt1 = li_mvt[i]\n",
    "    for j in range(i+1,len(li_mvt)):\n",
    "        dico_ = {}\n",
    "        li_mvt2 = li_mvt[j]\n",
    "        li_chi2 = [chi2_distance(li_mvt1[i],li_mvt2[i]) for i in range(0,len(li_mvt1))]\n",
    "        dico_['chi2distance_ALL_15'] = np.mean(li_chi2)\n",
    "        dico_['h1'] = li_hendate[i]\n",
    "        dico_['h2'] = li_hendate[j]\n",
    "        li_df.append(dico_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anypair = pd.DataFrame(li_df)\n",
    "display(df_anypair[df_anypair['chi2distance_ALL_15'].isnull()])\n",
    "df_anypair['henID1'] = df_anypair['h1'].map(lambda x: x.split('/')[0])\n",
    "df_anypair['henID2'] = df_anypair['h2'].map(lambda x: x.split('/')[0])\n",
    "df_anypair['level1'] = df_anypair['h1'].map(lambda x: dt.datetime.strptime(x.split('/')[1], '%Y-%m-%d'))\n",
    "df_anypair['level2'] = df_anypair['h2'].map(lambda x: dt.datetime.strptime(x.split('/')[1], '%Y-%m-%d'))\n",
    "#df_interintra['weeks_in_laying_barn'] = df_interintra['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_interintra['hen_pair'] = df_interintra.apply(lambda x: '-'.join(sorted([x['henID1'],x['henID2']])), axis=1)\n",
    "df_anypair.to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+'_df_DistanceBetweenAnyDaysHenSim_2h-17h59LEVEL.csv'), sep=';', index=False)\n",
    "print(df_anypair.shape)\n",
    "display(df_anypair.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_anypair['chi2distance_ALL_15']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = np.array(['ad','ad','er','ww'])\n",
    "l2 = np.array(['ad','ed','er','ww'])\n",
    "sum(l1==l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
