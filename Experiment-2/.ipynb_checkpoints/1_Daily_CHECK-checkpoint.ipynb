{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import preprocessing_Origins, ZoneVariable, HenDailyVariable_Origins, FB_process, is_day\n",
    "import config_exp2 as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise parameter\n",
    "path_initial_data = config.path_initial_data\n",
    "path_extracted_data_daily_check = config.path_extracted_data_daily_check\n",
    "id_run = config.id_run\n",
    "dico_rc_sys = config.dico_rc_sys\n",
    "path_FocalBird = config.path_FocalBird\n",
    "\n",
    "focal_name = config.focal_name\n",
    "path_Days = config.path_Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voltage thresholds\n",
    "#Threshold for minimarker and wintergarden battery change\n",
    "thresh_dev = 3100\n",
    "#Threshold for tag battery change\n",
    "thresh_tag = 2930"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Why have I done a new notebook for daily check: notebook from previous study issues, among these:\n",
    "1. need to download 6 files, rename them and put in the folder before using the cript. WIth this one download one file, no need of rename and then use the script directly\n",
    "2. not general enought to be used with three systems, so one should copy paste a lot of the script which makes it very long and ugly\n",
    "3. not correct regarding tagID in different hen and henID with multiple Tagid\n",
    "4. not correct regarding nan and 0 voltage\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the logs and device updates\n",
    "over_last_Xdays = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logs with their associated HenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\T\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\T\n",
      "C:\\Users\\camil\\AppData\\Local\\Temp/ipykernel_23444/1011670852.py:1: DeprecationWarning: invalid escape sequence \\T\n",
      "  p = glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\TagUpdates\\log*'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\TagUpdates\\log_00000009.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000009 has </text> <text style=color:green>367465</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\TagUpdates\\log_00000010.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000010 has </text> <text style=color:green>368203</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\TagUpdates\\log_00000011.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000011 has </text> <text style=color:green>367335</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\AppData\\Local\\Temp/ipykernel_23444/1011670852.py:7: DtypeWarning: Columns (2,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = preprocessing_Origins(p, config, save=False, dodevice=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\TagUpdates\\log_00000012.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000012 has </text> <text style=color:green>554586</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 3 - 5\\TagUpdates\\log_00000008.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000008 has </text> <text style=color:green>371711</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 3 - 5\\TagUpdates\\log_00000009.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000009 has </text> <text style=color:green>369474</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 3 - 5\\TagUpdates\\log_00000010.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000010 has </text> <text style=color:green>368800</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 3 - 5\\TagUpdates\\log_00000011.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000011 has </text> <text style=color:green>312317</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 8 - 9\\TagUpdates\\log_00000005.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000005 has </text> <text style=color:green>370065</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 8 - 9\\TagUpdates\\log_00000006.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000006 has </text> <text style=color:green>369656</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 8 - 9\\TagUpdates\\log_00000007.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black>log: log_00000007 has </text> <text style=color:green>144052</text> <text style=color:black> rows</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the focalBirdinfo, you have 169 ative tags\n",
      "(2765836, 47)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TagSerialNumber</th>\n",
       "      <th>TagID</th>\n",
       "      <th>Zone</th>\n",
       "      <th>systemgantnerid</th>\n",
       "      <th>useless_zone</th>\n",
       "      <th>signalstrength</th>\n",
       "      <th>zone2</th>\n",
       "      <th>signalstzone2</th>\n",
       "      <th>zone3</th>\n",
       "      <th>...</th>\n",
       "      <th>commentPopulation</th>\n",
       "      <th>comment HA1</th>\n",
       "      <th>InitialStartDate</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>ShouldBeExcluded</th>\n",
       "      <th>exception</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1309166</th>\n",
       "      <td>2021-10-08 00:00:17</td>\n",
       "      <td>02002D19</td>\n",
       "      <td>tag_218</td>\n",
       "      <td>2_Zone</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>was selected randomly by computer as 23  but m...</td>\n",
       "      <td></td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>pen8</td>\n",
       "      <td>pen5</td>\n",
       "      <td>pen9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309167</th>\n",
       "      <td>2021-10-08 00:00:19</td>\n",
       "      <td>02002D19</td>\n",
       "      <td>tag_218</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>was selected randomly by computer as 23  but m...</td>\n",
       "      <td></td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>pen8</td>\n",
       "      <td>pen5</td>\n",
       "      <td>pen9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309280</th>\n",
       "      <td>2021-10-08 00:00:50</td>\n",
       "      <td>02001559</td>\n",
       "      <td>tag_59</td>\n",
       "      <td>2_Zone</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp TagSerialNumber    TagID    Zone systemgantnerid  \\\n",
       "1309166 2021-10-08 00:00:17        02002D19  tag_218  2_Zone               1   \n",
       "1309167 2021-10-08 00:00:19        02002D19  tag_218  3_Zone               1   \n",
       "1309280 2021-10-08 00:00:50        02001559   tag_59  2_Zone               1   \n",
       "\n",
       "         useless_zone  signalstrength  zone2  signalstzone2  zone3  ...  \\\n",
       "1309166           1.0             5.0    0.0            0.0    0.0  ...   \n",
       "1309167           2.0            10.0    1.0            5.0    0.0  ...   \n",
       "1309280           1.0             6.0    0.0            0.0    0.0  ...   \n",
       "\n",
       "                                         commentPopulation  comment HA1  \\\n",
       "1309166  was selected randomly by computer as 23  but m...                \n",
       "1309167  was selected randomly by computer as 23  but m...                \n",
       "1309280                                                NaN          NaN   \n",
       "\n",
       "         InitialStartDate  StartDate    EndDate ShouldBeExcluded  exception  \\\n",
       "1309166        2021-09-28 2021-10-07 2022-08-01              NaN              \n",
       "1309167        2021-09-28 2021-10-07 2022-08-01              NaN              \n",
       "1309280        2021-09-28 2021-10-07 2022-08-01              NaN        NaN   \n",
       "\n",
       "            R1     R2    R3  \n",
       "1309166   pen8   pen5  pen9  \n",
       "1309167   pen8   pen5  pen9  \n",
       "1309280  pen11  pen10  pen5  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TagSerialNumber</th>\n",
       "      <th>TagID</th>\n",
       "      <th>Zone</th>\n",
       "      <th>systemgantnerid</th>\n",
       "      <th>useless_zone</th>\n",
       "      <th>signalstrength</th>\n",
       "      <th>zone2</th>\n",
       "      <th>signalstzone2</th>\n",
       "      <th>zone3</th>\n",
       "      <th>...</th>\n",
       "      <th>commentPopulation</th>\n",
       "      <th>comment HA1</th>\n",
       "      <th>InitialStartDate</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>ShouldBeExcluded</th>\n",
       "      <th>exception</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307275</th>\n",
       "      <td>2022-02-07 11:39:46</td>\n",
       "      <td>02002439</td>\n",
       "      <td>tag_203</td>\n",
       "      <td>2_Zone</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen12</td>\n",
       "      <td>pen11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307501</th>\n",
       "      <td>2022-02-07 11:39:51</td>\n",
       "      <td>02001542</td>\n",
       "      <td>tag_32</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305516</th>\n",
       "      <td>2022-02-07 11:39:51</td>\n",
       "      <td>0200216D</td>\n",
       "      <td>tag_194</td>\n",
       "      <td>3_Zone</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp TagSerialNumber    TagID    Zone systemgantnerid  \\\n",
       "1307275 2022-02-07 11:39:46        02002439  tag_203  2_Zone               2   \n",
       "1307501 2022-02-07 11:39:51        02001542   tag_32  3_Zone               2   \n",
       "1305516 2022-02-07 11:39:51        0200216D  tag_194  3_Zone               2   \n",
       "\n",
       "         useless_zone  signalstrength  zone2  signalstzone2  zone3  ...  \\\n",
       "1307275           1.0            15.0    2.0            9.0    4.0  ...   \n",
       "1307501           2.0            10.0    7.0            9.0    0.0  ...   \n",
       "1305516           7.0            15.0    2.0           12.0    3.0  ...   \n",
       "\n",
       "         commentPopulation  comment HA1  InitialStartDate  StartDate  \\\n",
       "1307275                NaN          NaN        2021-09-28 2021-10-07   \n",
       "1307501                NaN          NaN        2021-09-28 2021-10-07   \n",
       "1305516                NaN          NaN        2021-09-28 2021-10-07   \n",
       "\n",
       "           EndDate ShouldBeExcluded  exception     R1     R2     R3  \n",
       "1307275 2022-08-01              NaN        NaN  pen10  pen12  pen11  \n",
       "1307501 2022-08-01              NaN        NaN  pen11  pen11  pen11  \n",
       "1305516 2022-08-01              NaN        NaN  pen11  pen11  pen11  \n",
       "\n",
       "[3 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\TagUpdates\\log*'))\n",
    "#mtime = os.stat(os.path.join('.', p[0])).st_mtime\n",
    "#download_time = dt.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d-%H:%M')\n",
    "#download_time = dt.datetime.strptime(download_time, '%Y-%m-%d-%H:%M')\n",
    "#print('The file were downloaded at: ', download_time)\n",
    "#print('There is %d log files:\\n  %s'%(len(p),'  \\n  '.join(p)))\n",
    "df = preprocessing_Origins(p, config, save=False, dodevice=False)\n",
    "print(df.shape)\n",
    "display(df.head(3))\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the focalBirdinfo, you have 169 ative tags\n"
     ]
    }
   ],
   "source": [
    "df_FB = pd.read_csv(path_FocalBird, sep=',', parse_dates=['StartDate','EndDate'], dayfirst=True, encoding='latin') #verified dates:correct\n",
    "#fill end date to today+1 for the birds which we dont know when is there end date (+1: so that today is taken into account)\n",
    "df_FB['EndDate'].fillna(config.date_max+dt.timedelta(days=1), inplace=True)\n",
    "df_FB['TagID'] = df_FB['TagID'].map(lambda x: 'tag_'+str(x)) #new:exp2\n",
    "#exclude rows were tags were not functionning correctly for some reason \n",
    "df_FB = df_FB[df_FB['ShouldBeExcluded']!='yes']\n",
    "#define a list with the active tags of today/last date\n",
    "li_active_tags = list(df_FB[df_FB['EndDate']>=config.date_max]['TagID'].unique())\n",
    "#Counter(li_active_tags)\n",
    "print('From the focalBirdinfo, you have %d ative tags'%len(li_active_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### active tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 29)\n",
      "(169, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>SireID</th>\n",
       "      <th>RPenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>Rtreatment</th>\n",
       "      <th>LPLegring</th>\n",
       "      <th>legringID</th>\n",
       "      <th>FocalLegringName</th>\n",
       "      <th>HA1_weight</th>\n",
       "      <th>HA1_NeckFeather</th>\n",
       "      <th>...</th>\n",
       "      <th>commentPopulation</th>\n",
       "      <th>comment HA1</th>\n",
       "      <th>InitialStartDate</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>ShouldBeExcluded</th>\n",
       "      <th>exception</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Rpen12</td>\n",
       "      <td>pen10</td>\n",
       "      <td>Queue</td>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>red1</td>\n",
       "      <td>1691.7</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.09.2021</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen11</td>\n",
       "      <td>pen8</td>\n",
       "      <td>pen9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>Rpen13</td>\n",
       "      <td>pen10</td>\n",
       "      <td>NoQueue</td>\n",
       "      <td>red</td>\n",
       "      <td>17</td>\n",
       "      <td>red17</td>\n",
       "      <td>1807.0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.09.2021</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "      <td>pen10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>Rpen13</td>\n",
       "      <td>pen10</td>\n",
       "      <td>NoQueue</td>\n",
       "      <td>red</td>\n",
       "      <td>15</td>\n",
       "      <td>red15</td>\n",
       "      <td>1779.6</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.09.2021</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pen3</td>\n",
       "      <td>pen8</td>\n",
       "      <td>pen12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID  SireID  RPenID  PenID Rtreatment LPLegring  legringID  \\\n",
       "0      1      15  Rpen12  pen10      Queue       red          1   \n",
       "1      2      63  Rpen13  pen10    NoQueue       red         17   \n",
       "2      3      78  Rpen13  pen10    NoQueue       red         15   \n",
       "\n",
       "  FocalLegringName  HA1_weight  HA1_NeckFeather  ...  commentPopulation  \\\n",
       "0             red1      1691.7              100  ...                NaN   \n",
       "1            red17      1807.0              100  ...                NaN   \n",
       "2            red15      1779.6              100  ...                NaN   \n",
       "\n",
       "   comment HA1  InitialStartDate  StartDate    EndDate ShouldBeExcluded  \\\n",
       "0          NaN        28.09.2021 2021-10-07 2022-08-01              NaN   \n",
       "1          NaN        28.09.2021 2021-10-07 2022-08-01              NaN   \n",
       "2          NaN        28.09.2021 2021-10-07 2022-08-01              NaN   \n",
       "\n",
       "   exception     R1     R2     R3  \n",
       "0        NaN  pen11   pen8   pen9  \n",
       "1        NaN  pen10  pen10  pen10  \n",
       "2        NaN   pen3   pen8  pen12  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tag = pd.read_csv(path_FocalBird, sep=',', parse_dates=['StartDate','EndDate'], dayfirst=True, encoding='latin')\n",
    "df_tag['EndDate'].fillna(dt.date.today(), inplace=True)\n",
    "print(df_tag.shape)\n",
    "df_tag = df_tag[df_tag['ShouldBeExcluded']!='yes']\n",
    "df_tag['TagID'] = df_tag['TagID'].map(lambda x: 'tag_'+str(x)) #new:exp2\n",
    "print(df_tag.shape)\n",
    "df_tag.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From your focalbird document you should have 169 ative tags\n"
     ]
    }
   ],
   "source": [
    "li_active_tags = list(set(df_tag[df_tag['EndDate']>=pd.to_datetime(dt.date.today())]['TagID'].unique()))\n",
    "#Counter(li_active_tags)\n",
    "print('From your focalbird document you should have %d ative tags'%len(li_active_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\D\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\D\n",
      "C:\\Users\\camil\\AppData\\Local\\Temp/ipykernel_23444/965875378.py:4: DeprecationWarning: invalid escape sequence \\D\n",
      "  for path_system in glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\DeviceUpdates')):\n",
      " 11%|█████████▎                                                                          | 1/9 [00:22<03:03, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215495, 20)\n",
      "----------------- G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\DeviceUpdates\\log_00000028.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▋                                                                 | 2/9 [00:45<02:38, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215495, 20)\n",
      "----------------- G:\\VPHI\\Welfare\\2- Research Projects\\Camille Montalcini\\Origins.GS\\GantnerSystem\\DATA\\Barn 4 Pen 10 - 12\\DeviceUpdates\\log_00000029.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▋                                                                 | 2/9 [00:48<02:48, 24.04s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'str' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/965875378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#remove last row as str some times and we dont really care about having so much device info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#df_device['Timestamp'] = df_test['Timestamp'].map(lambda x: dt.datetime.strptime(x, \"%d.%m.%Y %H:%M:%S\")) #faster than parse_dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_device\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4160\u001b[0m         \"\"\"\n\u001b[1;32m-> 4161\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23444/965875378.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mdf_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#remove last row as str some times and we dont really care about having so much device info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#df_device['Timestamp'] = df_test['Timestamp'].map(lambda x: dt.datetime.strptime(x, \"%d.%m.%Y %H:%M:%S\")) #faster than parse_dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_device\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_device\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-----------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: descriptor 'date' for 'datetime.datetime' objects doesn't apply to a 'str' object"
     ]
    }
   ],
   "source": [
    "#select last x logs\n",
    "last_x_logs = math.ceil(over_last_Xdays/2) #arondi en haut\n",
    "li_logs = []\n",
    "for path_system in glob.glob(os.path.join(path_initial_data, 'Barn 4 Pen*\\DeviceUpdates')):\n",
    "    li_ = glob.glob(os.path.join(path_system, 'log*'))\n",
    "    li_.sort(key=lambda x: os.path.getmtime(x), reverse=False)\n",
    "    li_logs.extend(li_[-last_x_logs:]) \n",
    "#next version\n",
    "#li_newFirmwarecol = ['Timestamp','sort','code','sender','Temperature','Battery Voltage','MovementCounter','LastLFSeen',\n",
    "#                     'LFCounter','LFRSSISum','Zone', 'Subzone','LFRSSI','Time','LastInfo','LastLocation','LastAction']\n",
    "li_newFirmwarecol = ['Timestamp','sort','code','sender','Temperature','Battery Voltage','MovementCounter','LastLFSeen',\n",
    "                     'LFCounter','LFRSSISum','Zone', 'Subzone','Time','LastInfo','LastLocation','LastAction']\n",
    "#lastReg = LastAction\n",
    "li_df = []\n",
    "for path_log in tqdm.tqdm(li_logs):\n",
    "    #confused month and day\n",
    "    df_device = pd.read_csv(os.path.join(path_log), sep=';', names=li_newFirmwarecol, parse_dates=['LastAction','Timestamp'],\n",
    "                           dayfirst=True)\n",
    "    df_device['data_path'] = path_log\n",
    "    df_device['system'] = 'pens:'+path_log.split('Barn 4 Pen ')[1].split('\\\\')[0]\n",
    "    df_device['logID'] = path_log.split('\\\\')[-1].split('.')[0]\n",
    "    df_device = df_device[:-1] #remove last row as str some times and we dont really care about having so much device info\n",
    "    #df_device['Timestamp'] = df_test['Timestamp'].map(lambda x: dt.datetime.strptime(x, \"%d.%m.%Y %H:%M:%S\")) #faster than parse_dates\n",
    "    df_device['date'] = df_device['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "    print(df_device.shape)\n",
    "    print('-----------------', path_log)\n",
    "    #display(df_device.head(3))\n",
    "    #display(df_device.tail(3))\n",
    "    li_df.append(df_device)\n",
    "df_device = pd.concat(li_df)\n",
    "df_device = df_device[df_device['Timestamp']>=dt.datetime(2020,9,29)]\n",
    "df_device['sender'].fillna(' ', inplace=True)\n",
    "#add the info on if the device needs batterie or not\n",
    "df_device['NeedsBatteries'] = df_device.apply(lambda x: ('mini' in x['sender']) | (x['sender']=='Wintergarten') | \\\n",
    "                                              (x['sort']=='Tag'), axis=1)\n",
    "\n",
    "#add 'tag_' to the tag names\n",
    "df_device['sender_tag'] = df_device['sender'].map(lambda x: 'tag_'+str(x)) #new:exp2\n",
    "df_device['sender'] = np.where(df_device['sort']=='Tag', df_device['sender_tag'], df_device['sender'])\n",
    "\n",
    "#remove old tags\n",
    "print(df_device.shape)\n",
    "df_device = df_device[~((df_device['sort']=='Tag')&(~df_device['sender'].isin(li_active_tags)))]\n",
    "print(df_device['logID'].unique())\n",
    "print(df_device.shape)\n",
    "df_device.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_device.groupby(['system','logID'])['NeedsBatteries'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_device[df_device['logID']=='log_00000010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an error might be cause if the alst row was not complet when the file was downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_device[df_device['sort']=='Marker'][['code','sender','system']].drop_duplicates() #all actives at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_device[(df_device['sort']=='Tag')&(df_device['Battery Voltage']<0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use only the last few days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time = max(df_device['Timestamp'].tolist())\n",
    "\n",
    "#remove the days we dont want\n",
    "df_device['to_analyse'] = df_device['Timestamp'].map(lambda x: x>=(download_time-dt.timedelta(days=over_last_Xdays)))\n",
    "df_device = df_device[df_device['to_analyse']]\n",
    "\n",
    "path_daily_ver = os.path.join(path_extracted_data_daily_check,str(download_time).split(' ')[0])\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_daily_ver):\n",
    "    os.makedirs(path_daily_ver)\n",
    "\n",
    "#keep only the last over_last_Xdays days in the logs\n",
    "df['to_analyse'] = df['Timestamp'].map(lambda x: x>=(download_time-dt.timedelta(days=over_last_Xdays)))\n",
    "df = df[df['to_analyse']]\n",
    "df[df['to_analyse']]['date'].unique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tags last records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags last records and active tags with no records\n",
    "df_ = df[df['TagID'].isin(li_active_tags)].groupby(['TagID','PenID'])['Timestamp'].agg(lambda x: list(x)).reset_index()\n",
    "df_['last_record_timestamp'] = df_['Timestamp'].map(lambda x: max(x))\n",
    "df_['nbr_h_since_lastrecord'] = df_['last_record_timestamp'].map(lambda x: int((download_time-x).total_seconds()/60/60))\n",
    "\n",
    "#add active tags that had no transition at all\n",
    "li_no_transition = [i for i in li_active_tags if i not in df['TagID'].unique()]\n",
    "df_no_transition = pd.DataFrame([{'TagID':tag_, 'nbr_h_since_lastrecord':9999} for tag_ in li_no_transition])\n",
    "print(df_no_transition.shape, df_.shape)\n",
    "df_ = pd.concat([df_, df_no_transition])\n",
    "print(df_.shape)\n",
    "#remove the older row of tags taht appear two times (i.e. if they changed pens for example)\n",
    "df_.sort_values(['nbr_h_since_lastrecord'], ascending=False, inplace=True)\n",
    "df_.drop_duplicates(subset=['TagID'], keep='last', inplace=True)\n",
    "df_[['TagID','PenID','last_record_timestamp','nbr_h_since_lastrecord']].to_csv(os.path.join(path_daily_ver, \n",
    "                                                                           id_run+str(download_time).split(' ')[0]+'h_TagsLastRecords.csv'), \n",
    "                                                              sep=';', index=False)\n",
    "\n",
    "h = 10\n",
    "print('------------- Tags with no records since at least %d hours: -------------'%h)\n",
    "print('There is %d such tags, we will print a maximum of 50 line (starting form the worst ones)'%df_[df_['nbr_h_since_lastrecord']>h].shape[0])\n",
    "li_tag_issues = df_[df_['nbr_h_since_lastrecord']>h][['TagID','PenID','last_record_timestamp','nbr_h_since_lastrecord']]['TagID'].tolist()\n",
    "print('There is %d tags with at least one issue'%len(set(li_tag_issues)))\n",
    "df_tag_summary = df_.copy()\n",
    "df_[df_['nbr_h_since_lastrecord']>h][['TagID','PenID','last_record_timestamp','nbr_h_since_lastrecord']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['TagID']=='19'] #10.04 morning: verify in video\n",
    "#df_device[df_device['sender']=='29']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader last update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#understand how the device logs are\n",
    "df_test = df_device.groupby('code')['system'].agg(lambda x: len(set(x))).reset_index()\n",
    "df_test[df_test['system']>1] #--> no code in two system!!\n",
    "#importantly:\n",
    "df_device[df_device['sort']!='Tag'].groupby(['sender'])['system','code','sort'].agg(lambda x: set(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reader_code in dico_rc_sys.keys():\n",
    "    print(\"The last read out from the reader of %s arrived at: %s\"%(dico_rc_sys[reader_code],\n",
    "                                                    str(max(df_device[df_device['code']==reader_code]['LastAction'].tolist()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#cleaning step: remove days for specific hens when the tag was not sending output regularly anymore\n",
    "df_test = df_device[df_device['sort']=='Tag'].copy()\n",
    "df_test['date'] = df_test['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "df_test = df_test.groupby(['sender','date','hour'])['LastAction'].agg(lambda x: list(x)).reset_index()\n",
    "df_test.rename(columns={'sender':'TagID'}, inplace=True)\n",
    "df_test['nbr_last_action']\n",
    "#last action biggest gap\n",
    "print(df_test.shape)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LFCoutner = df_device[df_device['sort']=='Tag'].copy()\n",
    "df_LFCoutner['date'] = df_LFCoutner['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "#df_LFCoutner['is_day'] = df_LFCoutner['Timestamp'].map(lambda x: is_day(x, config.dico_night_hour))\n",
    "df_LFCoutner = df_LFCoutner.groupby(['sender','date'])['LFCounter'].agg(lambda x: sorted(list(x))).reset_index()\n",
    "df_LFCoutner['LFCounter_nbr_equal0'] = df_LFCoutner['LFCounter'].map(lambda x: sum([i==0 for i in x]))\n",
    "df_LFCoutner['LFCounter_atleastone0'] = df_LFCoutner['LFCounter_nbr_equal0'].map(lambda x: x>0)\n",
    "print(df_LFCoutner.shape)\n",
    "df_ = df_LFCoutner[df_LFCoutner['LFCounter_atleastone0']].groupby(['sender'])[['date',\n",
    "                                                                'LFCounter_nbr_equal0']].agg(lambda x: list(x)).reset_index()\n",
    "df_.to_csv(os.path.join(path_daily_ver, id_run+str(download_time).split(' ')[0]+'_LFCounterEqual0.csv'),sep=';')\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#New data!!!: plt.hist(df_device['MovementCounter'].dropna(),bins='auto');\n",
    "#plt.hist(df_device['Temperature'].dropna(),bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biggest gap over the entire day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lastactionGAP = df_device[df_device['sort']=='Tag'].copy()\n",
    "df_lastactionGAP['date'] = df_lastactionGAP['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "#df_lastactionGAP['is_day'] = df_lastactionGAP['Timestamp'].map(lambda x: is_day(x, config.dico_night_hour))\n",
    "#df_lastactionGAP = df_lastactionGAP[df_lastactionGAP['is_day']]\n",
    "df_lastactionGAP = df_lastactionGAP.groupby(['sender','date'])['LastAction'].agg(lambda x: sorted(list(x))).reset_index()\n",
    "#last action biggest gap of the day\n",
    "df_lastactionGAP['li_gap_of_the_day_tsstarted'] = df_lastactionGAP['LastAction'].map(lambda x: {x[i]:(x[i+1]-x[i]).total_seconds() for i in range(0,len(x)-1)})\n",
    "df_lastactionGAP['biggest_gap_of_day_mn'] = df_lastactionGAP['li_gap_of_the_day_tsstarted'].map(lambda x: round(max(x.items(), \n",
    "                                                                                         key=operator.itemgetter(1))[1]/60,0))\n",
    "df_lastactionGAP['start_biggest_gap_of_day'] = df_lastactionGAP['li_gap_of_the_day_tsstarted'].map(lambda x: max(x.items(), \n",
    "                                                                                               key=operator.itemgetter(1))[0])\n",
    "df_lastactionGAP.to_csv(os.path.join(path_daily_ver, id_run+str(download_time).split(' ')[0]+'_LastactionGAP.csv'),sep=';')\n",
    "print(df_lastactionGAP.shape)\n",
    "df_lastactionGAP[df_lastactionGAP['biggest_gap_of_day_mn']>12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### very last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by date in order to take the last voltage using a simple list\n",
    "df_ = df_device.groupby(['code','sender','system','sort','NeedsBatteries'])['LastAction'].agg(lambda x: list(x)).reset_index()\n",
    "df_['last_LastAction'] = df_['LastAction'].map(lambda x: max(x))\n",
    "df_['nbr_mn_since_LastUpdate'] = df_['last_LastAction'].map(lambda x: (download_time-x).total_seconds()/60)\n",
    "\n",
    "#add tags with no update:\n",
    "li_no_transition = [i for i in li_active_tags if i not in df_device['sender'].unique()]\n",
    "df_no_transition = pd.DataFrame([{'sender':tag_, 'nbr_mn_since_LastUpdate':9999} for tag_ in li_no_transition])\n",
    "print(df_no_transition.shape, df_.shape)\n",
    "df_ = pd.concat([df_, df_no_transition])\n",
    "print(df_.shape)\n",
    "print('There is %d device with 0 updates'%df_no_transition.shape[0])\n",
    "df_.sort_values(['nbr_mn_since_LastUpdate'], ascending=False, inplace=True)\n",
    "#remove the older sender that appear two times (i.e. if they changed pens for example)\n",
    "df_.drop_duplicates(subset=['system','sender'], keep='last', inplace=True)\n",
    "df_[['code','sender','system','sort','last_LastAction','nbr_mn_since_LastUpdate']].to_csv(os.path.join(path_daily_ver, \n",
    "                                            id_run+str(download_time).split(' ')[0]+'h_DeviceLastUpdate.csv'), sep=';', index=False)\n",
    "\n",
    "\n",
    "mn = 12\n",
    "li_tag_issues.extend(df_[df_['nbr_mn_since_LastUpdate']>mn]['sender'])\n",
    "print('There is %d tags with at least one issue'%len(set(li_tag_issues)))\n",
    "\n",
    "print('------------- Device with no update since at least %d minutes -------------'%mn)\n",
    "df_tag_summary = pd.merge(df_tag_summary, df_[df_['sort']=='Tag'], left_on='TagID', right_on='sender', how='outer')\n",
    "#display(df_tag_summary.head(3))\n",
    "display(df_[df_['nbr_mn_since_LastUpdate']>mn][['code','sender','system','sort','last_LastAction','nbr_mn_since_LastUpdate']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Voltage last D days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = 7 #assuming I do this one a week, it make sense to plot it once a week\n",
    "#D=2 was not enough as we would miss some tags that were at 2600 (e.g. 82)\n",
    "df_device['is_last_'+str(D)+'days'] = df_device['Timestamp'].map(lambda x: x>=(download_time-dt.timedelta(days=D)))\n",
    "df_ = df_device[df_device['is_last_'+str(D)+'days']].groupby(['code','sender','system','sort',\n",
    "                                                        'NeedsBatteries'])['Battery Voltage'].agg(lambda x: list(x)).reset_index()\n",
    "df_['min_Battery_Voltage_last_'+str(D)+'days'] = df_['Battery Voltage'].map(lambda x: min(x))\n",
    "df_['avg_Battery_Voltage_last_'+str(D)+'days'] = df_['Battery Voltage'].map(lambda x: np.nanmean(x))\n",
    "df_.sort_values(['min_Battery_Voltage_last_'+str(D)+'days'], ascending=False, inplace=True)\n",
    "# check whether at least one of the last entries was below the critical threshold \n",
    "df_['CRITICAL'] = df_.apply(lambda x:sum([i<thresh_dev for i in x['Battery Voltage']])>=1 if x['sort']!='Tag' \\\n",
    "                            else sum([i<thresh_tag for i in x['Battery Voltage']])>=1, axis=1)\n",
    "df_.to_csv(os.path.join(path_daily_ver,id_run+str(download_time).split(' ')[0]+'h_Battery VoltageLast'+str(D)+'days.csv'), sep=';', index=False)\n",
    "print('------------- Critical Battery Voltage of device/tags (under threshold at least once during the last %d days -------------'%D)\n",
    "li_tag_issues.extend(df_[(df_['CRITICAL'])&(df_['sort']=='Tag')]['sender'])\n",
    "print(df_tag_summary.shape)\n",
    "df_tag_summary = df_tag_summary.drop(['sender'], axis=1)\n",
    "df_tag_summary = pd.merge(df_tag_summary, df_[df_['sort']=='Tag'][['CRITICAL','min_Battery_Voltage_last_'+str(D)+'days',\n",
    "                                                                   'avg_Battery_Voltage_last_'+str(D)+'days','sender']], \n",
    "                          left_on='TagID', right_on='sender', how='outer')\n",
    "df_tag_summary.drop(['LastAction','Timestamp','NeedsBatteries'], axis=1).to_csv(os.path.join(path_daily_ver,id_run+str(download_time).split(' ')[0]+'_TagSummary.csv'), sep=';', index=False)\n",
    "print(df_tag_summary.shape)\n",
    "#display(df_tag_summary.head(3))\n",
    "print('There is %d tags with at least one issue:'%len(set(li_tag_issues)))\n",
    "df_[(df_['CRITICAL'])&(df_['NeedsBatteries'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#plot\n",
    "\n",
    "df_device = df_device.sort_values(['LastAction'])\n",
    "for tag in li_active_tags:\n",
    "    df_plt = df_device[df_device['sender']==str(tag)][['voltage','Timestamp']]\n",
    "    plt.plot(df_plt['Timestamp'].tolist(), df_plt['voltage'].tolist());\n",
    "    plt.title(tag)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#plot the batterie level, the tagupdates and the number of transition for each tags, one plot per day\n",
    "df_device['date'] = df_device['Timestamp'].map(lambda x: dt.datetime.date(x))\n",
    "df_device = df_device.sort_values(['LastAction'])\n",
    "#us the log files to crate a df_tr file with one row per hen per hour, and the number of transition in a column\n",
    "df['hour'] = df['Timestamp'].map(lambda x: x.hour if pd.isnull(x)!=np.nan else np.nan)\n",
    "df_tr = df.groupby(['TagID','date','hour'])['Timestamp'].count().reset_index()\n",
    "df_tr.rename(columns={'Timestamp':'nbr_transition_last1h'}, inplace=True)\n",
    "df_tr['date_hour'] = df_tr.apply(lambda x: dt.datetime(x['date'].year, x['date'].month, x['date'].day, x['hour'],0,0), axis=1)\n",
    "\n",
    "#for tag in tqdm.tqdm(set(li_tag_issues)):\n",
    "for tag in tqdm.tqdm(li_active_tags):\n",
    "    try:\n",
    "        plt.figure(figsize=(18,4))\n",
    "        ax = plt.subplot(111) \n",
    "\n",
    "        #Battery Voltage\n",
    "        df_plt = df_device[df_device['sender']==tag].copy()\n",
    "        SystemID = df_plt['system'].iloc[0]\n",
    "        ax.plot(df_plt['Timestamp'].tolist(), df_plt['Battery Voltage'].tolist(), color='blue');\n",
    "\n",
    "        #number of transition in the last hours    \n",
    "        ax2=ax.twinx()\n",
    "        df_tr_ = df_tr[df_tr['TagID']==tag].copy()\n",
    "        ax2.plot(df_tr_['date_hour'].tolist(), df_tr_['nbr_transition_last1h'].tolist(), color='green');\n",
    "\n",
    "        #number of device update in the last hour\n",
    "        df_plt['hour'] = df_plt['Timestamp'].map(lambda x: x.hour if pd.isnull(x)!=np.nan else np.nan)\n",
    "        df_up = df_plt.groupby(['date','hour'])['LastAction'].agg(lambda x: list(x)).reset_index()\n",
    "        df_up['date_hour'] = df_up.apply(lambda x: dt.datetime(x['date'].year, x['date'].month, x['date'].day, x['hour'],0,0), axis=1)\n",
    "        df_up['nbr_update_last1h'] = df_up.apply(lambda x: sum([i>=(x['date_hour']-dt.timedelta(hours=1)) for i in x['LastAction']]), \n",
    "                                                 axis=1)\n",
    "        ax2.plot(df_up['date_hour'].tolist(), df_up['nbr_update_last1h'].tolist(), color='r');\n",
    "\n",
    "        #add days and plot\n",
    "        for day in df_plt['date'].unique() : \n",
    "            plt.axvline(x=day, linewidth=1, color='b')\n",
    "        plt.title('TagID: '+tag)\n",
    "        #for label in ax.get_xticklabels():\n",
    "        #    label.set_rotation(90) \n",
    "        y_ = np.nanmax(df_plt['Battery Voltage'].tolist())\n",
    "        x_ = np.nanmin(df_plt['date'].unique())\n",
    "        ax.text(x_, y_-0.1*(y_-np.nanmin(df_plt['Battery Voltage'].tolist())), '#device update in the last hour -right axis', fontsize=10, color='r')\n",
    "        ax.text(x_, y_-0.2*(y_-np.nanmin(df_plt['Battery Voltage'].tolist())), '#transition in the last hour -right axis', fontsize=10, color='green')\n",
    "        ax.text(x_, y_-0.3*(y_-np.nanmin(df_plt['Battery Voltage'].tolist())), 'Battery Voltage -left axis', fontsize=10, color='blue')\n",
    "\n",
    "        #create a director if not existing\n",
    "        path_incase = os.path.join(path_daily_ver, 'INcaseALLplot', SystemID.replace(':',''))\n",
    "        if not os.path.exists(path_incase):\n",
    "            os.makedirs(path_incase)\n",
    "        plt.savefig(os.path.join(path_incase,id_run+'_'+str(tag)+'Tag_CHECK.png'), dpi=300,\n",
    "                                format='png', bbox_inches='tight')\n",
    "    except Exception as e:\n",
    "                print('ERROR:-------------',e, '    TAG: ',tag)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tag with potential issues:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
