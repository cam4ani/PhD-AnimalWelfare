https://www.statisticssolutions.com/the-chi-square-test-in-structural-equation-modeling/
cfi>0.9
For example, a typical benchmark for the comparative fit index (CFI) is .90, meaning that values of .90 or greater indicate good fit, and values less than .90 indicate poor fit. 
For the CFI, some scholars suggest a benchmark of .90 (e.g., Schumacker & Lomax, 2010), but others may suggest a stricter benchmark of .95 (e.g., Hu & Bentler, 1999)
The reason why the chi-square test is not very useful is because of its sensitivity to sample size. The larger the sample size, the greater the chances of obtaining a statistically significant chi-square.
Because the chi-square test will be significant no matter what, it does not provide any useful information, and other measures of fit need to be considered.
As a final note, it is worth mentioning that the chi-square statistic itself (along with its degrees of freedom) can be a useful measure of model fit; it is just the significance test that ends up being useless. Some scholars recommend using the chi-square divided by the degrees of freedom (χ2/df) as a measure of model fit, with values of 5 or less being a common benchmark
Hu, L., & Bentler, P. M. (1999). Cutoff criteria for fit indexes in covariance structure analysis: Conventional criteria versus new alternatives. Structural Equation Modeling, 6, 1-55.

Schumacker, R. E., & Lomax, R. G. (2010). A beginner’s guide to structural equation modeling (3rd ed.). New York, NY: Routledge Academic.



-------------lscm package
detailed: https://milanwiedemann.github.io/lcsm/
########### 
alpha_constant: Constant change factor
beta: Proportional change factor
phi: Autoregression of change scores
########### coupling model parameters 
coupling_piecewise	Piecewise coupling parameters
coupling_piecewise_num	Changepoint of piecewise coupling parameters
delta_con_xy	Change score x (t) determined by true score y (t)
delta_con_yx	Change score y (t) determined by true score x (t)
delta_lag_xy	Change score x (t) determined by true score y (t-1)
delta_lag_yx	Change score y (t) determined by true score x (t-1)
xi_con_xy	Change score x (t) determined by change score y (t)
xi_con_yx	Change score y (t) determined by change score x (t)
xi_lag_xy	Change score x (t) determined by change score y (t-1)
xi_lag_yx	Change score y (t) determined by change score x (t-1)

full in-formation maximum likelihood to deal with missing data (‘missing=’fiml’)
Yuan-Bentler correction for non-normality (‘estimator=’mlr’)

p-value, chi2: 
This tests the null hypothesis that the predicted model and observed data are equal. Because you want your predictions to match the actual data as closely as possible, you do not want to reject this null hypothesis. In other words, a nonsignificant result for this test indicates good model fit.

as the parameters estiamtes are the same for each timestamp, they should be equally spaced in time

TO CHECK
can I put observed data as non gaussian into a single latent variable?



----------------------------------------
We scale the latent variable by fixing the first factor loading to 1 and latent variable mean to 0 OR mean of the loading  to avoid fixing one factor!! TODO
Change slope *1,2:TODO
Intercept and factor loadings have to be tested for time invariance, which can only be tested for non single indicator (as model needs these constrain to be identifiable)
Change score have to be autocorrelated until single indicator model: todo! Remove them and add more indicators
Higher rate of estimation issue with a single indicator!
Multiple indicators works with already 2 time points
Error variance equal across time: not necessarily for multiple indicators: todo test it
But you have to check correlates errors!! But more flexible and stable so use multiple indicators






