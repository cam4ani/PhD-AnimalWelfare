{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic package\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import operator\n",
    "from scipy import stats\n",
    "from numpy import inf\n",
    "import networkx as nx\n",
    "from dtaidistance import dtw\n",
    "import random\n",
    "\n",
    "#save and load dictionaries/lists\n",
    "import pickle\n",
    "\n",
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#PCA\n",
    "from sklearn import decomposition\n",
    "\n",
    "#clustering\n",
    "from sklearn.cluster import KMeans #only numerical var\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import kmodes\n",
    "from kmodes.kmodes import KModes #with categorical var as well\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "PACKAGE_PARENT = '../'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "from UTILS import kmeans_clustering, ZoneVariable, time_series_henColumn_tsRow, FB_daily, corr_from_dep2feature,\\\n",
    "corr_from_feature2feature, correlationGraph, ZoneVariable, DataRepresentation1, sampen, chi2_distance, is_day, correct_key\n",
    "import config_origins as config"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "We want to assess the similarity between two consecutives days over the nestbox usage for inter and intra individuals. \n",
    "To do so, we will first compute per \"nbr_bin minutes\"(sevearla bin to check stability) the number of minutes in the nestbox-zone. This will then be used with the DTW in order to have a similarity measure.\n",
    "\n",
    "Note\n",
    "1. that for the first day (30.9.2020) some hens had no transition recorded, hence we dont know in which zone they are, even by looking at the first transition. Thus, we wont be able to use it for the chi2-distance computation nor for the DTW between two time series. But, we are able to use it for the percentage of hen without any transitions.\n",
    "2. we dont remove days that have the WG opening, or nestbox opening, or light change, as this is most of the days. We will isntead focus the analysis on comparing the similarity inter vs intra, instead of each day separately quantitatif value\n",
    "\n",
    "DTW parameters:\n",
    "https://dtaidistance.readthedocs.io/en/latest/modules/dtw.html\n",
    "1. windows: \"Only allow for maximal shifts from the two diagonals smaller than this number. It includes the diagonal, meaning that an Euclidean distance is obtained by setting window=1.\"\n",
    "--> choose so taht we allow for time deformation of maximum 30 minutes (30/nbr_binmn)\n",
    "2. penalty: \"Penalty to add if compression or expansion is applied\" (usefull to be understood: https://github.com/wannesm/dtaidistance/issues/56)\n",
    "--> we choosed a penalty of 0 for now :)\n",
    "\n",
    "Chi2 reference:\n",
    "(Face Description with Local Binary Patterns: Application to Face Recognition. 2004) that Chi-Square distance perfoms better than Histogram intersection and Log-likelihood statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change the configuration file if not done yet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print('change the configuration file if not done yet!')\n",
    "path_extracted_data = config.path_extracted_data\n",
    "id_run = config.id_run\n",
    "dico_pen_tr = config.dico_pen_tr\n",
    "li_binmn = config.li_binmn\n",
    "penalty = config.penalty\n",
    "dico_window = config.dico_window\n",
    "birth_date = config.birth_date\n",
    "dico_night_hour = config.dico_night_hour\n",
    "max_date_adaptability = config.max_date_adaptability\n",
    "path_extracted_data_visual = os.path.join(path_extracted_data,'visual')\n",
    "path_extracted_data_visual_adap = os.path.join(path_extracted_data,'visual','Treatment&Classs','adaptability')\n",
    "path_extracted_data_visual_adap_verification = os.path.join(path_extracted_data_visual_adap,'verification')\n",
    "#create a director if not existing\n",
    "if not os.path.exists(path_extracted_data_visual_adap_verification):\n",
    "    os.makedirs(path_extracted_data_visual_adap_verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected hens\n",
    "li_selected_hens = pickle.load(open(os.path.join(path_extracted_data_visual_adap,'li_selected_hens.pkl'), 'rb'))\n",
    "len(li_selected_hens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>PenID</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>R-Pen</th>\n",
       "      <th>InitialStartDate</th>\n",
       "      <th>29-09 weight</th>\n",
       "      <th>10-12 juin weight</th>\n",
       "      <th>weight 23-11-2020</th>\n",
       "      <th>weight 04-01-2021</th>\n",
       "      <th>weight 01-02-21</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>percentage_of_gain_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>9</td>\n",
       "      <td>EPI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1696.5</td>\n",
       "      <td>1787.8</td>\n",
       "      <td>1800.9</td>\n",
       "      <td>OFH</td>\n",
       "      <td>49.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_10</td>\n",
       "      <td>11</td>\n",
       "      <td>LEXP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1488.3</td>\n",
       "      <td>1628.4</td>\n",
       "      <td>1602.1</td>\n",
       "      <td>OFH</td>\n",
       "      <td>39.093458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hen_101</td>\n",
       "      <td>5</td>\n",
       "      <td>MEXP</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1625.7</td>\n",
       "      <td>1751.1</td>\n",
       "      <td>1723.4</td>\n",
       "      <td>OFH</td>\n",
       "      <td>50.249538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID  PenID CLASS  R-Pen InitialStartDate  29-09 weight  \\\n",
       "0    hen_1      9   EPI    1.0       2020-06-10        1134.0   \n",
       "1   hen_10     11  LEXP    1.0       2020-06-10        1070.0   \n",
       "3  hen_101      5  MEXP    3.0       2020-06-10        1082.0   \n",
       "\n",
       "   10-12 juin weight  weight 23-11-2020  weight 04-01-2021  weight 01-02-21  \\\n",
       "0               57.0             1696.5             1787.8           1800.9   \n",
       "1               70.4             1488.3             1628.4           1602.1   \n",
       "3               66.0             1625.7             1751.1           1723.4   \n",
       "\n",
       "  Treatment  percentage_of_gain_weight  \n",
       "0       OFH                  49.603175  \n",
       "1       OFH                  39.093458  \n",
       "3       OFH                  50.249538  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#focal birds info (one row per bird)\n",
    "df_FB = pd.read_csv(os.path.join(path_extracted_data,id_run+'df_FOCALBIRDS.csv'), sep=';', parse_dates=['InitialStartDate'],\n",
    "                     dayfirst=True) \n",
    "df_FB = df_FB[df_FB['HenID'].isin(li_selected_hens)]\n",
    "df_FB['percentage_of_gain_weight'] = df_FB.apply(lambda x: (x['weight 23-11-2020']-x['29-09 weight'])/x['29-09 weight']*100, axis=1)\n",
    "print(df_FB.shape)\n",
    "df_FB.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27214, 199)\n",
      "(6721, 199)\n",
      "(6721, 199)\n",
      "(6721, 199)\n",
      "(6382, 199)\n",
      "(6382, 199)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>level</th>\n",
       "      <th>duration_1_Zone</th>\n",
       "      <th>duration_2_Zone</th>\n",
       "      <th>duration_3_Zone</th>\n",
       "      <th>duration_4_Zone</th>\n",
       "      <th>duration_5_Zone</th>\n",
       "      <th>verification_daily_total_duration</th>\n",
       "      <th>dur_values</th>\n",
       "      <th>dur_values_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>PC0</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>clustering_ALL</th>\n",
       "      <th>weeks_in_laying_barn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18886.0</td>\n",
       "      <td>3488.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>5908.0</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>[0.0, 18886.0, 3488.0, 518.0, 5908.0]</td>\n",
       "      <td>[0.0, 0.6557638888888889, 0.12111111111111111,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9310.0</td>\n",
       "      <td>5636.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17454.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 9310.0, 5636.0, 0.0, 17454.0]</td>\n",
       "      <td>[0.0, 0.2873456790123457, 0.17395061728395061,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31849.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>[0.0, 0.0, 551.0, 0.0, 31849.0]</td>\n",
       "      <td>[0.0, 0.0, 0.017006172839506173, 0.0, 0.982993...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID      level  duration_1_Zone  duration_2_Zone  duration_3_Zone  \\\n",
       "0  hen_1 2020-09-30              0.0          18886.0           3488.0   \n",
       "1  hen_1 2020-10-01              0.0           9310.0           5636.0   \n",
       "2  hen_1 2020-10-02              0.0              0.0            551.0   \n",
       "\n",
       "   duration_4_Zone  duration_5_Zone  verification_daily_total_duration  \\\n",
       "0            518.0           5908.0                            28800.0   \n",
       "1              0.0          17454.0                            32400.0   \n",
       "2              0.0          31849.0                            32400.0   \n",
       "\n",
       "                              dur_values  \\\n",
       "0  [0.0, 18886.0, 3488.0, 518.0, 5908.0]   \n",
       "1    [0.0, 9310.0, 5636.0, 0.0, 17454.0]   \n",
       "2        [0.0, 0.0, 551.0, 0.0, 31849.0]   \n",
       "\n",
       "                               dur_values_normalized  ... PC0 PC1 PC2 PC3 PC4  \\\n",
       "0  [0.0, 0.6557638888888889, 0.12111111111111111,...  ... NaN NaN NaN NaN NaN   \n",
       "1  [0.0, 0.2873456790123457, 0.17395061728395061,...  ... NaN NaN NaN NaN NaN   \n",
       "2  [0.0, 0.0, 0.017006172839506173, 0.0, 0.982993...  ... NaN NaN NaN NaN NaN   \n",
       "\n",
       "   PC5 PC6 PC7 clustering_ALL weeks_in_laying_barn  \n",
       "0  NaN NaN NaN            NaN                    1  \n",
       "1  NaN NaN NaN            NaN                    1  \n",
       "2  NaN NaN NaN            NaN                    1  \n",
       "\n",
       "[3 rows x 199 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily variables (one row per (henID, date))\n",
    "df_daily = pd.read_csv(os.path.join(path_extracted_data, 'daily_ALL_Variable_Tranformed.csv'), sep=';',\n",
    "                     parse_dates=['level','FirstTimestamp_1_Zone', 'FirstTimestamp_2_Zone', 'FirstTimestamp_3_Zone',\n",
    "                              'FirstTimestamp_4_Zone', 'FirstTimestamp_5_Zone', \n",
    "                              'Nestbox_time_of_first_staid_longer_than900sec',\n",
    "                              'duration_last-firsttransition_mn'], dayfirst=True) \n",
    "df_daily['DOA'] = df_daily['level'].map(lambda x: (x-dt.datetime(2020,6,3)).days) \n",
    "df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: int((x-119)/7)+1)\n",
    "#df_daily['weeks_in_laying_barn'] = df_daily['DOA'].map(lambda x: math.ceil(x/7))\n",
    "#first two month seems good from the %of hens not moving plot! and sounds good too (twice longer thatn they need to start moving)\n",
    "print(df_daily.shape)\n",
    "\n",
    "#filter by dates\n",
    "df_daily = df_daily[df_daily['level']<=max_date_adaptability] \n",
    "df_daily = df_daily[df_daily['level']>dt.datetime(2020,9,29)]\n",
    "\n",
    "#filter the selected hens\n",
    "df_daily = df_daily[df_daily['HenID'].isin(li_selected_hens)] \n",
    "\n",
    "#remove days that are not fully recorded\n",
    "df_daily['nbr_sec_per_day'] = df_daily['level'].map(lambda x: dico_night_hour[correct_key(x,dico_night_hour)]['nbr_hour']*60*60)\n",
    "df_daily['is_correct_amount_time'] = df_daily.apply(lambda x: x['nbr_sec_per_day']==x['verification_daily_total_duration'], axis=1)\n",
    "df_daily[(~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull())][['level', 'HenID', 'Total_number_transition', 'dur_values', 'verification_daily_total_duration','nbr_sec_per_day']]\n",
    "print(df_daily.shape)\n",
    "display(df_daily = df_daily[~((~df_daily['is_correct_amount_time'])&(~df_daily['Total_number_transition'].isnull()))])\n",
    "print(df_daily.shape)\n",
    "\n",
    "#remove the days where the night had movement recorded but not the days\n",
    "print(df_daily.shape)\n",
    "#display(df_daily[df_daily.isna().any(axis=1)])\n",
    "df_daily = df_daily[~df_daily['verification_daily_total_duration'].isnull()]\n",
    "print(df_daily.shape)\n",
    "\n",
    "df_daily['dur_values_normalized'].replace('[nan, nan, nan, nan, nan]','[np.nan,np.nan,np.nan,np.nan,np.nan]', inplace=True)\n",
    "df_daily['dur_values_normalized'] = df_daily['dur_values_normalized'].map(lambda x: eval(x))\n",
    "df_daily['duration_last-firsttransition_mn'] = df_daily['duration_last-firsttransition_mn'].astype(float)\n",
    "print(df_daily.shape)\n",
    "df_daily.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#download MLPs vectors\n",
    "#For now we restrict to 2h-17h in order to always compare same length TS as we will compare across days, the lenght might differ\n",
    "dico_pen_bin_zone_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                 id_run+'dico_pen_bin_zone_level_h_2h-17h59LEVEL.pkl'), 'rb'))\n",
    "dico_pen_bin_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                     id_run+'dico_pen_bin_level_h_2h-17h59LEVEL.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute distances across pairs of MLPS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "compute distance for any two (inter or intra) animal from the same pen, on day i and day i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>DOA</th>\n",
       "      <th>WOA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>119</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>120</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>121</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       level  DOA  WOA\n",
       "0 2020-09-30  119   17\n",
       "1 2020-10-01  120   18\n",
       "2 2020-10-02  121   18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doa = df_daily[['level','DOA','WOA']].drop_duplicates()\n",
    "df_doa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 8/8 [2:00:11<00:00, 901.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['li_chi2_5', 'li_chi2_10', 'li_chi2_15', 'li_chi2_20', 'li_chi2_30']\n",
      "(97411, 106)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>level+1</th>\n",
       "      <th>henID1</th>\n",
       "      <th>henID2</th>\n",
       "      <th>PenID</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>dur_values_normalized_henID1</th>\n",
       "      <th>dur_values_normalized_henID2</th>\n",
       "      <th>chi2distance</th>\n",
       "      <th>DOA</th>\n",
       "      <th>...</th>\n",
       "      <th>nbr_obs_l1_30_4_Zone</th>\n",
       "      <th>nbr_obs_l2_30_4_Zone</th>\n",
       "      <th>DTW_30_1_Zone</th>\n",
       "      <th>nbr_obs_l1_30_1_Zone</th>\n",
       "      <th>nbr_obs_l2_30_1_Zone</th>\n",
       "      <th>is_same_ind</th>\n",
       "      <th>type</th>\n",
       "      <th>HenID1_CLASS</th>\n",
       "      <th>HenID2_CLASS</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>hen_102</td>\n",
       "      <td>hen_102</td>\n",
       "      <td>pen3</td>\n",
       "      <td>OFH</td>\n",
       "      <td>[0.0, 0.010625, 0.19631944444444444, 0.0215625...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.128991</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>True</td>\n",
       "      <td>Intra individuals - OFH</td>\n",
       "      <td>MEXP</td>\n",
       "      <td>MEXP</td>\n",
       "      <td>MEXP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>hen_26</td>\n",
       "      <td>hen_82</td>\n",
       "      <td>pen5</td>\n",
       "      <td>OFH</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.434783950617284, 0.1385185185185185, 0...</td>\n",
       "      <td>0.411457</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>Inter individuals - OFH</td>\n",
       "      <td>LEXP</td>\n",
       "      <td>EPI</td>\n",
       "      <td>LEXPEPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21100</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>hen_26</td>\n",
       "      <td>hen_83</td>\n",
       "      <td>pen5</td>\n",
       "      <td>OFH</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>Inter individuals - OFH</td>\n",
       "      <td>LEXP</td>\n",
       "      <td>EPI</td>\n",
       "      <td>LEXPEPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           level    level+1   henID1   henID2 PenID Treatment  \\\n",
       "0     2020-09-30 2020-10-01  hen_102  hen_102  pen3       OFH   \n",
       "21099 2020-09-30 2020-10-01   hen_26   hen_82  pen5       OFH   \n",
       "21100 2020-09-30 2020-10-01   hen_26   hen_83  pen5       OFH   \n",
       "\n",
       "                            dur_values_normalized_henID1  \\\n",
       "0      [0.0, 0.010625, 0.19631944444444444, 0.0215625...   \n",
       "21099                          [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "21100                          [0.0, 0.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                            dur_values_normalized_henID2  chi2distance  DOA  \\\n",
       "0                              [0.0, 0.0, 0.0, 0.0, 1.0]      0.128991  119   \n",
       "21099  [0.0, 0.434783950617284, 0.1385185185185185, 0...      0.411457  119   \n",
       "21100                          [0.0, 0.0, 0.0, 0.0, 1.0]      0.000000  119   \n",
       "\n",
       "       ...  nbr_obs_l1_30_4_Zone  nbr_obs_l2_30_4_Zone DTW_30_1_Zone  \\\n",
       "0      ...                    33                    33           0.0   \n",
       "21099  ...                    33                    33           0.0   \n",
       "21100  ...                    33                    33           0.0   \n",
       "\n",
       "       nbr_obs_l1_30_1_Zone  nbr_obs_l2_30_1_Zone  is_same_ind  \\\n",
       "0                        33                    33         True   \n",
       "21099                    33                    33        False   \n",
       "21100                    33                    33        False   \n",
       "\n",
       "                          type  HenID1_CLASS  HenID2_CLASS    CLASS  \n",
       "0      Intra individuals - OFH          MEXP          MEXP     MEXP  \n",
       "21099  Inter individuals - OFH          LEXP           EPI  LEXPEPI  \n",
       "21100  Inter individuals - OFH          LEXP           EPI  LEXPEPI  \n",
       "\n",
       "[3 rows x 106 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute the chi2-distance from any two normalized vector of durations per zone that are from consectives days and same pen\n",
    "li_df = []\n",
    "li_zone = list(dico_pen_bin_zone_level_h['pen3'][15].keys())\n",
    "#use df_daily datframe to ensure using ONLY available correct dates!\n",
    "for p, df_pen in tqdm.tqdm(df_daily.groupby('PenID')):\n",
    "    p = 'pen'+str(int(p))\n",
    "    li_date = set(df_pen['level'].tolist())\n",
    "    tr = df_pen['Treatment'].unique()[0]\n",
    "    for d1 in sorted(list(li_date)):\n",
    "        doa = df_doa[df_doa['level']==d1]['DOA'].values[0]\n",
    "        woa = df_doa[df_doa['level']==d1]['WOA'].values[0]\n",
    "        d2 = d1+dt.timedelta(days=1)\n",
    "        li_hen_d1 = df_pen[df_pen['level']==d1]['HenID'].unique()\n",
    "        li_hen_d2 = df_pen[df_pen['level']==d2]['HenID'].unique()\n",
    "        #its a symmetric measure, so we only do each combination once\n",
    "        for h1 in li_hen_d1:\n",
    "            for h2 in li_hen_d2:\n",
    "\n",
    "                ############ Overall aviary usage similarity across days in terms of duration\n",
    "                l1 = df_pen[(df_pen['HenID']==h1)&(df_pen['level']==d1)]['dur_values_normalized'].values[0]\n",
    "                l2 = df_pen[(df_pen['HenID']==h2)&(df_pen['level']==d2)]['dur_values_normalized'].values[0]\n",
    "                dico_ = {'level':d1, 'level+1':d2, 'henID1':h1, 'henID2':h2, 'PenID':p, 'Treatment':tr,\n",
    "                         'dur_values_normalized_henID1':l1,'dur_values_normalized_henID2':l2,\n",
    "                         'chi2distance':chi2_distance(l1,l2),'DOA':doa,'WOA':woa}\n",
    "                \n",
    "                ############# Specifics' zones usage similarity across days\n",
    "                for nbr_binmn in li_binmn:\n",
    "                    \n",
    "                    #chi2distance of duration at small grained bin inervals does not really make sense when comparing one MLP\n",
    "                    #with one on the day after, as the light schedule change. DTW is better in this case.\n",
    "                    #for now we keep as long as we are exploring\n",
    "                    #ALL zone together with chi2distance\n",
    "                    l1_chi2 = dico_pen_bin_level_h[p][nbr_binmn][d1][h1]\n",
    "                    l2_chi2 = dico_pen_bin_level_h[p][nbr_binmn][d2][h2]\n",
    "                    dico_['nbr_obs_chi2all_'+str(nbr_binmn)] = len(l1_chi2)\n",
    "                    li_chi2 = [chi2_distance(l1_chi2[i],l2_chi2[i]) for i in range(0,len(l1_chi2))]\n",
    "                    dico_['li_chi2_'+str(nbr_binmn)] = li_chi2\n",
    "                    #note that we can't simply sum as there is not the same amount of 15mn bin per day!\n",
    "                    dico_['chi2distance_ALL_'+str(nbr_binmn)] = np.mean(li_chi2)\n",
    "                    \n",
    "                    #per zone with DTW\n",
    "                    for ZONE in li_zone:\n",
    "                        dtw_value = np.nan\n",
    "                        try:\n",
    "                            l1 = np.array(dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE][d1][h1], dtype=np.double)\n",
    "                            l2 = np.array(dico_pen_bin_zone_level_h[p][nbr_binmn][ZONE][d2][h2], dtype=np.double)\n",
    "                            #compute distance measure\n",
    "                            #path = dtw.warping_path(s1, s2)\n",
    "                            #dtwvis.plot_warping(s1, s2, path, filename=\"warp.png\")\n",
    "                            #d = dtw.distance_fast(s1, s2)\n",
    "                            #psi: #of start and end points of a sequence can be ignored if this would lead to a lower distance\n",
    "                            dtw_value, paths = dtw.warping_paths(l1, l2, window=dico_window[nbr_binmn], psi=0, penalty=penalty) #, max_step=0\n",
    "                        except Exception as e:\n",
    "                            #print(e)\n",
    "                            #print(p,' ',nbr_binmn,' ',ZONE,' ',d1,' ',h1,' ',d2,' ',h2)\n",
    "                            pass #dont do anything\n",
    "                        dico_['DTW_'+str(nbr_binmn)+'_'+ZONE] = round(dtw_value,1)  \n",
    "                        dico_['nbr_obs_l1_'+str(nbr_binmn)+'_'+ZONE] = len(l1)\n",
    "                        dico_['nbr_obs_l2_'+str(nbr_binmn)+'_'+ZONE] = len(l2)\n",
    "                li_df.append(dico_)\n",
    "                \n",
    "#turn inter and intra distances into a dataframe                \n",
    "df_interintra = pd.DataFrame(li_df)\n",
    "#df_interintra = df_interintra[~df_interintra['chi2distance'].isnull()]\n",
    "df_interintra['is_same_ind'] = df_interintra.apply(lambda x: x['henID1']==x['henID2'], axis=1)\n",
    "df_interintra = df_interintra.sort_values('DOA', ascending=True)\n",
    "dico_name = {True: 'Intra individuals', False:'Inter individuals'}\n",
    "df_interintra['type'] = df_interintra.apply(lambda x: dico_name[x['is_same_ind']]+' - '+x['Treatment'], axis=1)\n",
    "#add class\n",
    "df_interintra['HenID1_CLASS'] = df_interintra['henID1'].map(lambda x: df_FB[df_FB['HenID']==x]['CLASS'].values[0])\n",
    "df_interintra['HenID2_CLASS'] = df_interintra['henID2'].map(lambda x: df_FB[df_FB['HenID']==x]['CLASS'].values[0])\n",
    "df_interintra['CLASS'] = df_interintra.apply(lambda x:x['HenID1_CLASS']+''+x['HenID2_CLASS'], axis=1)\n",
    "df_interintra['CLASS'] = df_interintra['CLASS'].replace('MEXPMEXP','MEXP')\n",
    "df_interintra['CLASS'] = df_interintra['CLASS'].replace('LEXPLEXP','LEXP')\n",
    "li_col = list(df_interintra.columns)\n",
    "li_remove = [i for i in li_col if i.startswith('li_chi2_')]\n",
    "print(li_remove)\n",
    "li_keep = [i for i in li_col if i not in li_remove]\n",
    "#df_interintra.iloc[0:1000].to_csv(os.path.join(path_extracted_data_visual_adap, id_run+'_df_DistanceRoutineDev_4verification.csv'), sep=';', index=False)\n",
    "#df_interintra.filter(li_keep).to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+'_df_DistanceRoutineDev.csv'), sep=';', index=False)\n",
    "df_interintra.to_csv(os.path.join(path_extracted_data_visual_adap ,id_run+'_df_DistanceRoutineDev2h-17h59LEVEL.csv'), sep=';', index=False)\n",
    "print(df_interintra.shape)\n",
    "display(df_interintra.head(3))\n",
    "#~4h of run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 106)\n",
      "(0, 106)\n",
      "(0, 106)\n",
      "(0, 106)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#identify potential issues\n",
    "print(df_interintra[df_interintra['DTW_5_3_Zone'].isnull()].shape)\n",
    "print(df_interintra[df_interintra['DTW_5_3_Zone']==np.inf].shape)\n",
    "print(df_interintra[df_interintra['chi2distance'].isnull()].shape)\n",
    "print(df_interintra[df_interintra['chi2distance']==np.inf].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test some DTW output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#for generality purpose, open the dictionary\n",
    "dico_pen_bin_zone_level_h = pickle.load(open(os.path.join(path_extracted_data_visual_adap, \n",
    "                                                     id_run+'dico_pen_bin_zone_level_h.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [05:11<00:00, 38.98s/it]\n"
     ]
    }
   ],
   "source": [
    "#choose x random days for x random hens per pen/bin/zone and plot its intra ts\n",
    "#random.seed(0) #for reproducibility\n",
    "nbr_days = 3\n",
    "nbr_hens = 3\n",
    "for p, dico_bin_zone_level_h in tqdm.tqdm(dico_pen_bin_zone_level_h.items()):\n",
    "    for nbr_binmn, dico_zone_level_h in dico_bin_zone_level_h.items():\n",
    "        for ZONE, dico_level_h in dico_zone_level_h.items():\n",
    "            li_randates = random.sample(dico_level_h.keys(), nbr_days)\n",
    "            for d1 in li_randates:\n",
    "                d2 = d1+dt.timedelta(days=1)\n",
    "                li_ranhens = random.sample(dico_level_h[d1].keys(), nbr_hens)\n",
    "                for h in li_ranhens:\n",
    "                    #might fail if we dont have the day but we dont care we jsut want few plots to udnerstand better\n",
    "                    try:\n",
    "                        l1 = np.array(dico_level_h[d1][h], dtype=np.double) \n",
    "                        l2 = np.array(dico_level_h[d2][h], dtype=np.double) \n",
    "                        fig = plt.figure(figsize=(15,5))\n",
    "                        dtw_value, p = dtw.warping_paths(l1, l2, window=dico_window[nbr_binmn], psi=0, penalty=penalty)\n",
    "                        plt.plot(l1, color='blue')\n",
    "                        plt.plot(l2, color='orange')\n",
    "                        title = str(round(dtw_value,2))+'_'+h+'_BIN'+str(nbr_binmn)+'_'+ZONE\n",
    "                        plt.title(title)\n",
    "                        plt.savefig(os.path.join(path_extracted_data_visual_adap_verification, title+'.png'))\n",
    "                        plt.close()\n",
    "                    except Exception as e:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " array([[0.        ,        inf,        inf,        inf,        inf,\n",
       "                inf,        inf,        inf,        inf],\n",
       "        [       inf, 0.        , 0.        , 1.        , 1.        ,\n",
       "         1.        , 1.        ,        inf,        inf],\n",
       "        [       inf,        inf, 1.        , 0.        , 1.        ,\n",
       "         1.41421356, 1.41421356, 1.41421356,        inf],\n",
       "        [       inf,        inf,        inf, 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#small testing\n",
    "l_1 = np.array([1,0,1], dtype=np.double)\n",
    "l_2 = np.array([1,1,0,1,1,1,1,1], dtype=np.double)\n",
    "dtw.warping_paths(l_1, l_2, window=1, psi=0, penalty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
