{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "#data augmentation\n",
    "#import local version of the library imgaug\n",
    "sys.path.append('C:\\\\Users\\\\camil\\\\Desktop\\\\animals_code\\\\imgaug')\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "#unbalanced dataset\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "path_image = os.path.join('datasets','KBF','ANNOTATED_IMAGES')\n",
    "\n",
    "#import local version of the library of Mask RCNN\n",
    "sys.path.append('C:\\\\Users\\\\camil\\\\Desktop\\\\animals_code\\\\Mask_RCNN')\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join('C:\\\\Users\\\\camil','Desktop','animals_code','Mask_RCNN', \"mask_rcnn_coco_resnet101.h5\")\n",
    "IMAGENET_WEIGHTS_PATH = os.path.join('C:\\\\Users\\\\camil','Desktop','animals_code','Mask_RCNN', \"resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "LOGS_DIRECTORY = os.path.join('C:\\\\Users\\\\camil\\Desktop\\\\animals_code\\\\PhD-AnimalWelfare','KBF_CNN','LOGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU issue (595): for fast update to monitoring it in real time. If it is utilized some, but not all the time, it means that\n",
    "#it waits for CPU to finish and halt, it means that your load_mask or load_image function is slow.\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0' TODO: check what this is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on command prompt: conda install cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_data_class_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images must be all in the path_image folder for the algo to use them. We will simply provide the algo the name of the image \n",
    "#and the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        8\n",
      "DETECTION_MIN_CONFIDENCE       0.65\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                17\n",
      "IMAGE_MIN_DIM                  170\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [256 256   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0005\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               30\n",
      "MEAN_PIXEL                     [80 80 80]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           KBF_flickr\n",
      "NUM_CLASSES                    5\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        200\n",
      "POST_NMS_ROIS_TRAINING         600\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              2\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.2\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                15\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               2\n",
      "WEIGHT_DECAY                   1e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = utils_data_class_and_config.DataConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.Sometimes(0.85,[\n",
    "        \n",
    "    #Sharpen or emboss an image: 'see more the pixels' & contrast\n",
    "    iaa.SomeOf(0.2,[iaa.Sharpen(alpha=(0.5,1), lightness=(1)),\n",
    "                  iaa.Emboss(alpha=(0.5,1), strength=(1.0,1.7)),\n",
    "                   iaa.ContrastNormalization((0.5,1.5))]),\n",
    "    \n",
    "    #dangerous with our data\n",
    "    #Add r values between -30 and 30 to images. In 50% of all images the values differ per channel (3 sampled value). \n",
    "    #In the other 50% of all images the value is the same for all channels: (change color constancy)\n",
    "    #iaa.Add((-20, 20), per_channel=0.5),\n",
    "    #Increase/decrease S (saturation i.e. how colorful it is)\n",
    "    #iaa.WithColorspace(to_colorspace=\"HSV\", from_colorspace=\"RGB\", \n",
    "    #                         children=iaa.WithChannels(1, iaa.Multiply((0.65,1.35)))),\n",
    "    #not good as it can be part of caracteristic for species\n",
    "    #scale image independantly in x and y axis \n",
    "    #iaa.Affine(scale={\"x\": (0.75, 1.25), \"y\": (0.75, 1.25)}),\n",
    "    #distortion\n",
    "    #iaa.PiecewiseAffine(scale=(0.01, 0.03)),\n",
    "    \n",
    "    #darkness/brightness choose one of both technique\n",
    "    iaa.Sometimes(0.2,iaa.SomeOf(1,[iaa.Multiply((0.75, 1.25)),\n",
    "                                    #Increase/decrease V (value i.e. how bright/dark) \n",
    "                                    iaa.WithColorspace(to_colorspace=\"HSV\", from_colorspace=\"RGB\", \n",
    "                                                       children=iaa.WithChannels(2, iaa.Multiply((0.75, 1.25))))])),\n",
    "    \n",
    "    #flip horizontaly and vertically to make as if the fish was swimimg from both direction and from upside down\n",
    "    iaa.Fliplr(0.3),\n",
    "    iaa.Flipud(0.15),\n",
    "    iaa.Sometimes(0.3,iaa.Affine(rotate=(-15, 15))),\n",
    "    #iaa.Sometimes(0.5,iaa.SomeOf(1, [iaa.Affine(rotate=15),iaa.Affine(rotate=30),iaa.Affine(rotate=45),\n",
    "    #                                 iaa.Affine(rotate=5),iaa.Affine(rotate=10),iaa.Affine(rotate=25),\n",
    "    #                                 iaa.Affine(rotate=60),iaa.Affine(rotate=75),iaa.Affine(rotate=0)]))\n",
    "    \n",
    "    #weather: Clouds, Fog, Snowflakes & noise #iaa.Fog(),iaa.Snowflakes(density=(0.005, 0.025),flake_size=(0.2, 1.0))\n",
    "    #noise: \n",
    "    iaa.Sometimes(0.2,iaa.SomeOf(1,[iaa.AdditiveGaussianNoise(scale=0.007*255), \n",
    "                                    iaa.AverageBlur(k=(2, 5))])),\n",
    "    #AttributeError: 'CloudLayer' object has no attribute 'density_min'\n",
    "    #iaa.Sometimes(0.2,[iaa.SomeOf(1,[iaa.Clouds(),\n",
    "    #                                 iaa.Snowflakes(density=(0.005, 0.025),flake_size=(0.2, 1.0))])]),\n",
    "    \n",
    "    #resize (not bigger as not all fish can be bigger, but smaller in theory yes)\n",
    "    iaa.Sometimes(0.5,iaa.Resize((0.5, 1.0)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10057796542673430702\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14448868414071970151\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17878557664136668624\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#verify if tensorflow with GPU is well installed : it works!\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Device to load the neural network on.\n",
    "#Useful if you're training a model on the same \n",
    "#machine, in which case use CPU and leave the\n",
    "#GPU for training.\n",
    "#DEVICE = \"/GPU:0\"  # /cpu:0 or /gpu:0\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    model = modellib.MaskRCNN(mode='training', model_dir=LOGS_DIRECTORY, config=config)\n",
    "#hence can not change config and using same model, its initiate with this config now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode='training', model_dir=LOGS_DIRECTORY, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, firstepoch=0, second=25, third=5, fourth=3):\n",
    "    \n",
    "    path_ = path_image\n",
    "\n",
    "    ########################################################################################   \n",
    "    #print('Fine tune Resnet stage 4 and up with algue to be able to distinguish between both')\n",
    "    \n",
    "    #Finetune layers from ResNet stage 4 and up\n",
    "    #training dataset.\n",
    "    '''dataset_train = utils_data_class_and_config.VGG_Dataset()\n",
    "    dataset_train.load_vgg(path_, \"train\")\n",
    "    dataset_train.prepare()\n",
    "    \n",
    "    #validation dataset\n",
    "    dataset_val = utils_data_class_and_config.VGG_Dataset()\n",
    "    dataset_val.load_vgg(path_, \"val\")\n",
    "    dataset_val.prepare()\n",
    "    \n",
    "    #training\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate = config.LEARNING_RATE,\n",
    "                epochs = firstepoch,\n",
    "                layers = 'all', augmentation=aug)'''\n",
    "    \n",
    "    ########################################################################################\n",
    "    #print('Fine tune all layers without algue')\n",
    "    \n",
    "    #training dataset.\n",
    "    dataset_train = utils_data_class_and_config.VGG_Dataset()\n",
    "    dataset_train.load_vgg(path_, \"train\")\n",
    "    dataset_train.prepare()\n",
    "    \n",
    "    #validation dataset\n",
    "    dataset_val = utils_data_class_and_config.VGG_Dataset()\n",
    "    dataset_val.load_vgg(path_, \"val\")\n",
    "    dataset_val.prepare()\n",
    "    \n",
    "    print('start training')\n",
    "    #training\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=firstepoch+second,\n",
    "                layers='all') #, augmentation=aug\n",
    "    \n",
    "    '''model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE/10,\n",
    "                epochs=firstepoch+second+third,\n",
    "                layers='all', augmentation=aug)\n",
    "    \n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE/100,\n",
    "                epochs=firstepoch+second+third+fourth,\n",
    "                layers='all')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the last layers because they require a number of classes matching\n",
    "WEIGHTS_PATH = IMAGENET_WEIGHTS_PATH\n",
    "WEIGHTS_PATH = COCO_WEIGHTS_PATH\n",
    "model.load_weights(WEIGHTS_PATH, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "#my ones\n",
    "#WEIGHTS_PATH = os.path.join(LOGS_DIRECTORY, '?', 'mask_rcnn_dog_flickr_0400.h5')\n",
    "#model.load_weights(WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "\n",
      "Starting at epoch 0. LR=0.0005\n",
      "\n",
      "Checkpoint Path: C:\\Users\\camil\\Desktop\\animals_code\\PhD-AnimalWelfare\\KBF_CNN\\LOGS\\kbf_flickr20210806T1046\\mask_rcnn_kbf_flickr_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - batch: 7.0000 - size: 2.0000 - loss: 3.2621 - rpn_class_loss: 0.0998 - rpn_bbox_loss: 2.0566 - mrcnn_class_loss: 0.5273 - mrcnn_bbox_loss: 0.3394 - mrcnn_mask_loss: 0.2390 WARNING:tensorflow:From C:\\Users\\camil\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "15/15 [==============================] - 184s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 3.2621 - rpn_class_loss: 0.0998 - rpn_bbox_loss: 2.0566 - mrcnn_class_loss: 0.5273 - mrcnn_bbox_loss: 0.3394 - mrcnn_mask_loss: 0.2390 - val_loss: 1.4434 - val_rpn_class_loss: 0.0564 - val_rpn_bbox_loss: 1.3870 - val_mrcnn_class_loss: 9.2089e-06 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 173s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 2.1351 - rpn_class_loss: 0.0788 - rpn_bbox_loss: 1.7110 - mrcnn_class_loss: 0.0084 - mrcnn_bbox_loss: 0.2119 - mrcnn_mask_loss: 0.1250 - val_loss: 1.2127 - val_rpn_class_loss: 0.0372 - val_rpn_bbox_loss: 1.1755 - val_mrcnn_class_loss: 1.9073e-06 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 173s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.8704 - rpn_class_loss: 0.0606 - rpn_bbox_loss: 1.2566 - mrcnn_class_loss: 0.0118 - mrcnn_bbox_loss: 0.3109 - mrcnn_mask_loss: 0.2306 - val_loss: 1.7620 - val_rpn_class_loss: 0.0782 - val_rpn_bbox_loss: 0.8636 - val_mrcnn_class_loss: 0.0161 - val_mrcnn_bbox_loss: 0.3331 - val_mrcnn_mask_loss: 0.4710\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 175s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.9707 - rpn_class_loss: 0.0559 - rpn_bbox_loss: 1.1582 - mrcnn_class_loss: 0.0170 - mrcnn_bbox_loss: 0.4280 - mrcnn_mask_loss: 0.3116 - val_loss: 2.1820 - val_rpn_class_loss: 0.1154 - val_rpn_bbox_loss: 1.4900 - val_mrcnn_class_loss: 0.0166 - val_mrcnn_bbox_loss: 0.2540 - val_mrcnn_mask_loss: 0.3060\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 181s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.6247 - rpn_class_loss: 0.0445 - rpn_bbox_loss: 1.0834 - mrcnn_class_loss: 0.0076 - mrcnn_bbox_loss: 0.2793 - mrcnn_mask_loss: 0.2099 - val_loss: 0.9934 - val_rpn_class_loss: 0.0403 - val_rpn_bbox_loss: 0.9530 - val_mrcnn_class_loss: 2.2560e-05 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 170s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 1.8824 - rpn_class_loss: 0.0602 - rpn_bbox_loss: 1.5726 - mrcnn_class_loss: 0.0054 - mrcnn_bbox_loss: 0.1213 - mrcnn_mask_loss: 0.1228 - val_loss: 2.0558 - val_rpn_class_loss: 0.0244 - val_rpn_bbox_loss: 0.6582 - val_mrcnn_class_loss: 0.0170 - val_mrcnn_bbox_loss: 0.7508 - val_mrcnn_mask_loss: 0.6053\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 171s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 2.0854 - rpn_class_loss: 0.0733 - rpn_bbox_loss: 1.3937 - mrcnn_class_loss: 0.0065 - mrcnn_bbox_loss: 0.2975 - mrcnn_mask_loss: 0.3143 - val_loss: 1.0593 - val_rpn_class_loss: 0.0467 - val_rpn_bbox_loss: 0.2345 - val_mrcnn_class_loss: 0.0075 - val_mrcnn_bbox_loss: 0.4305 - val_mrcnn_mask_loss: 0.3402\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 171s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 1.7014 - rpn_class_loss: 0.0423 - rpn_bbox_loss: 1.0495 - mrcnn_class_loss: 0.0064 - mrcnn_bbox_loss: 0.3569 - mrcnn_mask_loss: 0.2462 - val_loss: 3.1492 - val_rpn_class_loss: 0.0545 - val_rpn_bbox_loss: 1.9632 - val_mrcnn_class_loss: 0.0137 - val_mrcnn_bbox_loss: 0.8876 - val_mrcnn_mask_loss: 0.2301\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 178s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.6239 - rpn_class_loss: 0.0434 - rpn_bbox_loss: 0.9138 - mrcnn_class_loss: 0.0083 - mrcnn_bbox_loss: 0.3900 - mrcnn_mask_loss: 0.2684 - val_loss: 2.6650 - val_rpn_class_loss: 0.0221 - val_rpn_bbox_loss: 1.4158 - val_mrcnn_class_loss: 0.0087 - val_mrcnn_bbox_loss: 0.7108 - val_mrcnn_mask_loss: 0.5077\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 179s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.7817 - rpn_class_loss: 0.0425 - rpn_bbox_loss: 1.0269 - mrcnn_class_loss: 0.0066 - mrcnn_bbox_loss: 0.3799 - mrcnn_mask_loss: 0.3257 - val_loss: 1.5641 - val_rpn_class_loss: 0.0378 - val_rpn_bbox_loss: 0.9429 - val_mrcnn_class_loss: 0.0076 - val_mrcnn_bbox_loss: 0.2782 - val_mrcnn_mask_loss: 0.2977\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 174s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.8929 - rpn_class_loss: 0.0356 - rpn_bbox_loss: 1.2476 - mrcnn_class_loss: 0.0074 - mrcnn_bbox_loss: 0.3584 - mrcnn_mask_loss: 0.2439 - val_loss: 1.9133 - val_rpn_class_loss: 0.0205 - val_rpn_bbox_loss: 0.4465 - val_mrcnn_class_loss: 0.0115 - val_mrcnn_bbox_loss: 0.8910 - val_mrcnn_mask_loss: 0.5439\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 173s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.3842 - rpn_class_loss: 0.0328 - rpn_bbox_loss: 0.8057 - mrcnn_class_loss: 0.0077 - mrcnn_bbox_loss: 0.3079 - mrcnn_mask_loss: 0.2302 - val_loss: 1.3979 - val_rpn_class_loss: 0.0250 - val_rpn_bbox_loss: 0.6722 - val_mrcnn_class_loss: 0.0054 - val_mrcnn_bbox_loss: 0.2555 - val_mrcnn_mask_loss: 0.4397\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 170s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 1.1949 - rpn_class_loss: 0.0401 - rpn_bbox_loss: 0.6935 - mrcnn_class_loss: 0.0047 - mrcnn_bbox_loss: 0.2429 - mrcnn_mask_loss: 0.2137 - val_loss: 1.1807 - val_rpn_class_loss: 0.0292 - val_rpn_bbox_loss: 0.7854 - val_mrcnn_class_loss: 0.0061 - val_mrcnn_bbox_loss: 0.1567 - val_mrcnn_mask_loss: 0.2034\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 173s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.5506 - rpn_class_loss: 0.0438 - rpn_bbox_loss: 0.9937 - mrcnn_class_loss: 0.0030 - mrcnn_bbox_loss: 0.2838 - mrcnn_mask_loss: 0.2263 - val_loss: 2.5877 - val_rpn_class_loss: 0.0520 - val_rpn_bbox_loss: 1.7306 - val_mrcnn_class_loss: 0.0099 - val_mrcnn_bbox_loss: 0.4677 - val_mrcnn_mask_loss: 0.3275\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 177s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.4967 - rpn_class_loss: 0.0496 - rpn_bbox_loss: 1.0966 - mrcnn_class_loss: 0.0041 - mrcnn_bbox_loss: 0.1847 - mrcnn_mask_loss: 0.1618 - val_loss: 2.0351 - val_rpn_class_loss: 0.0409 - val_rpn_bbox_loss: 0.9204 - val_mrcnn_class_loss: 0.0163 - val_mrcnn_bbox_loss: 0.5210 - val_mrcnn_mask_loss: 0.5366\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 175s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.3906 - rpn_class_loss: 0.0423 - rpn_bbox_loss: 0.8903 - mrcnn_class_loss: 0.0038 - mrcnn_bbox_loss: 0.2686 - mrcnn_mask_loss: 0.1856 - val_loss: 1.6572 - val_rpn_class_loss: 0.0521 - val_rpn_bbox_loss: 0.8670 - val_mrcnn_class_loss: 0.0016 - val_mrcnn_bbox_loss: 0.5799 - val_mrcnn_mask_loss: 0.1567\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 174s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.4716 - rpn_class_loss: 0.0337 - rpn_bbox_loss: 0.8479 - mrcnn_class_loss: 0.0052 - mrcnn_bbox_loss: 0.3535 - mrcnn_mask_loss: 0.2313 - val_loss: 1.6199 - val_rpn_class_loss: 0.0510 - val_rpn_bbox_loss: 1.0963 - val_mrcnn_class_loss: 0.0045 - val_mrcnn_bbox_loss: 0.2354 - val_mrcnn_mask_loss: 0.2327\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 186s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.5121 - rpn_class_loss: 0.0322 - rpn_bbox_loss: 0.8218 - mrcnn_class_loss: 0.0051 - mrcnn_bbox_loss: 0.4254 - mrcnn_mask_loss: 0.2276 - val_loss: 0.6919 - val_rpn_class_loss: 0.0329 - val_rpn_bbox_loss: 0.6590 - val_mrcnn_class_loss: 9.3724e-05 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 170s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 1.4268 - rpn_class_loss: 0.0343 - rpn_bbox_loss: 0.8391 - mrcnn_class_loss: 0.0070 - mrcnn_bbox_loss: 0.3310 - mrcnn_mask_loss: 0.2153 - val_loss: 1.3656 - val_rpn_class_loss: 0.0294 - val_rpn_bbox_loss: 0.9425 - val_mrcnn_class_loss: 0.0046 - val_mrcnn_bbox_loss: 0.2175 - val_mrcnn_mask_loss: 0.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "15/15 [==============================] - 177s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.5493 - rpn_class_loss: 0.0384 - rpn_bbox_loss: 1.1970 - mrcnn_class_loss: 0.0033 - mrcnn_bbox_loss: 0.2039 - mrcnn_mask_loss: 0.1068 - val_loss: 1.8648 - val_rpn_class_loss: 0.0395 - val_rpn_bbox_loss: 1.3868 - val_mrcnn_class_loss: 0.0048 - val_mrcnn_bbox_loss: 0.2992 - val_mrcnn_mask_loss: 0.1345\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 183s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.5398 - rpn_class_loss: 0.0345 - rpn_bbox_loss: 0.9747 - mrcnn_class_loss: 0.0063 - mrcnn_bbox_loss: 0.3245 - mrcnn_mask_loss: 0.1997 - val_loss: 2.1079 - val_rpn_class_loss: 0.0381 - val_rpn_bbox_loss: 1.2182 - val_mrcnn_class_loss: 0.0072 - val_mrcnn_bbox_loss: 0.3607 - val_mrcnn_mask_loss: 0.4837\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 181s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 0.9816 - rpn_class_loss: 0.0301 - rpn_bbox_loss: 0.7449 - mrcnn_class_loss: 0.0021 - mrcnn_bbox_loss: 0.1167 - mrcnn_mask_loss: 0.0877 - val_loss: 0.7295 - val_rpn_class_loss: 0.0186 - val_rpn_bbox_loss: 0.7108 - val_mrcnn_class_loss: 1.2108e-04 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 181s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.3272 - rpn_class_loss: 0.0302 - rpn_bbox_loss: 0.8056 - mrcnn_class_loss: 0.0059 - mrcnn_bbox_loss: 0.2455 - mrcnn_mask_loss: 0.2402 - val_loss: 1.5174 - val_rpn_class_loss: 0.0437 - val_rpn_bbox_loss: 0.9545 - val_mrcnn_class_loss: 0.0074 - val_mrcnn_bbox_loss: 0.3859 - val_mrcnn_mask_loss: 0.1260\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 179s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.2719 - rpn_class_loss: 0.0347 - rpn_bbox_loss: 0.7508 - mrcnn_class_loss: 0.0046 - mrcnn_bbox_loss: 0.3067 - mrcnn_mask_loss: 0.1751 - val_loss: 0.8626 - val_rpn_class_loss: 0.0293 - val_rpn_bbox_loss: 0.6399 - val_mrcnn_class_loss: 0.0015 - val_mrcnn_bbox_loss: 0.0664 - val_mrcnn_mask_loss: 0.1255\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 173s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.3019 - rpn_class_loss: 0.0293 - rpn_bbox_loss: 0.7316 - mrcnn_class_loss: 0.0049 - mrcnn_bbox_loss: 0.2764 - mrcnn_mask_loss: 0.2597 - val_loss: 1.3569 - val_rpn_class_loss: 0.0246 - val_rpn_bbox_loss: 0.7083 - val_mrcnn_class_loss: 0.0017 - val_mrcnn_bbox_loss: 0.3355 - val_mrcnn_mask_loss: 0.2868\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 172s 11s/step - batch: 7.0000 - size: 2.0000 - loss: 1.3084 - rpn_class_loss: 0.0298 - rpn_bbox_loss: 0.9530 - mrcnn_class_loss: 0.0037 - mrcnn_bbox_loss: 0.1564 - mrcnn_mask_loss: 0.1654 - val_loss: 1.0072 - val_rpn_class_loss: 0.0246 - val_rpn_bbox_loss: 0.6940 - val_mrcnn_class_loss: 0.0021 - val_mrcnn_bbox_loss: 0.1733 - val_mrcnn_mask_loss: 0.1131\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 181s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.7181 - rpn_class_loss: 0.0323 - rpn_bbox_loss: 0.9908 - mrcnn_class_loss: 0.0058 - mrcnn_bbox_loss: 0.3805 - mrcnn_mask_loss: 0.3087 - val_loss: 1.3254 - val_rpn_class_loss: 0.0171 - val_rpn_bbox_loss: 0.3405 - val_mrcnn_class_loss: 0.0120 - val_mrcnn_bbox_loss: 0.4954 - val_mrcnn_mask_loss: 0.4605\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 180s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.2654 - rpn_class_loss: 0.0281 - rpn_bbox_loss: 0.6431 - mrcnn_class_loss: 0.0086 - mrcnn_bbox_loss: 0.3091 - mrcnn_mask_loss: 0.2764 - val_loss: 1.0962 - val_rpn_class_loss: 0.0289 - val_rpn_bbox_loss: 1.0673 - val_mrcnn_class_loss: 1.2808e-04 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 182s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.0623 - rpn_class_loss: 0.0315 - rpn_bbox_loss: 0.7406 - mrcnn_class_loss: 0.0049 - mrcnn_bbox_loss: 0.1411 - mrcnn_mask_loss: 0.1442 - val_loss: 0.4310 - val_rpn_class_loss: 0.0182 - val_rpn_bbox_loss: 0.2221 - val_mrcnn_class_loss: 0.0041 - val_mrcnn_bbox_loss: 0.1057 - val_mrcnn_mask_loss: 0.0810\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 184s 12s/step - batch: 7.0000 - size: 2.0000 - loss: 1.1490 - rpn_class_loss: 0.0279 - rpn_bbox_loss: 0.7191 - mrcnn_class_loss: 0.0055 - mrcnn_bbox_loss: 0.2398 - mrcnn_mask_loss: 0.1566 - val_loss: 2.0024 - val_rpn_class_loss: 0.0163 - val_rpn_bbox_loss: 1.4034 - val_mrcnn_class_loss: 0.0063 - val_mrcnn_bbox_loss: 0.3827 - val_mrcnn_mask_loss: 0.1938\n"
     ]
    }
   ],
   "source": [
    "#train or evaluate\n",
    "train(model, 0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once TensorBoard is running, navigate your web browser to localhost:6006 to view the TensorBoard.\n",
    "#tensorboard --logdir=C:\\Users\\camil\\Desktop\\animals_code\\PhD-AnimalWelfare\\KBF_CNN\\LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: remove some class!!!\n",
    "#try without dog.. oke?\n",
    "# si non try with all\n",
    "#si non try with only dog then with all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
