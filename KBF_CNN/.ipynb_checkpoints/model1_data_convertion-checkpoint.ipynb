{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import collections\n",
    "import operator\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all_annotated_image = os.path.join('datasets','KBF','ANNOTATED_IMAGES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_PARENT = '..'\n",
    "SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser('__file__'))))\n",
    "sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))\n",
    "\n",
    "from UTILS.utils import from_vggbbox_get_vggpolygon, lists_remove_in1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each time new images are annotated, copy all images from the folder (i.e. even the one which were not annotated) and put\n",
    "#the annotation files in the annotations folder. We will here remove (put into no_regions fodler) all images which does not have\n",
    "#one or more regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download annotation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>size</th>\n",
       "      <th>regions</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>annotations_name</th>\n",
       "      <th>nbr_regions</th>\n",
       "      <th>no_type</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>70631</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>65599</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>66715</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\2.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename   size                                            regions  \\\n",
       "0    0.jpg  70631  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "1    1.jpg  65599  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "2    2.jpg  66715  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "\n",
       "  file_attributes           annotations_name  nbr_regions  no_type  \\\n",
       "0              {}  via_region_data (14).json            2    False   \n",
       "1              {}  via_region_data (14).json            1    False   \n",
       "2              {}  via_region_data (14).json            1    False   \n",
       "\n",
       "                                  path  \n",
       "0  datasets\\KBF\\ANNOTATED_IMAGES\\0.jpg  \n",
       "1  datasets\\KBF\\ANNOTATED_IMAGES\\1.jpg  \n",
       "2  datasets\\KBF\\ANNOTATED_IMAGES\\2.jpg  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path_all_annotated_image,'image_info.csv'), index_col=False, sep=';')\n",
    "df['regions'] = df['regions'].map(lambda x: eval(x))\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove some class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trier(x,li_keep):\n",
    "    xn = []\n",
    "    for r in x:\n",
    "        s = r['region_attributes']['CLASS']\n",
    "        if s in li_keep:\n",
    "            xn.append(r)\n",
    "    return xn\n",
    "#small test\n",
    "#trier(df['regions'].iloc[0], ['DO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['regions'] = df['regions'].map(lambda x: trier(x,['R', 'GF', 'F', 'G']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 177 annotated images\n",
      "There is 247 masks in total\n"
     ]
    }
   ],
   "source": [
    "li_species = []\n",
    "for k,reg in enumerate(df['regions'].tolist()):\n",
    "    for i in range(len(reg)):\n",
    "        s = reg[i]['region_attributes']['type']\n",
    "        if s=='':\n",
    "            print('no type')\n",
    "        else:\n",
    "            li_species.append(s)\n",
    "print('There is %d annotated images'%df.shape[0])\n",
    "print('There is %d masks in total'%len(li_species))\n",
    "c = dict(collections.Counter(li_species))\n",
    "if ('EY' in c) & ('EA' in c):\n",
    "    print('There is %d eyes and %d ears'%(c['EY'],c['EA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 4 classes: \n",
      "F \tG \tGF \tR\n"
     ]
    }
   ],
   "source": [
    "print('There is %d classes: %s'%(len(c.keys()),'\\n'+' \\t'.join(c.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': 26, 'G': 191, 'GF': 8, 'R': 22}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### species that exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thats the dico used in the config file, so if a species is not specified in this dico, then add in both the dico and the \n",
    "#config\n",
    "p = os.path.join(path_all_annotated_image, 'algo_file')\n",
    "#create a director if not existing for images\n",
    "if not os.path.exists(p):\n",
    "    os.makedirs(p)\n",
    "    \n",
    "dico_classid_id = {\"F\":1, \"G\":2, \"GF\":3, 'R':4}\n",
    "pickle.dump(dico_classid_id, open(os.path.join(p,'dico_classid_id.pkl'), 'wb'))\n",
    "#note that if not all species are used there will have a higher number of class_id than their truely is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species that exist but wont be taken into account for model: \n"
     ]
    }
   ],
   "source": [
    "print('Species that exist but wont be taken into account for model: ')\n",
    "for k in c.keys():\n",
    "    if k not in dico_classid_id.keys():\n",
    "        print('\\t', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['width'] = np.nan\n",
    "df['height'] = np.nan\n",
    "for img_p in df['path'].tolist():\n",
    "    img = cv2.imread(img_p)\n",
    "    df.loc[df['path']==img_p,'height'] = img.shape[0]\n",
    "    df.loc[df['path']==img_p,'width'] = img.shape[1]\n",
    "    \n",
    "df['width'] = df['width'].astype(int)\n",
    "df['height'] = df['height'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 151 images in the training set and 26 in the validation set\n"
     ]
    }
   ],
   "source": [
    "#split in training and validation set randomly according to the above nbr\n",
    "#note that for now we are not splitting according to the dtae, as it wont be good for certain species for which we have only one\n",
    "#date and also because their is a lot of variation in a single day! a osmetime particular situation occur over oen day only and\n",
    "#we still want to verify them. With mroe data we would be able to split according a independantn var: date\n",
    "li_id = df['filename'].tolist()\n",
    "nbr_val_image = int(len(li_id)*0.15)\n",
    "val_id = random.sample(li_id, nbr_val_image)\n",
    "train_id = [x for x in li_id if x not in val_id]\n",
    "print('There is %d images in the training set and %d in the validation set'%(len(train_id),len(val_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save annotations for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moves each of these train images to the train folder\n",
    "dico_t_id = {'train':train_id, 'val':val_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>size</th>\n",
       "      <th>regions</th>\n",
       "      <th>file_attributes</th>\n",
       "      <th>annotations_name</th>\n",
       "      <th>nbr_regions</th>\n",
       "      <th>no_type</th>\n",
       "      <th>path</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>70631</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\0.jpg</td>\n",
       "      <td>794</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>65599</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\1.jpg</td>\n",
       "      <td>810</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>66715</td>\n",
       "      <td>[{'shape_attributes': {'name': 'polygon', 'all...</td>\n",
       "      <td>{}</td>\n",
       "      <td>via_region_data (14).json</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>datasets\\KBF\\ANNOTATED_IMAGES\\2.jpg</td>\n",
       "      <td>794</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename   size                                            regions  \\\n",
       "0    0.jpg  70631  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "1    1.jpg  65599  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "2    2.jpg  66715  [{'shape_attributes': {'name': 'polygon', 'all...   \n",
       "\n",
       "  file_attributes           annotations_name  nbr_regions  no_type  \\\n",
       "0              {}  via_region_data (14).json            2    False   \n",
       "1              {}  via_region_data (14).json            1    False   \n",
       "2              {}  via_region_data (14).json            1    False   \n",
       "\n",
       "                                  path  width  height  \n",
       "0  datasets\\KBF\\ANNOTATED_IMAGES\\0.jpg    794    1437  \n",
       "1  datasets\\KBF\\ANNOTATED_IMAGES\\1.jpg    810    1437  \n",
       "2  datasets\\KBF\\ANNOTATED_IMAGES\\2.jpg    794    1437  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There will be 4 different class\n",
      "{'GF', 'G', 'F', 'R'}\n"
     ]
    }
   ],
   "source": [
    "li_reg = df['regions'].tolist()\n",
    "li_possible_type = []\n",
    "for reg in li_reg:\n",
    "    try:\n",
    "        for r in reg:\n",
    "            li_possible_type.append(r['region_attributes']['type'])\n",
    "    except Exception as e:\n",
    "        print(reg, e)\n",
    "#sort by order of number of annotations\n",
    "#c_final = dict(collections.Counter(li_possible_type))\n",
    "#c_final = sorted(c_final.items(), key=operator.itemgetter(1))\n",
    "#c_final.reverse()\n",
    "#dico_classid_id = {c_final[i][0]:i+1 for i in range(len(c_final))}\n",
    "print('There will be %d different class'%len(set(li_possible_type)))\n",
    "print(set(li_possible_type))\n",
    "L2add = [x for x in set(li_possible_type) if x not in dico_classid_id.keys()]\n",
    "L2add = [x for x in L2add if x not in ['AL', 'N']]\n",
    "if len(L2add)>0:\n",
    "    print('you should add these species to the config file, modify parameter NUM_CLASSES in the config file, and add them to \\\n",
    "    the above dico dico_classid_id:')\n",
    "    print(L2add)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update class_id_ when we have species, also update in utils_data_config\n",
    "dico_t_classes = {}\n",
    "for t in ['train', 'val']:\n",
    "    \n",
    "    li_allclasses = []\n",
    "    #create annotation file for training/validation \n",
    "    path_annotation_for_model = os.path.join(path_all_annotated_image, 'annotation_'+t+'.pkl')\n",
    "\n",
    "    #gather annotations\n",
    "    li = []\n",
    "    for filename in dico_t_id[t]:\n",
    "        reg = df[df['filename']==filename]['regions'].values[0]\n",
    "        try:\n",
    "            li_classids = [reg[k]['region_attributes']['type'] for k in range(len(reg))]\n",
    "            li_poly = [reg[k]['shape_attributes'] for k in range(len(reg))]\n",
    "\n",
    "            #remove all the unwanted mask which could not be removed during annotations (type=N)\n",
    "            #note that we keep the images, we jsut remove the annotation\n",
    "            li_classids, li_poly = lists_remove_in1(li_classids, li_poly, 'N')\n",
    "\n",
    "            #remove all AL on images (correct as it does not exist image with only one AL)\n",
    "            li_classids, li_poly = lists_remove_in1(li_classids, li_poly, 'AL')\n",
    "\n",
    "            #add info\n",
    "            li.append({'height':df[df['filename']==filename]['height'].values[0], #482\n",
    "                       'width':df[df['filename']==filename]['width'].values[0], #608\n",
    "                       'filename':filename,\n",
    "                       'class_id_':[dico_classid_id[x] for x in li_classids],\n",
    "                       'polygons':li_poly})\n",
    "            li_allclasses.extend(li_classids)\n",
    "        except Exception as e:\n",
    "            print(e, filename)\n",
    "\n",
    "    #verify duplicates\n",
    "    li_filename = [x['filename'] for x in li]\n",
    "    if len(li_filename)!=len(set(li_filename)):\n",
    "        print('ERROR: you have duplicates, verify which image has been annotated twice')\n",
    "        sys.exit()\n",
    "\n",
    "    #save\n",
    "    pickle.dump(li, open(path_annotation_for_model, 'wb'))\n",
    "    dico_t_classes[t] = list(set(li_allclasses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(li_filename),len(set(li_filename)))\n",
    "from collections import Counter\n",
    "ltest = [item for item, count in Counter(li_filename).items() if count > 1]\n",
    "print(len(ltest))\n",
    "df[df['filename']=='augmented_0_CYPY01_CAM02B02_02.06.16_183551_TRL_C.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following class are available: R, G, F, GF\n",
      "the following class are in validation: GF, F, G, R\n"
     ]
    }
   ],
   "source": [
    "li_t = dico_t_classes['train']\n",
    "li_v = dico_t_classes['val']\n",
    "print('the following class are available: %s'% ', '.join(set(li_v+li_t)))\n",
    "print('the following class are in validation: %s'% ', '.join(li_v))\n",
    "\n",
    "#if some class are in the validation but not in the training set print error\n",
    "if sum([x not in li_t for x in li_v])>0:\n",
    "    print('ERROR: some class are in the validation but not in the training set')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
