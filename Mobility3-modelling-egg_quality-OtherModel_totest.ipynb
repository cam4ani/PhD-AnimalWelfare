{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\camil\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#basic package\n",
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import time\n",
    "import re\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import math\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "#modelling\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf, acf, pacf\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we restrict the time series to one value per 60 seconds \n",
      "we compute the complexity variables each 30 minutes \n",
      "each variables includes the values of at least the last 120.00 minutes (i.e. are using 120.00 values)\n"
     ]
    }
   ],
   "source": [
    "from UTILS import perc_element_dico\n",
    "import config_mobility as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_extracted_data = config.path_extracted_data\n",
    "path_initial_data = config.path_initial_data\n",
    "id_run = config.id_run\n",
    "path_save_ = os.path.join(path_extracted_data, 'visual', 'egg','ACF-PACF_allhour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>mn</th>\n",
       "      <th>pacf_confintdifference</th>\n",
       "      <th>pacf_value</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.114295</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>10A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.172965</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>10A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.352229</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>10A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID  mn  pacf_confintdifference  pacf_value session\n",
       "0  hen_1  20                0.114295   23.666667     10A\n",
       "1  hen_1  30                0.172965   24.500000     10A\n",
       "2  hen_1  60                0.352229   24.000000     10A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\camil\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>pacf_variance</th>\n",
       "      <th>pacf_dico</th>\n",
       "      <th>pacf_perc_24</th>\n",
       "      <th>pacf_perc_23</th>\n",
       "      <th>pacf_perc_29</th>\n",
       "      <th>pacf_perc_25</th>\n",
       "      <th>pacf_perc_27</th>\n",
       "      <th>pacf_perc_20</th>\n",
       "      <th>pacf_perc_21</th>\n",
       "      <th>...</th>\n",
       "      <th>pacf_perc_28</th>\n",
       "      <th>pacf_perc_16</th>\n",
       "      <th>pacf_perc_19</th>\n",
       "      <th>pacf_perc_13</th>\n",
       "      <th>pacf_perc_11</th>\n",
       "      <th>pacf_perc_14</th>\n",
       "      <th>pacf_perc_17</th>\n",
       "      <th>perc_before24</th>\n",
       "      <th>perc_after24</th>\n",
       "      <th>nbr_unsign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>0.400</td>\n",
       "      <td>{24: 60.0, 25: 20.0, 23: 20.0}</td>\n",
       "      <td>60.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>{25: 100.0}</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_100</td>\n",
       "      <td>21.918</td>\n",
       "      <td>{24: 14.286, 11: 14.286, 23: 28.571, 25: 42.857}</td>\n",
       "      <td>14.286</td>\n",
       "      <td>28.571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.857</td>\n",
       "      <td>42.857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID  pacf_variance                                         pacf_dico  \\\n",
       "0    hen_1          0.400                    {24: 60.0, 25: 20.0, 23: 20.0}   \n",
       "1   hen_10          0.000                                       {25: 100.0}   \n",
       "2  hen_100         21.918  {24: 14.286, 11: 14.286, 23: 28.571, 25: 42.857}   \n",
       "\n",
       "   pacf_perc_24  pacf_perc_23  pacf_perc_29  pacf_perc_25  pacf_perc_27  \\\n",
       "0        60.000        20.000           0.0        20.000           0.0   \n",
       "1         0.000         0.000           0.0       100.000           0.0   \n",
       "2        14.286        28.571           0.0        42.857           0.0   \n",
       "\n",
       "   pacf_perc_20  pacf_perc_21     ...      pacf_perc_28  pacf_perc_16  \\\n",
       "0           0.0           0.0     ...               0.0           0.0   \n",
       "1           0.0           0.0     ...               0.0           0.0   \n",
       "2           0.0           0.0     ...               0.0           0.0   \n",
       "\n",
       "   pacf_perc_19  pacf_perc_13  pacf_perc_11  pacf_perc_14  pacf_perc_17  \\\n",
       "0           0.0           0.0         0.000           0.0           0.0   \n",
       "1           0.0           0.0         0.000           0.0           0.0   \n",
       "2           0.0           0.0        14.286           0.0           0.0   \n",
       "\n",
       "   perc_before24  perc_after24  nbr_unsign  \n",
       "0         20.000        20.000         1.0  \n",
       "1          0.000       100.000         1.0  \n",
       "2         42.857        42.857         1.0  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#egg shift\n",
    "df_shift = pd.read_csv(os.path.join(path_save_,id_run+'df_acf_pacf_session_summary.csv'), sep=';')\n",
    "display(df_shift.head(3))\n",
    "#keep only with 60mn\n",
    "df_shift = df_shift[df_shift['mn']==60]\n",
    "dico_hen_nbrunsign = dict(df_shift.groupby(['HenID'])['pacf_confintdifference'].agg(lambda x: sum([i<=0.1 for i in x])))\n",
    "#remove not strong significicant pacf\n",
    "df_shift = df_shift[df_shift['pacf_confintdifference']>0.1]\n",
    "\n",
    "df_shift['pacf_value'] = df_shift['pacf_value'].map(lambda x: round(x))\n",
    "li_val = df_shift['pacf_value'].unique()\n",
    "#extract variables\n",
    "fct2apply = {'pacf_variance':lambda x: round(np.var(x),3),\n",
    "            'pacf_dico':lambda x: perc_element_dico(x)}\n",
    "df_shift = df_shift.groupby(['HenID'])['pacf_value'].agg(fct2apply).reset_index()\n",
    "for v in li_val:\n",
    "    df_shift['pacf_perc_'+str(int(v))] = df_shift['pacf_dico'].map(lambda x: round(x.get(float(v),0.0),3))\n",
    "df_shift['perc_before24'] = df_shift['pacf_dico'].map(lambda x: sum([v for k,v in x.items() if k<24]))\n",
    "df_shift['perc_after24'] = df_shift['pacf_dico'].map(lambda x: sum([v for k,v in x.items() if k>24]))\n",
    "df_shift['nbr_unsign'] = df_shift['HenID'].map(lambda x: dico_hen_nbrunsign[x])\n",
    "#df_shift.drop(columns=['pacf_dico'], inplace=True)\n",
    "print(df_shift.shape)\n",
    "df_shift.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465, 20)\n",
      "(9, 21) (1, 21) (1, 21)\n",
      "(465, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pen</th>\n",
       "      <th>egg_level</th>\n",
       "      <th>CollDay</th>\n",
       "      <th>Location</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Width</th>\n",
       "      <th>Color</th>\n",
       "      <th>PenColour</th>\n",
       "      <th>HenInPen</th>\n",
       "      <th>...</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>HenID_Legband</th>\n",
       "      <th>HenID</th>\n",
       "      <th>HenID_Filipe</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>FileName</th>\n",
       "      <th>severity</th>\n",
       "      <th>gap</th>\n",
       "      <th>date_mob</th>\n",
       "      <th>is_LSL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>d4</td>\n",
       "      <td>nest</td>\n",
       "      <td>64.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>bbr</td>\n",
       "      <td>1bbr</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>LSL</td>\n",
       "      <td>1.12</td>\n",
       "      <td>hen_12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11A12</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>d4</td>\n",
       "      <td>nest</td>\n",
       "      <td>72.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>mbr</td>\n",
       "      <td>1mbr</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>LSL</td>\n",
       "      <td>1.18</td>\n",
       "      <td>hen_18</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>11A18</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>d4</td>\n",
       "      <td>nest</td>\n",
       "      <td>68.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>rbr</td>\n",
       "      <td>1rbr</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>LSL</td>\n",
       "      <td>1.15</td>\n",
       "      <td>hen_15</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>11A15</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pen  egg_level CollDay Location  Mass  Strength  Width Color PenColour  \\\n",
       "0    1 2017-08-07      d4     nest  64.2      47.0   0.31   bbr      1bbr   \n",
       "1    1 2017-08-07      d4     nest  72.9      46.0   0.28   mbr      1mbr   \n",
       "2    1 2017-08-07      d4     nest  68.1      33.0   0.25   rbr      1rbr   \n",
       "\n",
       "   HenInPen  ...   hybrid HenID_Legband   HenID HenID_Filipe  timepoint  \\\n",
       "0        12  ...      LSL          1.12  hen_12           12         11   \n",
       "1        18  ...      LSL          1.18  hen_18           18         11   \n",
       "2        15  ...      LSL          1.15  hen_15           15         11   \n",
       "\n",
       "   FileName severity  gap    date_mob is_LSL  \n",
       "0     11A12      2.9  0.0  2017-08-06    1.0  \n",
       "1     11A18      5.5  0.0  2017-08-06    1.0  \n",
       "2     11A15      6.9  1.0  2017-08-06    1.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#egg variable\n",
    "df_egg = pd.read_csv(os.path.join(path_initial_data,'Mo_eggs_matched_with_ID.csv'), sep=';', parse_dates=['Date'])\n",
    "print(df_egg.shape)\n",
    "#df_egg = df_egg[df_egg['Strength']!='na']\n",
    "df_egg['Date']= df_egg['Date'].replace(dt.datetime(2017,9,15), dt.datetime(2017,8,15)) #TODO: ASK YAMENAH CORRECT?\n",
    "df_egg = df_egg.replace('na', np.nan)\n",
    "df_egg['Strength'] = df_egg['Strength'].astype(float)\n",
    "df_egg['Mass'] = df_egg['Mass'].astype(float)\n",
    "df_egg['Width'] = df_egg['Width'].astype(float)\n",
    "df_egg.rename(columns={'Date':'egg_level', 'HenID_Christina':'HenID'}, inplace=True)\n",
    "df_egg['HenID'] = df_egg['HenID'].map(lambda x: 'hen_'+str(x))\n",
    "df_egg['is_LSL'] = df_egg['hybrid'].map(lambda x: float(x=='LSL'))\n",
    "print(df_egg[df_egg['Strength'].isnull()].shape, df_egg[df_egg['Mass'].isnull()].shape, df_egg[df_egg['Width'].isnull()].shape)\n",
    "print(df_egg.shape)\n",
    "df_egg.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>duration_zone_1</th>\n",
       "      <th>duration_zone_2</th>\n",
       "      <th>duration_zone_3</th>\n",
       "      <th>duration_zone_4</th>\n",
       "      <th>duration_zone_5</th>\n",
       "      <th>FirstTimestamp_zone_1</th>\n",
       "      <th>FirstTimestamp_zone_2</th>\n",
       "      <th>FirstTimestamp_zone_3</th>\n",
       "      <th>FirstTimestamp_zone_4</th>\n",
       "      <th>...</th>\n",
       "      <th>SampEnt_zone_1</th>\n",
       "      <th>SampEnt_zone_2</th>\n",
       "      <th>SampEnt_zone_3</th>\n",
       "      <th>SampEnt_zone_4</th>\n",
       "      <th>SampEnt_zone_5</th>\n",
       "      <th>FirstTimestamp_zone_1_h</th>\n",
       "      <th>FirstTimestamp_zone_2_h</th>\n",
       "      <th>FirstTimestamp_zone_3_h</th>\n",
       "      <th>FirstTimestamp_zone_4_h</th>\n",
       "      <th>FirstTimestamp_zone_5_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_100</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>4.205833</td>\n",
       "      <td>0.991389</td>\n",
       "      <td>1.286944</td>\n",
       "      <td>8.503056</td>\n",
       "      <td>2017-07-15 10:32:17</td>\n",
       "      <td>2017-07-15 02:21:31</td>\n",
       "      <td>2017-07-15 02:08:22</td>\n",
       "      <td>2017-07-15 02:07:03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>0.022160</td>\n",
       "      <td>10.538056</td>\n",
       "      <td>2.358611</td>\n",
       "      <td>2.139444</td>\n",
       "      <td>2.117500</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_100</td>\n",
       "      <td>1.045556</td>\n",
       "      <td>1.544167</td>\n",
       "      <td>0.977222</td>\n",
       "      <td>1.473889</td>\n",
       "      <td>9.959167</td>\n",
       "      <td>2017-07-16 09:29:54</td>\n",
       "      <td>2017-07-16 03:49:39</td>\n",
       "      <td>2017-07-16 03:05:41</td>\n",
       "      <td>2017-07-16 02:48:18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>0.010793</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>9.498333</td>\n",
       "      <td>3.827500</td>\n",
       "      <td>3.094722</td>\n",
       "      <td>2.805000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_100</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>1.851111</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>1.223056</td>\n",
       "      <td>11.804722</td>\n",
       "      <td>2017-07-17 10:21:23</td>\n",
       "      <td>2017-07-17 04:30:03</td>\n",
       "      <td>2017-07-17 04:41:58</td>\n",
       "      <td>2017-07-17 04:42:44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.008536</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>0.010099</td>\n",
       "      <td>10.356389</td>\n",
       "      <td>4.500833</td>\n",
       "      <td>4.699444</td>\n",
       "      <td>4.712222</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HenID  duration_zone_1  duration_zone_2  duration_zone_3  \\\n",
       "0  hen_100         0.012778         4.205833         0.991389   \n",
       "1  hen_100         1.045556         1.544167         0.977222   \n",
       "2  hen_100         0.102778         1.851111         0.018333   \n",
       "\n",
       "   duration_zone_4  duration_zone_5 FirstTimestamp_zone_1  \\\n",
       "0         1.286944         8.503056   2017-07-15 10:32:17   \n",
       "1         1.473889         9.959167   2017-07-16 09:29:54   \n",
       "2         1.223056        11.804722   2017-07-17 10:21:23   \n",
       "\n",
       "  FirstTimestamp_zone_2 FirstTimestamp_zone_3 FirstTimestamp_zone_4  \\\n",
       "0   2017-07-15 02:21:31   2017-07-15 02:08:22   2017-07-15 02:07:03   \n",
       "1   2017-07-16 03:49:39   2017-07-16 03:05:41   2017-07-16 02:48:18   \n",
       "2   2017-07-17 04:30:03   2017-07-17 04:41:58   2017-07-17 04:42:44   \n",
       "\n",
       "            ...            SampEnt_zone_1  SampEnt_zone_2  SampEnt_zone_3  \\\n",
       "0           ...                  0.002235        0.018886        0.014852   \n",
       "1           ...                  0.007679        0.010937        0.009991   \n",
       "2           ...                  0.002257        0.008536        0.002235   \n",
       "\n",
       "   SampEnt_zone_4  SampEnt_zone_5 FirstTimestamp_zone_1_h  \\\n",
       "0        0.018080        0.022160               10.538056   \n",
       "1        0.010793        0.012134                9.498333   \n",
       "2        0.010307        0.010099               10.356389   \n",
       "\n",
       "   FirstTimestamp_zone_2_h  FirstTimestamp_zone_3_h  FirstTimestamp_zone_4_h  \\\n",
       "0                 2.358611                 2.139444                 2.117500   \n",
       "1                 3.827500                 3.094722                 2.805000   \n",
       "2                 4.500833                 4.699444                 4.712222   \n",
       "\n",
       "   FirstTimestamp_zone_5_h  \n",
       "0                      2.0  \n",
       "1                      2.0  \n",
       "2                      2.0  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MLPS session metrics\n",
    "li_path = glob.glob(os.path.join(path_extracted_data,'VF_time_serie_day_*_variables_SIMPLER.csv'))\n",
    "dico_sess_dfvar = {}\n",
    "li_zone = ['zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5']\n",
    "for path_ in li_path:\n",
    "    sessID = path_.split('_')[-3]\n",
    "    df_ = pd.read_csv(path_, sep=';', index_col=0, parse_dates=['level','FirstTimestamp_zone_1','FirstTimestamp_zone_2',\n",
    "                                                                'FirstTimestamp_zone_3','FirstTimestamp_zone_4',\n",
    "                                                                'FirstTimestamp_zone_5'])\n",
    "    #day 2017-08-07 egg quality must be linked to the MLPs variable of the day 2017-08-06 with possible bias induce by if the hen \n",
    "    #laid the egg at 9h on the 2017-08-06 (or anytime after 8h, the time where the people take the egg). \n",
    "    df_['egg_level'] = df_['level'].map(lambda x: x+dt.timedelta(days=1))\n",
    "    for z in li_zone:\n",
    "        df_['SampEnt_'+z] = df_['SampEnt_perZone'].map(lambda x: eval(x).get(z,0))\n",
    "        df_['SampEnt_'+z] = df_['SampEnt_'+z].replace(-0.0,0)\n",
    "    df_.drop(columns=['level','verification_daily_total_duration','SampEnt_perZone'], inplace=True)    \n",
    "    #put to have less change among the dependant variable entries\n",
    "    df_['SampEnt_order2'] = df_['SampEnt_order2'].map(lambda x: x*10000)\n",
    "    for v in ['Max_duration','duration_zone_1','duration_zone_2','duration_zone_3','duration_zone_4','duration_zone_5']:\n",
    "        df_[v] = df_[v].map(lambda x: x/60/60)\n",
    "    df_['Variance_duration'] = df_['Variance_duration'].map(lambda x: x/(60*60)/(60*60))\n",
    "    li_fts = ['FirstTimestamp_zone_1','FirstTimestamp_zone_2','FirstTimestamp_zone_3','FirstTimestamp_zone_4',\n",
    "              'FirstTimestamp_zone_5']\n",
    "    for x in li_fts:\n",
    "        df_[x+'_h'] = df_[x].map(lambda x: x.hour+x.minute/60+x.second/60/60)\n",
    "        #lets say if we dont know that they went to 17h\n",
    "        df_[x+'_h'].fillna(17, inplace=True)\n",
    "    dico_sess_dfvar[sessID] = df_\n",
    "print(len(dico_sess_dfvar))\n",
    "dico_sess_dfvar['10B'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HenID</th>\n",
       "      <th>duration_zone_1</th>\n",
       "      <th>duration_zone_2</th>\n",
       "      <th>duration_zone_3</th>\n",
       "      <th>duration_zone_4</th>\n",
       "      <th>duration_zone_5</th>\n",
       "      <th>FirstTimestamp_zone_1</th>\n",
       "      <th>FirstTimestamp_zone_2</th>\n",
       "      <th>FirstTimestamp_zone_3</th>\n",
       "      <th>FirstTimestamp_zone_4</th>\n",
       "      <th>...</th>\n",
       "      <th>SampEnt_zone_1</th>\n",
       "      <th>SampEnt_zone_2</th>\n",
       "      <th>SampEnt_zone_3</th>\n",
       "      <th>SampEnt_zone_4</th>\n",
       "      <th>SampEnt_zone_5</th>\n",
       "      <th>FirstTimestamp_zone_1_h</th>\n",
       "      <th>FirstTimestamp_zone_2_h</th>\n",
       "      <th>FirstTimestamp_zone_3_h</th>\n",
       "      <th>FirstTimestamp_zone_4_h</th>\n",
       "      <th>FirstTimestamp_zone_5_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.260556</td>\n",
       "      <td>12.739444</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-08-03 04:30:49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>0.032790</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.513611</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026111</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>2.151389</td>\n",
       "      <td>12.785833</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-08-04 13:41:51</td>\n",
       "      <td>2017-08-04 13:40:05</td>\n",
       "      <td>2017-08-04 03:24:23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.034894</td>\n",
       "      <td>0.032449</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.697500</td>\n",
       "      <td>13.668056</td>\n",
       "      <td>3.406389</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hen_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>2.217778</td>\n",
       "      <td>12.724722</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2017-08-05 09:20:14</td>\n",
       "      <td>2017-08-05 09:19:30</td>\n",
       "      <td>2017-08-05 05:01:23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.029955</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.337222</td>\n",
       "      <td>9.325000</td>\n",
       "      <td>5.023056</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HenID  duration_zone_1  duration_zone_2  duration_zone_3  duration_zone_4  \\\n",
       "0  hen_1              0.0         0.000000         0.000000         2.260556   \n",
       "1  hen_1              0.0         0.026111         0.036667         2.151389   \n",
       "2  hen_1              0.0         0.026667         0.030833         2.217778   \n",
       "\n",
       "   duration_zone_5 FirstTimestamp_zone_1 FirstTimestamp_zone_2  \\\n",
       "0        12.739444                   NaT                   NaT   \n",
       "1        12.785833                   NaT   2017-08-04 13:41:51   \n",
       "2        12.724722                   NaT   2017-08-05 09:20:14   \n",
       "\n",
       "  FirstTimestamp_zone_3 FirstTimestamp_zone_4           ...             \\\n",
       "0                   NaT   2017-08-03 04:30:49           ...              \n",
       "1   2017-08-04 13:40:05   2017-08-04 03:24:23           ...              \n",
       "2   2017-08-05 09:19:30   2017-08-05 05:01:23           ...              \n",
       "\n",
       "  SampEnt_zone_1  SampEnt_zone_2  SampEnt_zone_3  SampEnt_zone_4  \\\n",
       "0            0.0        0.000000        0.000000        0.032790   \n",
       "1            0.0        0.002237        0.002235        0.034894   \n",
       "2            0.0        0.002235        0.002242        0.029955   \n",
       "\n",
       "   SampEnt_zone_5 FirstTimestamp_zone_1_h  FirstTimestamp_zone_2_h  \\\n",
       "0        0.032790                    17.0                17.000000   \n",
       "1        0.032449                    17.0                13.697500   \n",
       "2        0.027494                    17.0                 9.337222   \n",
       "\n",
       "   FirstTimestamp_zone_3_h  FirstTimestamp_zone_4_h  FirstTimestamp_zone_5_h  \n",
       "0                17.000000                 4.513611                      2.0  \n",
       "1                13.668056                 3.406389                      2.0  \n",
       "2                 9.325000                 5.023056                      2.0  \n",
       "\n",
       "[3 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_var11 = pd.concat([dico_sess_dfvar['11A'],dico_sess_dfvar['11B']])\n",
    "print(df_var11.shape)\n",
    "df_var11.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: why only 84??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 106\n"
     ]
    }
   ],
   "source": [
    "li_hen_mlp = df_var11['HenID'].unique()\n",
    "li_hen_egg = df_egg['HenID'].unique()\n",
    "print(len(li_hen_mlp), len(li_hen_egg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 21)\n"
     ]
    }
   ],
   "source": [
    "df_egg = df_egg[df_egg['HenID'].isin(li_hen_mlp)]\n",
    "print(df_egg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## daily ~ MLP metrics daily including only timestamp 11"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mixed effect models to account for hen variability and find: random hen-to-hen variability in egg quality\n",
    "multivariate modelling to account for multiple dependent variable stregnth, width, mass, Location\n",
    "generalized model to account for non-linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aggregate variable at day level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>egg_level</th>\n",
       "      <th>HenID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Width</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>group</th>\n",
       "      <th>severity</th>\n",
       "      <th>is_LSL</th>\n",
       "      <th>...</th>\n",
       "      <th>SampEnt_zone_1</th>\n",
       "      <th>SampEnt_zone_2</th>\n",
       "      <th>SampEnt_zone_3</th>\n",
       "      <th>SampEnt_zone_4</th>\n",
       "      <th>SampEnt_zone_5</th>\n",
       "      <th>FirstTimestamp_zone_1_h</th>\n",
       "      <th>FirstTimestamp_zone_2_h</th>\n",
       "      <th>FirstTimestamp_zone_3_h</th>\n",
       "      <th>FirstTimestamp_zone_4_h</th>\n",
       "      <th>FirstTimestamp_zone_5_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_12</td>\n",
       "      <td>nest</td>\n",
       "      <td>64.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.034288</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.871944</td>\n",
       "      <td>9.785556</td>\n",
       "      <td>3.980278</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_18</td>\n",
       "      <td>nest</td>\n",
       "      <td>72.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.865278</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_6</td>\n",
       "      <td>nest</td>\n",
       "      <td>65.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.072840</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.333611</td>\n",
       "      <td>6.330000</td>\n",
       "      <td>2.203333</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   egg_level   HenID Location  Mass  Strength  Width hybrid group  severity  \\\n",
       "0 2017-08-07  hen_12     nest  64.2      47.0   0.31    LSL     A       2.9   \n",
       "1 2017-08-07  hen_18     nest  72.9      46.0   0.28    LSL     A       5.5   \n",
       "2 2017-08-07   hen_6     nest  65.3      53.0   0.27    LSL     A       5.6   \n",
       "\n",
       "   is_LSL           ...            SampEnt_zone_1  SampEnt_zone_2  \\\n",
       "0     1.0           ...                       0.0        0.002283   \n",
       "1     1.0           ...                       0.0        0.000000   \n",
       "2     1.0           ...                       0.0        0.004494   \n",
       "\n",
       "   SampEnt_zone_3  SampEnt_zone_4  SampEnt_zone_5 FirstTimestamp_zone_1_h  \\\n",
       "0        0.006795        0.034288        0.027683                    17.0   \n",
       "1        0.000000        0.012291        0.012291                    17.0   \n",
       "2        0.011394        0.072840        0.061064                    17.0   \n",
       "\n",
       "  FirstTimestamp_zone_2_h FirstTimestamp_zone_3_h FirstTimestamp_zone_4_h  \\\n",
       "0                9.871944                9.785556                3.980278   \n",
       "1               17.000000               17.000000                2.865278   \n",
       "2                6.333611                6.330000                2.203333   \n",
       "\n",
       "  FirstTimestamp_zone_5_h  \n",
       "0                     2.0  \n",
       "1                     2.0  \n",
       "2                     2.0  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df_egg.filter(['egg_level','HenID','Date','Location','Mass','Strength','Width','hybrid','group','severity',\n",
    "                             'is_LSL']),\n",
    "              df_var11, on=['egg_level','HenID'], how='left')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>egg_level</th>\n",
       "      <th>HenID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Strength</th>\n",
       "      <th>Width</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>group</th>\n",
       "      <th>severity</th>\n",
       "      <th>is_LSL</th>\n",
       "      <th>...</th>\n",
       "      <th>pacf_perc_28</th>\n",
       "      <th>pacf_perc_16</th>\n",
       "      <th>pacf_perc_19</th>\n",
       "      <th>pacf_perc_13</th>\n",
       "      <th>pacf_perc_11</th>\n",
       "      <th>pacf_perc_14</th>\n",
       "      <th>pacf_perc_17</th>\n",
       "      <th>perc_before24</th>\n",
       "      <th>perc_after24</th>\n",
       "      <th>nbr_unsign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_12</td>\n",
       "      <td>nest</td>\n",
       "      <td>64.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_18</td>\n",
       "      <td>nest</td>\n",
       "      <td>72.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>hen_6</td>\n",
       "      <td>nest</td>\n",
       "      <td>65.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>LSL</td>\n",
       "      <td>A</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   egg_level   HenID Location  Mass  Strength  Width hybrid group  severity  \\\n",
       "0 2017-08-07  hen_12     nest  64.2      47.0   0.31    LSL     A       2.9   \n",
       "1 2017-08-07  hen_18     nest  72.9      46.0   0.28    LSL     A       5.5   \n",
       "2 2017-08-07   hen_6     nest  65.3      53.0   0.27    LSL     A       5.6   \n",
       "\n",
       "   is_LSL    ...      pacf_perc_28  pacf_perc_16  pacf_perc_19  pacf_perc_13  \\\n",
       "0     1.0    ...               0.0           0.0           0.0           0.0   \n",
       "1     1.0    ...               0.0           0.0           0.0           0.0   \n",
       "2     1.0    ...               0.0           0.0           0.0           0.0   \n",
       "\n",
       "   pacf_perc_11 pacf_perc_14 pacf_perc_17 perc_before24 perc_after24  \\\n",
       "0           0.0          0.0          0.0        25.000        0.000   \n",
       "1           0.0          0.0          0.0        44.444        0.000   \n",
       "2           0.0          0.0          0.0         0.000       27.273   \n",
       "\n",
       "  nbr_unsign  \n",
       "0        1.0  \n",
       "1        2.0  \n",
       "2        0.0  \n",
       "\n",
       "[3 rows x 80 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, df_shift, on=['HenID'], how='left')\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['egg_level', 'HenID', 'Location', 'Mass', 'Strength', 'Width', 'hybrid',\n",
       "       'group', 'severity', 'is_LSL', 'duration_zone_1', 'duration_zone_2',\n",
       "       'duration_zone_3', 'duration_zone_4', 'duration_zone_5',\n",
       "       'FirstTimestamp_zone_1', 'FirstTimestamp_zone_2',\n",
       "       'FirstTimestamp_zone_3', 'FirstTimestamp_zone_4',\n",
       "       'FirstTimestamp_zone_5', 'Total_number_zone',\n",
       "       'RunSampEnt_onLastTsOfEachLevel', 'RunDistEnt_onLastTsOfEachLevel',\n",
       "       'RunEnt_onLastTsOfEachLevel_nbr_value',\n",
       "       'RunEnt_onLastTsOfEachLevel_ts_value',\n",
       "       'RunSampEnt_onLastTsOfEachLevel_1', 'RunSampEnt_onLastTsOfEachLevel_2',\n",
       "       'RunSampEnt_onLastTsOfEachLevel_3', 'RunSampEnt_onLastTsOfEachLevel_4',\n",
       "       'RunSampEnt_onLastTsOfEachLevel_5', 'Max_duration_zones',\n",
       "       'Max_duration', 'Min_duration', 'Median_duration', 'Average_duration',\n",
       "       'Variance_duration', 'dico_zone_duration', 'Total_number_transition',\n",
       "       'distribution_entropy', 'nbr_bouts_zone_5', 'nbr_bouts_zone_4',\n",
       "       'nbr_bouts_zone_3', 'nbr_bouts_zone_2', 'nbr_bouts_zone_1',\n",
       "       'Max_duration_zone_4', 'SampEnt_order2', 'SampEnt_zone_1',\n",
       "       'SampEnt_zone_2', 'SampEnt_zone_3', 'SampEnt_zone_4', 'SampEnt_zone_5',\n",
       "       'FirstTimestamp_zone_1_h', 'FirstTimestamp_zone_2_h',\n",
       "       'FirstTimestamp_zone_3_h', 'FirstTimestamp_zone_4_h',\n",
       "       'FirstTimestamp_zone_5_h', 'pacf_variance', 'pacf_dico', 'pacf_perc_24',\n",
       "       'pacf_perc_23', 'pacf_perc_29', 'pacf_perc_25', 'pacf_perc_27',\n",
       "       'pacf_perc_20', 'pacf_perc_21', 'pacf_perc_22', 'pacf_perc_18',\n",
       "       'pacf_perc_10', 'pacf_perc_26', 'pacf_perc_30', 'pacf_perc_28',\n",
       "       'pacf_perc_16', 'pacf_perc_19', 'pacf_perc_13', 'pacf_perc_11',\n",
       "       'pacf_perc_14', 'pacf_perc_17', 'perc_before24', 'perc_after24',\n",
       "       'nbr_unsign'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choosing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(df_var11['egg_level'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_egg[df_egg['egg_level']=='2017-08-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['duration_zone_2'].isnull()]['HenID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['duration_zone_2'].isnull()]['egg_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_var11[(df_var11['HenID']=='hen_81')&(df_var11['egg_level']=='hen_81')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()\n",
    "#duration_zone_1!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(238, 80)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for now: remove those values\n",
    "print(df.shape)\n",
    "df = df[~((df['duration_zone_2'].isnull())&(df['duration_zone_4'].isnull()))]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nan\n",
    "li = ['SampEnt_order2', 'SampEnt_zone_1','SampEnt_zone_2', 'SampEnt_zone_3', 'SampEnt_zone_4', 'SampEnt_zone_5',\n",
    "          'RunSampEnt_onLastTsOfEachLevel', 'RunDistEnt_onLastTsOfEachLevel',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_1', 'RunSampEnt_onLastTsOfEachLevel_2',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_3', 'RunSampEnt_onLastTsOfEachLevel_4',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_5',\n",
    "          'distribution_entropy']\n",
    "df[li] = df[li].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'Mass' \n",
    "\n",
    "li_x = ['Location', 'Mass', 'Strength', 'Width'] \n",
    "\n",
    "li_hen = ['is_LSL', 'severity']\n",
    "\n",
    "li_mlp = ['duration_zone_1', 'duration_zone_2','duration_zone_3', 'duration_zone_4', 'duration_zone_5',\n",
    "           'FirstTimestamp_zone_1_h', 'FirstTimestamp_zone_2_h',\n",
    "           'FirstTimestamp_zone_3_h', 'FirstTimestamp_zone_4_h',\n",
    "           'FirstTimestamp_zone_5_h', 'Total_number_zone','Max_duration_zones',\n",
    "           'Max_duration', 'Min_duration', 'Median_duration', 'Average_duration',\n",
    "           'Variance_duration', 'dico_zone_duration', 'Total_number_transition',\n",
    "           'nbr_bouts_zone_5', 'nbr_bouts_zone_4',\n",
    "           'nbr_bouts_zone_3', 'nbr_bouts_zone_2', 'nbr_bouts_zone_1',\n",
    "           'Max_duration_zone_4']\n",
    "\n",
    "li_cpx = ['SampEnt_order2', 'SampEnt_zone_1','SampEnt_zone_2', 'SampEnt_zone_3', 'SampEnt_zone_4', 'SampEnt_zone_5',\n",
    "          'RunSampEnt_onLastTsOfEachLevel', 'RunDistEnt_onLastTsOfEachLevel',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_1', 'RunSampEnt_onLastTsOfEachLevel_2',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_3', 'RunSampEnt_onLastTsOfEachLevel_4',\n",
    "          'RunSampEnt_onLastTsOfEachLevel_5',\n",
    "          'distribution_entropy']     \n",
    "\n",
    "li_pacf = ['pacf_variance', 'pacf_perc_24', 'pacf_perc_23', 'pacf_perc_26',\n",
    "           'pacf_perc_25', 'pacf_perc_29', 'pacf_perc_22', 'pacf_perc_27',\n",
    "           'pacf_perc_28', 'pacf_perc_30', 'pacf_perc_15', 'pacf_perc_18',\n",
    "           'pacf_perc_21', 'pacf_perc_19', 'perc_before24', 'perc_after24','nbr_unsign']\n",
    "li_pacf_before24 = ['pacf_perc_23', 'pacf_perc_22', 'pacf_perc_15', 'pacf_perc_18',\n",
    "           'pacf_perc_21', 'pacf_perc_19']\n",
    "\n",
    "\n",
    "li_var = list(set(['is_LSL','duration_zone_1','duration_zone_2','duration_zone_5','duration_zone_4',\n",
    "          'Total_number_transition', 'severity','Variance_duration','distribution_entropy','SampEnt_order2','SampEnt_zone_4',\n",
    "          'Max_duration_zone_4','FirstTimestamp_zone_4_h']+li_pacf_before24))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mixed effects models are useful when we have data with more than one source of random variability. For example, an outcome may be measured more than once on the same person (repeated measures taken over time). When we do that we have to account for both within-person and across-person variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mixed effect model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mixed effects models are useful when we have data with more than one source of random variability. For example, an outcome may be measured more than once on the same person (repeated measures taken over time). When we do that we have to account for both within-person and across-person variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_var = ['duration_zone_1','duration_zone_2','duration_zone_5','duration_zone_4',\n",
    "          'Total_number_transition', 'severity','Variance_duration','distribution_entropy','SampEnt_order2','SampEnt_zone_4',\n",
    "          'Max_duration_zone_4','pacf_perc_24','perc_after24','perc_before24','FirstTimestamp_zone_4_h','is_LSL',\n",
    "         'Mass', 'Strength','nbr_unsign']\n",
    "g = sns.PairGrid(df[li_var])\n",
    "g.map(plt.scatter);\n",
    "plt.savefig(os.path.join(path_save_,id_run+'_scatterplot_var.png'), format='png', dpi=300)\n",
    "#Total_number_transition, duration_zone_2 , SampEnt_zone_4up --> perc_after24 up and perc_before24 down\n",
    "#Max_duration_zone_4, duration_zone_4 up --> erc_after24 down and perc_before24 up\n",
    "#??Variance_duration?? fucked up  --'SampEnt_order2','SampEnt_zone_4' down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "li_var = ['perc_after24','perc_before24','SampEnt_zone_4','duration_zone_2','duration_zone_4','Max_duration_zone_4',\n",
    "          'Total_number_transition']\n",
    "g = sns.PairGrid(df[li_var])\n",
    "g.map(plt.scatter);\n",
    "plt.savefig(os.path.join(path_save_,id_run+'_scatterplot_var.png'), format='png', dpi=300)\n",
    "#Total_number_transition, duration_zone_2 , SampEnt_zone_4up --> perc_after24 up and perc_before24 down\n",
    "#Max_duration_zone_4, duration_zone_4 up --> perc_after24 down and perc_before24 up\n",
    "#??Variance_duration?? fuck up up  --'SampEnt_order2','SampEnt_zone_4' down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the lmplot function within seaborn\n",
    "sns.lmplot(x = \"perc_before24\", y = \"Mass\", data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_var = list(set(['duration_zone_1','duration_zone_2','duration_zone_5','duration_zone_4',\n",
    "          'Total_number_transition', 'severity','distribution_entropy','SampEnt_order2','SampEnt_zone_4',\n",
    "          'Max_duration_zone_4','perc_before24','perc_after24','FirstTimestamp_zone_4_h','is_LSL','nbr_unsign']))\n",
    "mm = sm.MixedLM(endog=df['Mass'], exog=df[li_var], groups=df['HenID'])\n",
    "res = mm.fit(method='lbfgs') #method='lbfgs','cg'\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/statsmodels-dq/\n",
    "#e.g.: https://docs.w3cub.com/statsmodels/examples/notebooks/generated/glm_formula/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#perc_before24, perc_after24\n",
    "formula = x+' ~ '+'+'.join(li_var)\n",
    "min_sample_Size = 50 + 8*len(li_var)\n",
    "df_mod = df[~df[x].isnull()][li_var+[x,'HenID']].copy()\n",
    "display(df_mod.head(3))\n",
    "print(min_sample_Size)\n",
    "if min_sample_Size>=df_mod.shape[0]:\n",
    "    print('WARNING: reduce the dependant var or augment your number of observation')\n",
    "    sys.exit()\n",
    "    \n",
    "mod1 = smf.glm(formula=formula, data=df_mod).fit() #, family=sm.families.Binomial()\n",
    "mod1.summary()\n",
    "#--> mass seems to increase with higher percentgae of shift 22"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Pearson chi-squared test measures the goodness of fit of your model on your dependent variables. The degrees of freedom tell us the range in which the chi-square statistic is free to vary. It's used in the calculation of the chi-square.\n",
    "\n",
    "log likelihood is a way of saying the model is maximizing the probability that the parameters we observed in the sample (your dataset) are what we would observe in the population. That's what the likelihood function is doing anyway and taking the log of that function helps simplify it. Hence log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DL (if more data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029\n",
    "---------------dependant var multi class categorical variable\n",
    "use softmax as activation function and sparse-categorical cross entropy as loss function\n",
    "model = keras.Sequential([\n",
    " keras.layers.Dense(64, activation=tf.nn.relu,                  \n",
    " input_shape=(y_train.shape[1],)),\n",
    " keras.layers.Dense(64, activation=tf.nn.relu),\n",
    " keras.layers.Dense(#nbr_categories, activation=  'softmax')\n",
    " ])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "-----------continuous var ,mse as loss relu as activation finish with 1\n",
    "model = keras.Sequential([keras.layers.Dense(64, activation=tf.nn.relu,\n",
    "                                             input_shape=(y_train.shape[1],)),\n",
    "                                             keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                             keras.layers.Dense(1, activation=  'relu')])\n",
    "display(model.summary())\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "x = 'Mass' \n",
    "li_pacf_before24 = ['pacf_perc_23', 'pacf_perc_22', 'pacf_perc_15', 'pacf_perc_18',\n",
    "           'pacf_perc_21', 'pacf_perc_19']\n",
    "li_var = list(set(['is_LSL','duration_zone_1','duration_zone_2','duration_zone_5','duration_zone_4',\n",
    "          'Total_number_transition', 'severity','Variance_duration','distribution_entropy','SampEnt_order2','SampEnt_zone_4',\n",
    "          'Max_duration_zone_4','pacf_perc_23', 'pacf_perc_22']))\n",
    "\n",
    "df_mod = df[~df[x].isnull()][li_var+[x]].copy()\n",
    "\n",
    "#Select predictors\n",
    "y = df_mod[li_var]\n",
    "#Target variable \n",
    "x = df_mod[x]\n",
    "#Split data into train and test \n",
    "y_train, y_test, x_train, x_test = train_test_split(y, x , train_size = 0.8, random_state =  90)\n",
    "'''As y variable is multi class categorical variable, hence using softmax as activation function and sparse-categorical cross entropy as loss function.'''\n",
    "model = keras.Sequential([keras.layers.Dense(64, activation=tf.nn.relu,\n",
    "                                             input_shape=(y_train.shape[1],)),\n",
    "                                             keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                             keras.layers.Dense(1, activation=  'relu')])\n",
    "display(model.summary())\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "history1 = model.fit(y_train, x_train,\n",
    "                     epochs= 200, batch_size = 10,\n",
    "                     validation_data = (y_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = 'Location' \n",
    "li_pacf_before24 = ['pacf_perc_23', 'pacf_perc_22', 'pacf_perc_15', 'pacf_perc_18',\n",
    "           'pacf_perc_21', 'pacf_perc_19']\n",
    "li_var = list(set(['is_LSL','duration_zone_1','duration_zone_2','duration_zone_5','duration_zone_4',\n",
    "          'Total_number_transition', 'severity','Variance_duration','distribution_entropy','SampEnt_order2','SampEnt_zone_4',\n",
    "          'Max_duration_zone_4','pacf_perc_23', 'pacf_perc_22']))\n",
    "\n",
    "df_mod = df[~df[x].isnull()][li_var+[x]].copy()\n",
    "\n",
    "#Select predictors\n",
    "y = df_mod[li_var]\n",
    "\n",
    "#Target variable \n",
    "x = df_mod[x]\n",
    "\n",
    "#Split data into train and test \n",
    "y_train, y_test, x_train, x_test = train_test_split(y, x , train_size = 0.8, random_state =  90)\n",
    "\n",
    "model = keras.Sequential([\n",
    " keras.layers.Dense(64, activation=tf.nn.relu,                  \n",
    " input_shape=(y_train.shape[1],)),\n",
    " keras.layers.Dense(64, activation=tf.nn.relu),\n",
    " keras.layers.Dense(len(df['Location'].unique()), activation=  'softmax')\n",
    " ])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history1 = model.fit(y_train, x_train,\n",
    "                     epochs= 2000, batch_size = 10,\n",
    "                     validation_data = (y_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hen level ~ MLP metrics at hen level including all timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to think about"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remove one duration_zone_5\n",
    "GLMM\n",
    "add variable: age, nbr/% of transiiton that suate une zone, etc\n",
    "normalisation\n",
    "degree of freedom\n",
    "stepwise model\n",
    "nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
